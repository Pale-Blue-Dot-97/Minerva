{
  "$schema": "https://raw.githubusercontent.com/schemastore/schemastore/master/src/schemas/json/sarif-2.1.0-rtm.5.json",
  "version": "2.1.0",
  "runs": [
    {
      "tool": {
        "driver": {
          "name": "QDPY",
          "fullName": "Qodana for Python",
          "version": "223.8782.115",
          "rules": [],
          "taxa": [
            {
              "id": "EditorConfig",
              "name": "EditorConfig"
            },
            {
              "id": "Jupyter",
              "name": "Jupyter"
            },
            {
              "id": "Python",
              "name": "Python"
            },
            {
              "id": "PostgreSQL",
              "name": "PostgreSQL"
            },
            {
              "id": "Google App Engine (Python)",
              "name": "Google App Engine (Python)"
            },
            {
              "id": "SQL",
              "name": "SQL"
            },
            {
              "id": "XML",
              "name": "XML"
            },
            {
              "id": "YAML",
              "name": "YAML"
            },
            {
              "id": "JSON and JSON5",
              "name": "JSON and JSON5"
            },
            {
              "id": "MongoJS",
              "name": "MongoJS"
            },
            {
              "id": "RegExp",
              "name": "RegExp"
            },
            {
              "id": "Properties files",
              "name": "Properties files"
            },
            {
              "id": "MySQL",
              "name": "MySQL"
            },
            {
              "id": "CSS",
              "name": "CSS"
            },
            {
              "id": "Django",
              "name": "Django"
            },
            {
              "id": "HTML",
              "name": "HTML"
            },
            {
              "id": "CSS/Probable bugs",
              "name": "Probable bugs",
              "relationships": [
                {
                  "target": {
                    "id": "CSS",
                    "index": 13,
                    "toolComponent": {
                      "name": "QDPY"
                    }
                  },
                  "kinds": [
                    "superset"
                  ]
                }
              ]
            },
            {
              "id": "General",
              "name": "General"
            },
            {
              "id": "HTML/Accessibility",
              "name": "Accessibility",
              "relationships": [
                {
                  "target": {
                    "id": "HTML",
                    "index": 15,
                    "toolComponent": {
                      "name": "QDPY"
                    }
                  },
                  "kinds": [
                    "superset"
                  ]
                }
              ]
            },
            {
              "id": "SQL server",
              "name": "SQL server"
            },
            {
              "id": "CSS/Invalid elements",
              "name": "Invalid elements",
              "relationships": [
                {
                  "target": {
                    "id": "CSS",
                    "index": 13,
                    "toolComponent": {
                      "name": "QDPY"
                    }
                  },
                  "kinds": [
                    "superset"
                  ]
                }
              ]
            },
            {
              "id": "Structural search",
              "name": "Structural search"
            },
            {
              "id": "Dependency analysis",
              "name": "Dependency analysis"
            },
            {
              "id": "CSS/Code style issues",
              "name": "Code style issues",
              "relationships": [
                {
                  "target": {
                    "id": "CSS",
                    "index": 13,
                    "toolComponent": {
                      "name": "QDPY"
                    }
                  },
                  "kinds": [
                    "superset"
                  ]
                }
              ]
            },
            {
              "id": "Ini files",
              "name": "Ini files"
            },
            {
              "id": "RELAX NG",
              "name": "RELAX NG"
            },
            {
              "id": "Proofreading",
              "name": "Proofreading"
            },
            {
              "id": "Pyramid",
              "name": "Pyramid"
            },
            {
              "id": "Oracle",
              "name": "Oracle"
            },
            {
              "id": "Internationalization",
              "name": "Internationalization"
            },
            {
              "id": "Version control",
              "name": "Version control"
            }
          ],
          "language": "en-US",
          "contents": [
            "localizedData",
            "nonLocalizedData"
          ],
          "isComprehensive": false
        },
        "extensions": [
          {
            "name": "org.editorconfig.editorconfigjetbrains",
            "version": "223.8782",
            "rules": [
              {
                "id": "EditorConfigCharClassRedundancy",
                "shortDescription": {
                  "text": "Unnecessary character class"
                },
                "fullDescription": {
                  "text": "Reports character classes that consist of a single character. Such classes can be simplified to a character, for example '[a]'→'a'.",
                  "markdown": "Reports character classes that consist of a single character. Such classes can be simplified to a character, for example `[a]`→`a`."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigDeprecatedDescriptor",
                "shortDescription": {
                  "text": "Deprecated property"
                },
                "fullDescription": {
                  "text": "Reports EditorConfig properties that are no longer supported.",
                  "markdown": "Reports EditorConfig properties that are no longer supported."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigRootDeclarationUniqueness",
                "shortDescription": {
                  "text": "Extra top-level declaration"
                },
                "fullDescription": {
                  "text": "Reports multiple top-level declarations. There can be only one optional “root=true” top-level declaration in the EditorConfig file. Using multiple top-level declarations is not allowed.",
                  "markdown": "Reports multiple top-level declarations. There can be only one optional \"root=true\" top-level declaration in the EditorConfig file. Using multiple top-level declarations is not allowed."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigNumerousWildcards",
                "shortDescription": {
                  "text": "Too many wildcards"
                },
                "fullDescription": {
                  "text": "Reports sections that contain too many wildcards. Using a lot of wildcards may lead to performance issues.",
                  "markdown": "Reports sections that contain too many wildcards. Using a lot of wildcards may lead to performance issues."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigWildcardRedundancy",
                "shortDescription": {
                  "text": "Redundant wildcard"
                },
                "fullDescription": {
                  "text": "Reports wildcards that become redundant when the “**” wildcard is used in the same section. The “**” wildcard defines a broader set of files than any other wildcard. That is why, any other wildcard used in the same section has no affect and can be removed.",
                  "markdown": "Reports wildcards that become redundant when the \"\\*\\*\" wildcard is used in the same section.\n\n\nThe \"\\*\\*\" wildcard defines a broader set of files than any other wildcard.\nThat is why, any other wildcard used in the same section has no affect and can be removed."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigPartialOverride",
                "shortDescription": {
                  "text": "Overlapping sections"
                },
                "fullDescription": {
                  "text": "Reports subsets of files specified in the current section that overlap with other subsets in other sections. For example: '[{foo,bar}]' and '[{foo,bas}]' both contain “foo”.",
                  "markdown": "Reports subsets of files specified in the current section that overlap with other subsets in other sections. For example: `[{foo,bar}]` and `[{foo,bas}]` both contain \"foo\"."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigEmptySection",
                "shortDescription": {
                  "text": "Empty section"
                },
                "fullDescription": {
                  "text": "Reports sections that do not contain any EditorConfig properties.",
                  "markdown": "Reports sections that do not contain any EditorConfig properties."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigHeaderUniqueness",
                "shortDescription": {
                  "text": "EditorConfig section is not unique"
                },
                "fullDescription": {
                  "text": "Reports sections that define the same file pattern as other sections.",
                  "markdown": "Reports sections that define the same file pattern as other sections."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigShadowingOption",
                "shortDescription": {
                  "text": "Overriding property"
                },
                "fullDescription": {
                  "text": "Reports properties that override the same properties defined earlier in the file. For example: '[*.java]\nindent_size=4\n[{*.java,*.js}]\nindent_size=2' The second section includes the same files as '[*.java]' but also sets indent_size to value 2. Thus the first declaration 'indent_size=4'will be ignored.",
                  "markdown": "Reports properties that override the same properties defined earlier in the file.\n\nFor example:\n\n\n    [*.java]\n    indent_size=4\n    [{*.java,*.js}]\n    indent_size=2\n\nThe second section includes the same files as `[*.java]` but also sets indent_size to value 2. Thus the first declaration `indent_size=4`will be ignored."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigListAcceptability",
                "shortDescription": {
                  "text": "Unexpected value list"
                },
                "fullDescription": {
                  "text": "Reports lists of values that are used in properties in which lists are not supported. In this case, only a single value can be specified.",
                  "markdown": "Reports lists of values that are used in properties in which lists are not supported. In this case, only a single value can be specified."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigShadowedOption",
                "shortDescription": {
                  "text": "Overridden property"
                },
                "fullDescription": {
                  "text": "Reports properties that are already defined in other sections. For example: '[*.java]\nindent_size=4\n[{*.java,*.js}]\nindent_size=2' The second section includes all '*.java' files too but it also redefines indent_size. As a result the value 2 will be used for files matching '*.java'.",
                  "markdown": "Reports properties that are already defined in other sections.\n\nFor example:\n\n\n    [*.java]\n    indent_size=4\n    [{*.java,*.js}]\n    indent_size=2\n\nThe second section includes all `*.java` files too but it also redefines indent_size. As a result the value 2 will be used for files matching `*.java`."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigEmptyHeader",
                "shortDescription": {
                  "text": "Empty header"
                },
                "fullDescription": {
                  "text": "Reports sections with an empty header. Section header must contain file path globs in the format similar to one supported by 'gitignore'.",
                  "markdown": "Reports sections with an empty header. Section header must contain file path globs in the format similar to one supported by `gitignore`."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigValueCorrectness",
                "shortDescription": {
                  "text": "Invalid property value"
                },
                "fullDescription": {
                  "text": "Reports property values that do not meet value restrictions. For example, some properties may be only “true” or “false”, others contain only integer numbers etc. If a value has a limited set of variants, use code completion to see all of them.",
                  "markdown": "Reports property values that do not meet value restrictions. For example, some properties may be only \"true\" or \"false\", others contain only integer numbers etc. If a value has a limited set of variants, use code completion to see all of them."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigValueUniqueness",
                "shortDescription": {
                  "text": "Non-unique list value"
                },
                "fullDescription": {
                  "text": "Reports duplicates in lists of values.",
                  "markdown": "Reports duplicates in lists of values."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigMissingRequiredDeclaration",
                "shortDescription": {
                  "text": "Required declarations are missing"
                },
                "fullDescription": {
                  "text": "Reports properties that miss the required declarations. Refer to the documentation for more information.",
                  "markdown": "Reports properties that miss the required declarations. Refer to the documentation for more information."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigCharClassLetterRedundancy",
                "shortDescription": {
                  "text": "Duplicate character class letter"
                },
                "fullDescription": {
                  "text": "Reports wildcard patterns in the EditorConfig section that contain a duplicate character in the character class, for example '[aa]'.",
                  "markdown": "Reports wildcard patterns in the EditorConfig section that contain a duplicate character in the character class, for example `[aa]`."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigKeyCorrectness",
                "shortDescription": {
                  "text": "Unknown property"
                },
                "fullDescription": {
                  "text": "Reports properties that are not supported by the IDE. Note: some “ij” domain properties may require specific language plugins.",
                  "markdown": "Reports properties that are not supported by the IDE. Note: some \"ij\" domain properties may require specific language plugins."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigPatternEnumerationRedundancy",
                "shortDescription": {
                  "text": "Unnecessary braces"
                },
                "fullDescription": {
                  "text": "Reports pattern lists that are either empty '{}' or contain just one pattern, for example '{foo}'. The braces are needed only if there are two and more, for example: '{foo,bar}'",
                  "markdown": "Reports pattern lists that are either empty `{}` or contain just one pattern, for example `{foo}`. The braces are needed only if there are two and more, for example: `{foo,bar}`"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigEncoding",
                "shortDescription": {
                  "text": "File encoding doesn't match EditorConfig charset"
                },
                "fullDescription": {
                  "text": "Checks that current file encoding matches the encoding defined in \"charset\" property of .editorconfig file.",
                  "markdown": "Checks that current file encoding matches the encoding defined in \"charset\" property of .editorconfig file."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigSpaceInHeader",
                "shortDescription": {
                  "text": "Space in file pattern"
                },
                "fullDescription": {
                  "text": "Reports space characters in wildcard patterns that affect pattern matching. If these characters are not intentional, they should be removed.",
                  "markdown": "Reports space characters in wildcard patterns that affect pattern matching. If these characters are not intentional, they should be removed."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigOptionRedundancy",
                "shortDescription": {
                  "text": "Redundant property"
                },
                "fullDescription": {
                  "text": "Reports properties that are redundant when another applicable section already contains the same property and value. For example: '[*]\nindent_size=4\n[*.java]\nindent_size=4' are both applicable to '*.java' files and define the same 'indent_size' value.",
                  "markdown": "Reports properties that are redundant when another applicable section already contains the same property and value.\n\n\nFor example:\n\n\n    [*]\n    indent_size=4\n    [*.java]\n    indent_size=4\n\nare both applicable to `*.java` files and define the same `indent_size` value."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigRootDeclarationCorrectness",
                "shortDescription": {
                  "text": "Unexpected top-level declaration"
                },
                "fullDescription": {
                  "text": "Reports unexpected top-level declarations. Top-level declarations other than “root=true” are not allowed in the EditorConfig file.",
                  "markdown": "Reports unexpected top-level declarations. Top-level declarations other than \"root=true\" are not allowed in the EditorConfig file."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigReferenceCorrectness",
                "shortDescription": {
                  "text": "Invalid reference"
                },
                "fullDescription": {
                  "text": "Reports identifiers that are either unknown or have a wrong type.",
                  "markdown": "Reports identifiers that are either unknown or have a wrong type."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigUnusedDeclaration",
                "shortDescription": {
                  "text": "Unused declaration"
                },
                "fullDescription": {
                  "text": "Reports unused declarations. Such declarations can be removed.",
                  "markdown": "Reports unused declarations. Such declarations can be removed."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigPairAcceptability",
                "shortDescription": {
                  "text": "Unexpected key-value pair"
                },
                "fullDescription": {
                  "text": "Reports key-value pairs that are not allowed in the current context.",
                  "markdown": "Reports key-value pairs that are not allowed in the current context."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigPatternRedundancy",
                "shortDescription": {
                  "text": "Duplicate or redundant pattern"
                },
                "fullDescription": {
                  "text": "Reports file patterns that are redundant as there already are other patterns that define the same scope of files or even a broader one. For example, in '[{*.java,*}]' the first '*.java' pattern defines a narrower scope compared to '*'. That is why it is redundant and can be removed.",
                  "markdown": "Reports file patterns that are redundant as there already are other patterns that define the same scope of files or even a broader one. For example, in `[{*.java,*}]` the first `*.java` pattern defines a narrower scope compared to `*`. That is why it is redundant and can be removed."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigNoMatchingFiles",
                "shortDescription": {
                  "text": "No matching files"
                },
                "fullDescription": {
                  "text": "Reports sections with wildcard patterns that do not match any files under the directory in which the '.editorconfig' file is located.",
                  "markdown": "Reports sections with wildcard patterns that do not match any files under the directory in which the `.editorconfig` file is located."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EditorConfigUnexpectedComma",
                "shortDescription": {
                  "text": "Unexpected comma"
                },
                "fullDescription": {
                  "text": "Reports commas that cannot be used in the current context. Commas are allowed only as separators for values in lists.",
                  "markdown": "Reports commas that cannot be used in the current context. Commas are allowed only as separators for values in lists."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "EditorConfig",
                      "index": 0,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          },
          {
            "name": "Pythonid",
            "version": "223.8782",
            "rules": [
              {
                "id": "JupyterPackageInspection",
                "shortDescription": {
                  "text": "The 'jupyter' package is not installed"
                },
                "fullDescription": {
                  "text": "Reports cases when the 'jupyter' package is not installed for the selected Python interpreter. Without a properly installed 'jupyter' package, you cannot execute Jupyter notebooks. Click the corresponding link on the warning banner to install the missing package. You can also install the package in the Project Settings/Preferences or in the Python Packages tool window. See Installing Python package for more details.",
                  "markdown": "Reports cases when the `jupyter` package is not installed for the selected\nPython interpreter. Without a properly installed `jupyter` package, you cannot\nexecute Jupyter notebooks.\n\nClick the corresponding link on the warning banner to install the missing\npackage. You can also install the package in the Project **Settings/Preferences** or in the\n**Python Packages** tool window.\n\nSee [Installing Python package](https://www.jetbrains.com/help/pycharm/installing-uninstalling-and-upgrading-packages.html) for more details."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Jupyter",
                      "index": 1,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PySetFunctionToLiteralInspection",
                "shortDescription": {
                  "text": "Function call can be replaced with set literal"
                },
                "fullDescription": {
                  "text": "Reports calls to the 'set' function that can be replaced with the 'set' literal. Example: def do_mult(a, b):\n    c = a * b\n    return set([c, a, b])\n When the quick-fix is applied, the code changes to: def do_mult(a, b):\n    c = a * b\n    return {c, a, b}",
                  "markdown": "Reports calls to the `set` function that can be replaced with\nthe `set` literal.\n\n**Example:**\n\n```\ndef do_mult(a, b):\n    c = a * b\n    return set([c, a, b])\n```\n\nWhen the quick-fix is applied, the code changes to:\n\n```\ndef do_mult(a, b):\n    c = a * b\n    return {c, a, b}\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyStatementEffectInspection",
                "shortDescription": {
                  "text": "Statement has no effect"
                },
                "fullDescription": {
                  "text": "Reports statements that have no effect. Example: class Car:\n    def __init__(self, speed=0):\n        self.speed = speed\n        self.time # has no effect\n\n2 + 3 # has no effect\n In this example, you can either add a field 'time' to the 'Car' class or introduce variables for the problematic statements.",
                  "markdown": "Reports statements that have no effect.\n\n**Example:**\n\n```\nclass Car:\n    def __init__(self, speed=0):\n        self.speed = speed\n        self.time # has no effect\n\n2 + 3 # has no effect\n```\n\nIn this example, you can either add a field `time` to the `Car` class or\nintroduce variables for the problematic statements."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "Query_index_required",
                "shortDescription": {
                  "text": "Query does not have the required index"
                },
                "fullDescription": {
                  "text": "Reports GQL queries for which an index is not defined in 'index.yaml'. Such queries will fail on the production server. The quick-fix allows you to add the necessary index definitions.",
                  "markdown": "Reports GQL queries for which an index is not defined in `index.yaml`.\nSuch queries will fail on the production server.\nThe quick-fix allows you to add the necessary index definitions."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Google App Engine (Python)",
                      "index": 4,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyMandatoryEncodingInspection",
                "shortDescription": {
                  "text": "No encoding specified for file"
                },
                "fullDescription": {
                  "text": "Reports a missing encoding comment in Python 2. Example: class Book(object):\n    def __init__(self):\n        pass\n When the quick-fix is applied, the missing comment is added: # coding=utf-8\nclass Book(object):\n    def __init__(self):\n        pass",
                  "markdown": "Reports a missing encoding comment in Python 2.\n\n**Example:**\n\n```\nclass Book(object):\n    def __init__(self):\n        pass\n```\n\nWhen the quick-fix is applied, the missing comment is added:\n\n```\n# coding=utf-8\nclass Book(object):\n    def __init__(self):\n        pass\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyInconsistentIndentationInspection",
                "shortDescription": {
                  "text": "Inconsistent indentation"
                },
                "fullDescription": {
                  "text": "Reports inconsistent indentation in Python source files when, for example, you use a mixture of tabs and spaces in your code.",
                  "markdown": "Reports inconsistent indentation in Python source files when, for example,\nyou use a mixture of tabs and spaces in your code."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyAttributeOutsideInitInspection",
                "shortDescription": {
                  "text": "An instance attribute is defined outside `__init__`"
                },
                "fullDescription": {
                  "text": "Reports a problem when instance attribute definition is outside '__init__' method. Example:     class Book:\n    def __init__(self):\n        self.author = 'Mark Twain'\n\n    def release(self):\n        self.year = '1889'\n When the quick-fix is applied, the code sample changes to:     class Book:\n    def __init__(self):\n        self.year = '1889'\n        self.author = 'Mark Twain'\n\n    def release(self):\n        pass",
                  "markdown": "Reports a problem when instance attribute definition is outside `__init__` method.\n\n**Example:**\n\n```\n    class Book:\n    def __init__(self):\n        self.author = 'Mark Twain'\n\n    def release(self):\n        self.year = '1889'\n```\n\n\nWhen the quick-fix is applied, the code sample changes to:\n\n```\n    class Book:\n    def __init__(self):\n        self.year = '1889'\n        self.author = 'Mark Twain'\n\n    def release(self):\n        pass\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyTypedDictInspection",
                "shortDescription": {
                  "text": "Invalid TypedDict definition and usages"
                },
                "fullDescription": {
                  "text": "Reports invalid definition and usage of TypedDict. Example: from typing import TypedDict\n\n\nclass Movie(TypedDict):\n    name: str\n    year: int\n    rate: int = 10  # Right-hand side values are not supported\n\n    def method(self): # Invalid statement in TypedDict\n        pass\n\n\nm = Movie(name=\"name\", year=1000, rate=9)\nprint(m[\"director\"])  # There is no the 'director' key in 'Movie'\ndel m[\"name\"]  # The 'name' key cannot be deleted\nm[\"year\"] = \"1001\"  # Expected 'int', got 'str'",
                  "markdown": "Reports invalid definition and usage of\n[TypedDict](https://www.python.org/dev/peps/pep-0589/).\n\n**Example:**\n\n```\nfrom typing import TypedDict\n\n\nclass Movie(TypedDict):\n    name: str\n    year: int\n    rate: int = 10  # Right-hand side values are not supported\n\n    def method(self): # Invalid statement in TypedDict\n        pass\n\n\nm = Movie(name=\"name\", year=1000, rate=9)\nprint(m[\"director\"])  # There is no the 'director' key in 'Movie'\ndel m[\"name\"]  # The 'name' key cannot be deleted\nm[\"year\"] = \"1001\"  # Expected 'int', got 'str'\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyPep8Inspection",
                "shortDescription": {
                  "text": "PEP 8 coding style violation"
                },
                "fullDescription": {
                  "text": "Reports violations of the PEP 8 coding style guide by running the bundled pycodestyle.py tool.",
                  "markdown": "Reports violations of the [PEP 8 coding style guide](https://www.python.org/dev/peps/pep-0008/) by running the bundled [pycodestyle.py](https://github.com/PyCQA/pycodestyle) tool."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyMissingTypeHintsInspection",
                "shortDescription": {
                  "text": "Missing type hinting for function definition"
                },
                "fullDescription": {
                  "text": "Reports missing type hints for function declaration in one of the two formats: parameter annotations or a type comment. Select the Only when types are known checkbox if you want the inspection check the types collected from runtime or inferred.",
                  "markdown": "Reports missing type hints for function declaration in\none of the two formats: parameter annotations or a type comment.\n\nSelect the **Only when types are known** checkbox if you want the inspection check\nthe types collected from runtime or inferred."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyTupleItemAssignmentInspection",
                "shortDescription": {
                  "text": "Tuple item assignment is prohibited"
                },
                "fullDescription": {
                  "text": "Reports assignments to a tuple item. t = ('red', 'blue', 'green', 'white')\nt[3] = 'black'\n A quick-fix offers to replace the tuple with a list.",
                  "markdown": "Reports assignments to a tuple item.\n\n```\nt = ('red', 'blue', 'green', 'white')\nt[3] = 'black'\n```\n\nA quick-fix offers to replace the tuple with a list."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DjangoUnresolvedUrlInspection",
                "shortDescription": {
                  "text": "Django {% url %} tag arguments are unresolved"
                },
                "fullDescription": {
                  "text": "Reports a missing url in the 'url' tag. Example: {% url 'url_name' %}\n The IDE shows a warning if 'url_name' is not defined in the 'urls' file.",
                  "markdown": "Reports a missing url in the `url` tag.\n\n**Example:**\n\n```\n{% url 'url_name' %}\n```\n\nThe IDE shows a warning if `url_name` is not defined in the `urls` file."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DjangoUnresolvedStaticReferenceInspection",
                "shortDescription": {
                  "text": "Unresolved static reference"
                },
                "fullDescription": {
                  "text": "Reports unresolved references to static resources. Example: {% load staticfiles %}\n<link rel=\"stylesheet\" type=\"text/css\" href=\"{% static 'polls/style.css' %}\" />\n In this example, 'style.css' is highlighted if there is no such a file in the 'static/poll' directory.",
                  "markdown": "Reports unresolved references to static resources.\n\n**Example:**\n\n```\n{% load staticfiles %}\n<link rel=\"stylesheet\" type=\"text/css\" href=\"{% static 'polls/style.css' %}\" />\n```\n\nIn this example, `style.css` is highlighted if there is no such a file in the `static/poll`\ndirectory."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyInitNewSignatureInspection",
                "shortDescription": {
                  "text": "Incompatible signatures of __new__ and __init__"
                },
                "fullDescription": {
                  "text": "Reports incompatible signatures of the '__new__' and '__init__' methods. Example: class MyClass(object):\n    def __new__(cls, arg1):\n        return super().__new__(cls)\n\n    def __init__(self):\n        pass\n If the '__new__' and '__init__' have different arguments, then the 'MyClass' cannot be instantiated. As a fix, the IDE offers to apply the Change Signature refactoring.",
                  "markdown": "Reports incompatible signatures of the `__new__` and `__init__` methods.\n\n**Example:**\n\n```\nclass MyClass(object):\n    def __new__(cls, arg1):\n        return super().__new__(cls)\n\n    def __init__(self):\n        pass\n```\n\nIf the `__new__` and `__init__` have different arguments, then the `MyClass`\ncannot be instantiated.\n\nAs a fix, the IDE offers to apply the Change Signature refactoring."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyDunderSlotsInspection",
                "shortDescription": {
                  "text": "Invalid usages of classes with  '__slots__' definitions"
                },
                "fullDescription": {
                  "text": "Reports invalid usages of a class with '__slots__' definitions. Example: class Foo:\n    __slots__ = ['foo', 'bar']\n\n\nfoo = Foo()\nfoo.baz = 'spam'",
                  "markdown": "Reports invalid usages of a class with `__slots__` definitions.\n\n**Example:**\n\n```\nclass Foo:\n    __slots__ = ['foo', 'bar']\n\n\nfoo = Foo()\nfoo.baz = 'spam'\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EndBlockNamesInspection",
                "shortDescription": {
                  "text": "Django endblock name doesn't match the block name"
                },
                "fullDescription": {
                  "text": "Reports incorrect names of the closing blocks. Example:   {% block my_block %}\n  {% endblock not_correct %}",
                  "markdown": "Reports incorrect names of the closing blocks.\n\n**Example:**\n\n```\n  {% block my_block %}\n  {% endblock not_correct %}\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyDefaultArgumentInspection",
                "shortDescription": {
                  "text": "The default argument is mutable"
                },
                "fullDescription": {
                  "text": "Reports a problem when a mutable value as a list or dictionary is detected in a default value for an argument. Default argument values are evaluated only once at function definition time, which means that modifying the default value of the argument will affect all subsequent calls of that function. Example: def func(s, cache={}):\n    cache[s] = None\n When the quick-fix is applied, the code changes to: def func(s, cache=None):\n    if cache is None:\n        cache = {}\n    cache[s] = None",
                  "markdown": "Reports a problem when a mutable value as a list or dictionary is detected in a default value for\nan argument.   \n\nDefault argument values are evaluated only once at function definition time,\nwhich means that modifying the\ndefault value of the argument will affect all subsequent calls of that function.\n\n**Example:**\n\n```\ndef func(s, cache={}):\n    cache[s] = None\n```\n\nWhen the quick-fix is applied, the code changes to:\n\n```\ndef func(s, cache=None):\n    if cache is None:\n        cache = {}\n    cache[s] = None\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyMissingConstructorInspection",
                "shortDescription": {
                  "text": "Missed call to '__init__' of the super class"
                },
                "fullDescription": {
                  "text": "Reports cases when a call to the 'super' constructor in a class is missed. Example: class Fruit:\n    def __init__(self):\n        pass\n\n\nclass Pear(Fruit):\n    def __init__(self):\n        pass\n The 'Pear' class should have a 'super' call in the '__init__' method. When the quick-fix is applied, the code changes to: class Fruit:\n    def __init__(self):\n        pass\n\n\nclass Pear(Fruit):\n    def __init__(self):\n        super().__init__()",
                  "markdown": "Reports cases when a call to the `super` constructor in a class is missed.\n\n**Example:**\n\n```\nclass Fruit:\n    def __init__(self):\n        pass\n\n\nclass Pear(Fruit):\n    def __init__(self):\n        pass\n```\n\nThe `Pear` class should have a `super` call in the `__init__`\nmethod.\n\nWhen the quick-fix is applied, the code changes to:\n\n```\nclass Fruit:\n    def __init__(self):\n        pass\n\n\nclass Pear(Fruit):\n    def __init__(self):\n        super().__init__()\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyShadowingBuiltinsInspection",
                "shortDescription": {
                  "text": "Shadowing built-in names"
                },
                "fullDescription": {
                  "text": "Reports shadowing built-in names, such as 'len' or 'list'. Example: def len(a, b, c):\n    d = a + b + c\n    return d\n In this code fragment, the 'len' built-in name is used. The IDE offers to apply the Rename refactoring as a fix.",
                  "markdown": "Reports shadowing built-in names, such as `len` or `list`.\n\n**Example:**\n\n```\ndef len(a, b, c):\n    d = a + b + c\n    return d\n```\n\nIn this code fragment, the `len` built-in name is used. The IDE offers to\napply the Rename refactoring as a fix."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PySimplifyBooleanCheckInspection",
                "shortDescription": {
                  "text": "Redundant boolean variable check"
                },
                "fullDescription": {
                  "text": "Reports equality comparison with a boolean literal. Example: def func(s):\n    if s.isdigit() == True:\n        return int(s)\n With the quick-fix applied, the code fragment will be simplified to: def func(s):\n    if s.isdigit():\n        return int(s)",
                  "markdown": "Reports equality comparison with a boolean literal.\n\n**Example:**\n\n```\ndef func(s):\n    if s.isdigit() == True:\n        return int(s)\n```\n\nWith the quick-fix applied, the code fragment will be simplified to:\n\n```\ndef func(s):\n    if s.isdigit():\n        return int(s)\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyMethodOverridingInspection",
                "shortDescription": {
                  "text": "Method signature does not match signature of overridden method"
                },
                "fullDescription": {
                  "text": "Reports inconsistencies in overriding method signatures. Example: class Book:\n    def add_title(self):\n        pass\n\n\nclass Novel(Book):\n    def add_title(self, text):\n        pass\n Parameters of the 'add_title' method in the 'Novel' class do not match the method signature specified in the 'Book' class. As a fix, the IDE offers to apply the Change Signature refactoring.",
                  "markdown": "Reports inconsistencies in overriding method signatures.\n\n**Example:**\n\n```\nclass Book:\n    def add_title(self):\n        pass\n\n\nclass Novel(Book):\n    def add_title(self, text):\n        pass\n```\n\nParameters of the `add_title` method in the `Novel` class do not match the method\nsignature specified in the `Book` class. As a fix, the IDE offers to apply the Change Signature\nrefactoring."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyTestParametrizedInspection",
                "shortDescription": {
                  "text": "Incorrect arguments in @pytest.mark.parametrize"
                },
                "fullDescription": {
                  "text": "Reports functions that are decorated with @pytest.mark.parametrize but do not have arguments to accept parameters of the decorator.",
                  "markdown": "Reports functions that are decorated with [@pytest.mark.parametrize](https://docs.pytest.org/en/stable/parametrize.html) but do not have arguments to accept\nparameters of the decorator."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyDecoratorInspection",
                "shortDescription": {
                  "text": "Class-specific decorator is used outside the class"
                },
                "fullDescription": {
                  "text": "Reports usages of '@classmethod' or '@staticmethod' decorators in methods outside a class. Example: class State(object):\n\n    @classmethod\n    def my_state(cls, name):\n        cls.name = name\n\n\n@classmethod\ndef change_state(self):\n    pass\n The 'change_state' method should not use the '@classmethod' decorator or it should be moved to the 'State' class declaration. If you apply the 'Remove decorator' action, the code changes to: class State(object):\n\n    @classmethod\n    def my_state(cls, name):\n        cls.name = name\n\n\ndef change_state(self):\n    pass",
                  "markdown": "Reports usages of `@classmethod` or `@staticmethod` decorators\nin methods outside a class.\n\n**Example:**\n\n```\nclass State(object):\n\n    @classmethod\n    def my_state(cls, name):\n        cls.name = name\n\n\n@classmethod\ndef change_state(self):\n    pass\n```\n\nThe `change_state` method should not use the `@classmethod` decorator or it should be\nmoved to the `State` class declaration.\n\nIf you apply the `Remove decorator` action, the code changes to:\n\n```\nclass State(object):\n\n    @classmethod\n    def my_state(cls, name):\n        cls.name = name\n\n\ndef change_state(self):\n    pass\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyAsyncCallInspection",
                "shortDescription": {
                  "text": "Missing `await` syntax in coroutine calls"
                },
                "fullDescription": {
                  "text": "Reports coroutines that were called without using the 'await' syntax. Example: async def bar():\n    pass\n\n\nasync def foo():\n    bar()\n After the quick-fix is applied, the code changes to: async def bar():\n    pass\n\n\nasync def foo():\n    await bar()",
                  "markdown": "Reports coroutines that were called\nwithout using the `await` syntax.\n\n**Example:**\n\n```\nasync def bar():\n    pass\n\n\nasync def foo():\n    bar()\n```\n\nAfter the quick-fix is applied, the code changes to:\n\n```\nasync def bar():\n    pass\n\n\nasync def foo():\n    await bar()\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyComparisonWithNoneInspection",
                "shortDescription": {
                  "text": "Using equality operators to compare with None"
                },
                "fullDescription": {
                  "text": "Reports comparisons with 'None'. That type of comparisons should always be done with 'is' or 'is not', never the equality operators. Example: a = 2\n\n\nif a == None:\n    print(\"Success\")\n Once the quick-fix is applied, the code changes to: a = 2\n\n\nif a is None:\n    print(\"Success\")",
                  "markdown": "Reports comparisons with `None`. That type of comparisons\nshould always be done with `is` or `is not`, never\nthe equality operators.\n\n**Example:**\n\n```\na = 2\n\n\nif a == None:\n    print(\"Success\")\n```\n\nOnce the quick-fix is applied, the code changes to:\n\n```\na = 2\n\n\nif a is None:\n    print(\"Success\")\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CommandLineInspection",
                "shortDescription": {
                  "text": "Incorrect CLI syntax"
                },
                "fullDescription": {
                  "text": "Reports the problems if the arguments of the command you type in the console are not in the proper order. The inspection also verifies that option names and arguments are correct. Do not disable the inspection if you are going to use command-line interfaces like manage.py in Django.",
                  "markdown": "Reports the problems if the arguments of the command you type in the console are not in the proper order. The inspection also verifies\nthat option names and arguments are correct.\n\nDo not disable the inspection if you are going to use command-line interfaces like [manage.py in Django](https://www.jetbrains.com/help/pycharm/running-manage-py.html)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyCallingNonCallableInspection",
                "shortDescription": {
                  "text": "Attempt to call a non-callable object"
                },
                "fullDescription": {
                  "text": "Reports a problem when you are trying to call objects that are not callable, like, for example, properties: class Record:\n    @property\n    def as_json(self):\n\njson = Record().as_json()",
                  "markdown": "Reports a problem when you are trying\nto call objects that are not callable, like, for example, properties:\n\n```\nclass Record:\n    @property\n    def as_json(self):\n\njson = Record().as_json()\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyUnreachableCodeInspection",
                "shortDescription": {
                  "text": "Unreachable code"
                },
                "fullDescription": {
                  "text": "Reports code fragments that cannot be normally reached. Example: if True:\n    print('Yes')\nelse:\n    print('No')\n As a fix, you might want to check and modify the algorithm to ensure it implements the expected logic.",
                  "markdown": "Reports code fragments that cannot be normally reached.\n\n**Example:**\n\n```\nif True:\n    print('Yes')\nelse:\n    print('No')\n```\n\nAs a fix, you might want to check and modify the algorithm to ensure it implements\nthe expected logic."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyChainedComparisonsInspection",
                "shortDescription": {
                  "text": "Too complex chained comparisons"
                },
                "fullDescription": {
                  "text": "Reports chained comparisons that can be simplified. Example: 'def do_comparison(x):\n      xmin = 10\n      xmax = 100\n      if x >= xmin and x <= xmax:\n          pass' The IDE offers to simplify 'if x >= xmin and x <= xmax'. When the quick-fix is applied, the code changes to: 'def do_comparison(x):\n      xmin = 10\n      xmax = 100\n      if xmin <= x <= xmax:\n          pass'",
                  "markdown": "Reports chained comparisons that can be simplified.\n\n**Example:**\n\n\n      def do_comparison(x):\n          xmin = 10\n          xmax = 100\n          if x >= xmin and x <= xmax:\n              pass\n\nThe IDE offers to simplify `if x >= xmin and x <= xmax`.\nWhen the quick-fix is applied, the code changes to:\n\n\n      def do_comparison(x):\n          xmin = 10\n          xmax = 100\n          if xmin <= x <= xmax:\n              pass\n"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyMethodParametersInspection",
                "shortDescription": {
                  "text": "Improper first parameter"
                },
                "fullDescription": {
                  "text": "Reports methods that lack the first parameter that is usually named 'self'. Example: class Movie:\n\n   def show():\n       pass\n When the quick-fix is applied, the code changes to: class Movie:\n\n   def show(self):\n       pass\n The inspection also reports naming issues in class methods. Example: class Movie:\n    @classmethod\n    def show(abc):\n        pass\n Since the first parameter of a class method should be 'cls', the IDE provides a quick-fix to rename it.",
                  "markdown": "Reports methods that lack the first parameter that is usually\nnamed `self`.\n\n**Example:**\n\n```\nclass Movie:\n\n   def show():\n       pass\n```\n\nWhen the quick-fix is applied, the code changes to:\n\n```\nclass Movie:\n\n   def show(self):\n       pass\n```\n\nThe inspection also reports naming issues in class methods.\n\n**Example:**\n\n```\nclass Movie:\n    @classmethod\n    def show(abc):\n        pass\n```\n\nSince the first parameter of a class method should be `cls`, the IDE provides a quick-fix\nto rename it."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyDocstringTypesInspection",
                "shortDescription": {
                  "text": "Type in docstring does not match inferred type"
                },
                "fullDescription": {
                  "text": "Reports types in docstring that do not match dynamically inferred types.",
                  "markdown": "Reports types in docstring that do not match dynamically inferred types."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DjangoBrokenLineCommentInspection",
                "shortDescription": {
                  "text": "Broken line comment"
                },
                "fullDescription": {
                  "text": "Reports '#}' line comment ends in Django templates that do not have a matching line comment start. Example: comment #}\n The IDE highlights '#}' as it requires the corresponding '{#' token.",
                  "markdown": "Reports `#}` line comment ends in Django templates that do not have a\nmatching line comment start.\n\n**Example:**\n\n```\ncomment #}\n```\n\nThe IDE highlights `#}` as it requires the corresponding `{#` token."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyCompatibilityInspection",
                "shortDescription": {
                  "text": "Code is incompatible with specific Python versions"
                },
                "fullDescription": {
                  "text": "Reports incompatibility with the specified versions of Python. Enable this inspection if you need your code to be compatible with a range of Python versions, for example, if you are building a library. To define the range of the inspected Python versions, select the corresponding checkboxes in the Options section. For more information about the Python versions supported by the IDE, see the web help.",
                  "markdown": "Reports incompatibility with the specified versions of Python.\nEnable this inspection if you need your code to be compatible with a range of Python versions, for example,\nif you are building a library.\n\nTo define the range of the inspected Python versions, select the corresponding checkboxes in the **Options**\nsection.\n\nFor more information about the Python versions supported by the IDE, see the\n[web help](https://www.jetbrains.com/help/pycharm/python.html#support)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyGlobalUndefinedInspection",
                "shortDescription": {
                  "text": "Global variable is not defined at the module level"
                },
                "fullDescription": {
                  "text": "Reports problems when a variable defined through the 'global' statement is not defined in the module scope. Example: def foo():\n    global bar\n    print(bar)\n\nfoo()\n As a fix, you can move the global variable declaration: global bar\n\n\ndef foo():\n    print(bar)",
                  "markdown": "Reports problems when a variable defined through the `global`\nstatement is not defined in the module scope.\n\n**Example:**\n\n```\ndef foo():\n    global bar\n    print(bar)\n\nfoo()\n```\n\nAs a fix, you can move the global variable declaration:\n\n```\nglobal bar\n\n\ndef foo():\n    print(bar)\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyMethodFirstArgAssignmentInspection",
                "shortDescription": {
                  "text": "First argument of the method is reassigned"
                },
                "fullDescription": {
                  "text": "Reports cases when the first parameter, such as 'self' or 'cls', is reassigned in a method. Because in most cases, there are no objectives in such reassignment, the IDE indicates an error. Example: class Account:\n    def calc(self, balance):\n        if balance == 0:\n            self = balance\n        return self\n As a fix, you might want to check and modify the algorithm to ensure that reassignment is needed. If everything is correct, you can invoke intention actions for this code and opt to ignore the warning.",
                  "markdown": "Reports cases when the first parameter,\nsuch as `self` or `cls`, is reassigned in a method.\nBecause in most cases, there are no objectives in such reassignment, the\nIDE indicates an error.\n\n**Example:**\n\n```\nclass Account:\n    def calc(self, balance):\n        if balance == 0:\n            self = balance\n        return self\n```\n\nAs a fix, you might want to check and modify the algorithm to ensure that reassignment is needed. If everything is correct,\nyou can invoke intention actions for this code and opt to ignore the warning."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyProtocolInspection",
                "shortDescription": {
                  "text": "Invalid protocol definitions and usages"
                },
                "fullDescription": {
                  "text": "Reports invalid definitions and usages of protocols introduced in PEP-544. Example: from typing import Protocol\n\n\nclass MyProtocol(Protocol):\n    def method(self, p: int) -> str:\n        pass\n\n\nclass MyClass(MyProtocol):\n    def method(self, p: str) -> int: # Type of 'method' is not compatible with 'MyProtocol'\n        pass\n\n\nclass MyAnotherProtocol(MyClass, Protocol): # All bases of a protocol must be protocols\n    pass",
                  "markdown": "Reports invalid definitions and usages of protocols introduced in\n[PEP-544](https://www.python.org/dev/peps/pep-0544/).\n\n**Example:**\n\n```\nfrom typing import Protocol\n\n\nclass MyProtocol(Protocol):\n    def method(self, p: int) -> str:\n        pass\n\n\nclass MyClass(MyProtocol):\n    def method(self, p: str) -> int: # Type of 'method' is not compatible with 'MyProtocol'\n        pass\n\n\nclass MyAnotherProtocol(MyClass, Protocol): # All bases of a protocol must be protocols\n    pass\n\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyTypeHintsInspection",
                "shortDescription": {
                  "text": "Invalid type hints definitions and usages"
                },
                "fullDescription": {
                  "text": "Reports invalid usages of type hints. Example: from typing import TypeVar\n\nT0 = TypeVar('T1') # Argument of 'TypeVar' must be 'T0'\n\n\ndef b(p: int) -> int:  # Type specified both in a comment and annotation\n    # type: (int) -> int\n    pass\n\n\ndef c(p1, p2): # Type signature has too many arguments\n    # type: (int) -> int\n    pass\n Available quick-fixes offer various actions. You can rename, remove, or move problematic elements. You can also manually modify type declarations to ensure no warning is shown.",
                  "markdown": "Reports invalid usages of type hints.\n\n**Example:**\n\n```\nfrom typing import TypeVar\n\nT0 = TypeVar('T1') # Argument of 'TypeVar' must be 'T0'\n\n\ndef b(p: int) -> int:  # Type specified both in a comment and annotation\n    # type: (int) -> int\n    pass\n\n\ndef c(p1, p2): # Type signature has too many arguments\n    # type: (int) -> int\n    pass\n```\n\nAvailable quick-fixes offer various actions. You can rename, remove, or move problematic elements. You can also manually modify type declarations to ensure no warning is shown."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyMethodMayBeStaticInspection",
                "shortDescription": {
                  "text": "Method is not declared static"
                },
                "fullDescription": {
                  "text": "Reports any methods that do not require a class instance creation and can be made static. Example: class MyClass(object):\n    def my_method(self, x):\n        print(x)\n If a Make function from method quick-fix is applied, the code changes to: def my_method(x):\n    print(x)\n\n\nclass MyClass(object):\n    pass\n If you select the Make method static quick-fix, the '@staticmethod' decorator is added: class MyClass(object):\n    @staticmethod\n    def my_method(x):\n        print(x)",
                  "markdown": "Reports any methods that do not require a class instance creation and can be\nmade static.\n\n**Example:**\n\n```\nclass MyClass(object):\n    def my_method(self, x):\n        print(x)\n```\n\nIf a **Make function from method** quick-fix is applied, the code changes to:\n\n```\ndef my_method(x):\n    print(x)\n\n\nclass MyClass(object):\n    pass\n```\n\nIf you select the **Make method static** quick-fix, the `@staticmethod` decorator is added:\n\n```\nclass MyClass(object):\n    @staticmethod\n    def my_method(x):\n        print(x)\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyTupleAssignmentBalanceInspection",
                "shortDescription": {
                  "text": "Tuple assignment balance is incorrect"
                },
                "fullDescription": {
                  "text": "Reports cases when the number of expressions on the right-hand side and targets on the left-hand side are not the same. Example: t = ('red', 'blue', 'green', 'white')\n(c1, c2, c3) = t\n As a quick-fix, you can modify the highlighted code fragment to restore the tuple balance.",
                  "markdown": "Reports cases when the number of expressions on the right-hand side\nand targets on the left-hand side are not the same.\n\n**Example:**\n\n```\nt = ('red', 'blue', 'green', 'white')\n(c1, c2, c3) = t\n```\n\nAs a quick-fix, you can modify the highlighted code fragment to restore the tuple\nbalance."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyClassHasNoInitInspection",
                "shortDescription": {
                  "text": "Class has no `__init__` method"
                },
                "fullDescription": {
                  "text": "Reports cases in Python 2 when a class has no '__init__' method, neither its parent classes. Example: class Book():\n    pass\n The quick-fix adds the '__init__' method: class Book():\n    def __init__(self):\n        pass",
                  "markdown": "Reports cases in Python 2 when a class has no `__init__` method, neither its parent\nclasses.\n\n**Example:**\n\n```\nclass Book():\n    pass\n```\n\nThe quick-fix adds the `__init__` method:\n\n```\nclass Book():\n    def __init__(self):\n        pass\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyArgumentEqualDefaultInspection",
                "shortDescription": {
                  "text": "The function argument is equal to the default parameter value"
                },
                "fullDescription": {
                  "text": "Reports a problem when an argument passed to the function is equal to the default parameter value. This inspection is disabled by default to avoid performance degradation. Example: def my_function(a: int = 2):\n    print(a)\n\n\nmy_function(2)",
                  "markdown": "Reports a problem when an argument\npassed to the function is equal to the default parameter value.\n\nThis inspection is disabled by default to avoid performance degradation.\n\n**Example:**\n\n```\ndef my_function(a: int = 2):\n    print(a)\n\n\nmy_function(2)\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CythonUsageBeforeDeclarationInspection",
                "shortDescription": {
                  "text": "Cython variable is used before its declaration"
                },
                "fullDescription": {
                  "text": "Reports Cython variables being referenced before declaration. Example: cdef int c_x\n\nprint(c_x, c_y)  # Variable 'c_y' is used before its declaration\n\ncdef int c_y = 0",
                  "markdown": "Reports Cython variables being referenced before declaration.\n\n**Example:**\n\n```\ncdef int c_x\n\nprint(c_x, c_y)  # Variable 'c_y' is used before its declaration\n\ncdef int c_y = 0\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyClassVarInspection",
                "shortDescription": {
                  "text": "Invalid usage of ClassVar variables"
                },
                "fullDescription": {
                  "text": "Reports invalid usages of ClassVar annotations. Example: from typing import ClassVar\n\n\nclass Cat:\n    color: ClassVar[str] = \"white\"\n    weight: int\n\n    def __init__(self, weight: int):\n        self.weight = weight\n\n\nCat.color = \"black\"  # OK\nmy_cat = Cat(5)\nmy_cat.color = \"gray\"  # Error, setting class variable on instance",
                  "markdown": "Reports invalid usages of [ClassVar](https://docs.python.org/3/library/typing.html#typing.ClassVar) annotations.\n\n**Example:**\n\n```\nfrom typing import ClassVar\n\n\nclass Cat:\n    color: ClassVar[str] = \"white\"\n    weight: int\n\n    def __init__(self, weight: int):\n        self.weight = weight\n\n\nCat.color = \"black\"  # OK\nmy_cat = Cat(5)\nmy_cat.color = \"gray\"  # Error, setting class variable on instance\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyDictCreationInspection",
                "shortDescription": {
                  "text": "Dictionary creation can be rewritten by dictionary literal"
                },
                "fullDescription": {
                  "text": "Reports situations when you can rewrite dictionary creation by using a dictionary literal. This approach brings performance improvements. Example: dic = {}\ndic['var'] = 1\n When the quick-fix is applied, the code changes to: dic = {'var': 1}",
                  "markdown": "Reports situations when you can rewrite dictionary creation\nby using a dictionary literal.\n\nThis approach brings performance improvements.\n\n**Example:**\n\n```\ndic = {}\ndic['var'] = 1\n```\n\nWhen the quick-fix is applied, the code changes to:\n\n```\ndic = {'var': 1}\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyStringFormatInspection",
                "shortDescription": {
                  "text": "Errors in string formatting operations"
                },
                "fullDescription": {
                  "text": "Reports errors in string formatting operations. Example 1: \"Hello {1}\".format(\"people\")\n Example 2: def bar():\n    return 1\n\n\n\"%s %s\" % bar()\n As a fix, you need to rewrite string formatting fragments to adhere to the formatting syntax.",
                  "markdown": "Reports errors in string formatting operations.\n\n**Example 1:**\n\n```\n\"Hello {1}\".format(\"people\")\n```\n\n**Example 2:**\n\n```\ndef bar():\n    return 1\n\n\n\"%s %s\" % bar()\n```\n\nAs a fix, you need to rewrite string formatting fragments to\nadhere to the [formatting syntax](https://docs.python.org/3/library/string.html#format-string-syntax)."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyExceptionInheritInspection",
                "shortDescription": {
                  "text": "Exceptions do not inherit from standard 'Exception' class"
                },
                "fullDescription": {
                  "text": "Reports cases when a custom exception class is raised but does not inherit from the builtin Exception class. Example: class A:\n    pass\n\n\ndef me_exception():\n    raise A()\n The proposed quick-fix changes the code to: class A(Exception):\n    pass\n\n\ndef me_exception():\n    raise A()",
                  "markdown": "Reports cases when a custom exception class is\nraised but does not inherit from the\n[builtin Exception class](https://docs.python.org/3/library/exceptions.html).\n\n**Example:**\n\n```\nclass A:\n    pass\n\n\ndef me_exception():\n    raise A()\n```\n\nThe proposed quick-fix changes the code to:\n\n```\nclass A(Exception):\n    pass\n\n\ndef me_exception():\n    raise A()\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyAssignmentToLoopOrWithParameterInspection",
                "shortDescription": {
                  "text": "Assignments to 'for' loop or 'with' statement parameter"
                },
                "fullDescription": {
                  "text": "Reports the cases when you rewrite a loop variable with an inner loop:     for i in range(5):\n      for i in range(20, 25):\n          print(\"Inner\", i)\n      print(\"Outer\", i)\n  It also warns you if a variable declared in the 'with' statement is redeclared inside of the statement body:     with open(\"file\") as f:\n      f.read()\n      with open(\"file\") as f:",
                  "markdown": "Reports the cases when you rewrite a loop variable with an inner loop:\n\n```\n    for i in range(5):\n      for i in range(20, 25):\n          print(\"Inner\", i)\n      print(\"Outer\", i)\n  \n```\n\nIt also warns you if a variable declared in the `with` statement is redeclared inside of the statement body:\n\n```\n    with open(\"file\") as f:\n      f.read()\n      with open(\"file\") as f:\n  \n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DjangoUnresolvedFilterInspection",
                "shortDescription": {
                  "text": "Unresolved filter"
                },
                "fullDescription": {
                  "text": "Reports unresolved filters in Django templates. Example:   {{ my_value|cool_filter:\"arg\" }}",
                  "markdown": "Reports unresolved filters in Django templates.\n\n**Example:**\n\n```\n  {{ my_value|cool_filter:\"arg\" }}\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "AppEngineThreadsafeCGIHandlerInspection",
                "shortDescription": {
                  "text": "Threadsafe cannot be enabled with the CGI handler"
                },
                "fullDescription": {
                  "text": "Reports cases when threadsafe is not enabled with the CGI handler.",
                  "markdown": "Reports cases when threadsafe is not enabled with the CGI handler."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Google App Engine (Python)",
                      "index": 4,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DjangoRelationInspection",
                "shortDescription": {
                  "text": "Incorrect comparison expression in Django templates"
                },
                "fullDescription": {
                  "text": "Reports missing whitespaces before and after comparison operators in Django templates. Example: {% if my_var==1 %}\n{% endif %}",
                  "markdown": "Reports missing whitespaces before and after comparison operators in Django templates.\n\n**Example:**\n\n```\n{% if my_var==1 %}\n{% endif %}\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DjangoUnresolvedTagInspection",
                "shortDescription": {
                  "text": "Unresolved tag"
                },
                "fullDescription": {
                  "text": "Reports unresolved tags in Django templates. Example: <h1>{{ question.question_text }}</h1>\n<start>\n The IDE highlights '<start>'. You can either remove the tag or apply the quick-fix to add '<start>' to custom HTML tags.",
                  "markdown": "Reports unresolved tags in Django templates.\n\n**Example:**\n\n```\n<h1>{{ question.question_text }}</h1>\n<start>\n```\n\nThe IDE highlights `<start>`. You can either remove the tag or apply the quick-fix to\nadd `<start>` to custom HTML tags."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyFromFutureImportInspection",
                "shortDescription": {
                  "text": "Improper position of from __future__ import"
                },
                "fullDescription": {
                  "text": "Reports 'from __future__ import' statements that are used not at the beginning of a file. Example: a = 1\nfrom __future__ import print_function\nprint()\n When the quick-fix is applied, the code changes to: from __future__ import print_function\n\na = 1\nprint()",
                  "markdown": "Reports `from __future__ import`\nstatements that are used not at\nthe beginning of a file.\n\n**Example:**\n\n```\na = 1\nfrom __future__ import print_function\nprint()\n```\n\nWhen the quick-fix is applied, the code changes to:\n\n```\nfrom __future__ import print_function\n\na = 1\nprint()\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyUnresolvedReferencesInspection",
                "shortDescription": {
                  "text": "Unresolved references"
                },
                "fullDescription": {
                  "text": "Reports references in your code that cannot be resolved. In a dynamically typed language, this is possible in a limited number of cases. If a reference type is unknown, then its attributes are not highlighted as unresolved even if you know that they should be: def print_string(s):\n  print(s.abc())\n In this code fragment 's' is always a string and 'abc' should be highlighted as unresolved. However, 's' type is inferred as 'Any' and no warning is reported. The IDE provides quick-fix actions to add missing references on-the-fly.",
                  "markdown": "Reports references in your code that cannot be resolved.\n\nIn a dynamically typed language, this is possible in a limited number of cases.\n\nIf a reference type is unknown, then its attributes are not highlighted as unresolved even if you know that they should be:\n\n```\ndef print_string(s):\n  print(s.abc())\n```\n\nIn this code fragment `s` is always a string and `abc` should be highlighted as unresolved. However, `s`\ntype is inferred as `Any` and no warning is reported.\n\nThe IDE provides quick-fix actions to add missing references on-the-fly."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PySuperArgumentsInspection",
                "shortDescription": {
                  "text": "Wrong arguments to call super"
                },
                "fullDescription": {
                  "text": "Reports cases when any call to 'super(A, B)' does not meet the following requirements: 'B' is an instance of 'A' 'B' a subclass of 'A' Example: class Figure:\n    def color(self):\n        pass\n\n\nclass Rectangle(Figure):\n    def color(self):\n        pass\n\n\nclass Square(Figure):\n    def color(self):\n        return super(Rectangle, self).color() # Square is not an instance or subclass of Rectangle\n As a fix, you can make the 'Square' an instance of the 'Rectangle' class.",
                  "markdown": "Reports cases when any call to `super(A, B)` does not meet the\nfollowing requirements:\n\n* `B` is an instance of `A`\n* `B` a subclass of `A`\n\n**Example:**\n\n```\nclass Figure:\n    def color(self):\n        pass\n\n\nclass Rectangle(Figure):\n    def color(self):\n        pass\n\n\nclass Square(Figure):\n    def color(self):\n        return super(Rectangle, self).color() # Square is not an instance or subclass of Rectangle\n```\n\nAs a fix, you can make the `Square` an instance of the `Rectangle` class."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyPackageRequirementsInspection",
                "shortDescription": {
                  "text": "Unsatisfied package requirements"
                },
                "fullDescription": {
                  "text": "Reports packages mentioned in requirements files (for example, 'requirements.txt' or 'Pipfile') but not installed, or imported but not mentioned in requirements files. The IDE shows a quick-fix banner so that you can install the missing packages in one click.",
                  "markdown": "Reports packages mentioned in requirements files (for example, `requirements.txt` or `Pipfile`) but not installed,\nor imported but not mentioned in requirements files.\n\n\nThe IDE shows a quick-fix banner so that you can install the missing packages in one click."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DjangoOrmInspection",
                "shortDescription": {
                  "text": "Django ORM error"
                },
                "fullDescription": {
                  "text": "Reports several methods that may not be called due to some ORM reasons. Example: class Choice:\n    question = ForeignKey(Question, null=False)\n\n\nchoice_set = Question.objects.get(id=1).choice_set.remove()\n The 'remove' function can not be called if the foreign key has 'null=False'.",
                  "markdown": "Reports several methods that may not be called due to some ORM reasons.\n\n**Example:**\n\n```\nclass Choice:\n    question = ForeignKey(Question, null=False)\n\n\nchoice_set = Question.objects.get(id=1).choice_set.remove()\n```\n\nThe `remove` function can not be called if the foreign key has `null=False`."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DjangoUnresolvedTemplateReferenceInspection",
                "shortDescription": {
                  "text": "Unresolved template reference"
                },
                "fullDescription": {
                  "text": "Reports unresolved file references in string literals of 'extends'> and 'include'> Django tags. Example: {% extends \"../DjangoApp/templatetags/base.html\"%}\n In this example, the 'base.html' tag is highlighted, because it is not available in the specified location.",
                  "markdown": "Reports unresolved file references in string literals of\n`extends`\\> and `include`\\> Django tags.\n\n**Example:**\n\n```\n{% extends \"../DjangoApp/templatetags/base.html\"%}\n```\n\nIn this example, the `base.html` tag is highlighted, because it is not available in the\nspecified location."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyNonAsciiCharInspection",
                "shortDescription": {
                  "text": "File contains non-ASCII character"
                },
                "fullDescription": {
                  "text": "Reports cases in Python 2 when a file contains non-ASCII characters and does not have an encoding declaration at the top. Example: class A(object):\n# №5\n    def __init__(self):\n        pass\n In this example, the IDE reports a non-ASCII symbol in a comment and a lack of encoding declaration. Apply the proposed quick-fix to add a missing encoding declaration: # coding=utf-8\nclass A(object)\n# №5\n    def __init__(self):\n        pass",
                  "markdown": "Reports cases in Python 2 when a file contains non-ASCII characters and does not\nhave an encoding declaration at the top.\n\n**Example:**\n\n```\nclass A(object):\n# №5\n    def __init__(self):\n        pass\n```\n\nIn this example, the IDE reports a non-ASCII symbol in a comment and a lack of encoding\ndeclaration. Apply the proposed quick-fix to add a missing encoding declaration:\n\n```\n# coding=utf-8\nclass A(object)\n# №5\n    def __init__(self):\n        pass\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "Restricted_Python_calls",
                "shortDescription": {
                  "text": "Feature is not supported in the App Engine sandbox"
                },
                "fullDescription": {
                  "text": "Reports usages of Python features that are restricted by the Google App Engine sandbox and will cause a failure on the production server.",
                  "markdown": "Reports usages of Python features that are restricted by the Google App\nEngine sandbox and will cause a failure on the production server."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Google App Engine (Python)",
                      "index": 4,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyRedundantParenthesesInspection",
                "shortDescription": {
                  "text": "Redundant parentheses"
                },
                "fullDescription": {
                  "text": "Reports about redundant parentheses in expressions. The IDE provides the quick-fix action to remove the redundant parentheses.",
                  "markdown": "Reports about redundant parentheses in expressions.\n\nThe IDE provides the quick-fix action to remove the redundant parentheses."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyTrailingSemicolonInspection",
                "shortDescription": {
                  "text": "Prohibited trailing semicolon in a statement"
                },
                "fullDescription": {
                  "text": "Reports trailing semicolons in statements. Example: def my_func(a):\n    c = a ** 2;\n    return c\n IDE provides a quick-fix that removes a trailing semicolon. When you apply it, the code changes to: def my_func(a):\n    c = a ** 2\n    return c",
                  "markdown": "Reports trailing semicolons in statements.\n\n**Example:**\n\n```\ndef my_func(a):\n    c = a ** 2;\n    return c\n```\n\nIDE provides a quick-fix that removes a trailing semicolon. When you\napply it, the code changes to:\n\n```\ndef my_func(a):\n    c = a ** 2\n    return c\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyAbstractClassInspection",
                "shortDescription": {
                  "text": "Class must implement all abstract methods"
                },
                "fullDescription": {
                  "text": "Reports cases when not all abstract properties or methods are defined in a subclass. Example: from abc import abstractmethod, ABC\n\n\nclass Figure(ABC):\n\n    @abstractmethod\n    def do_figure(self):\n        pass\n\n\nclass Triangle(Figure):\n    def do_triangle(self):\n        pass\n When the quick-fix is applied, the IDE implements an abstract method for the 'Triangle' class: from abc import abstractmethod, ABC\n\n\nclass Figure(ABC):\n\n    @abstractmethod\n    def do_figure(self):\n        pass\n\n\nclass Triangle(Figure):\n    def do_figure(self):\n        pass\n\n    def do_triangle(self):\n        pass",
                  "markdown": "Reports cases when not all abstract properties or methods are defined in\na subclass.\n\n**Example:**\n\n```\nfrom abc import abstractmethod, ABC\n\n\nclass Figure(ABC):\n\n    @abstractmethod\n    def do_figure(self):\n        pass\n\n\nclass Triangle(Figure):\n    def do_triangle(self):\n        pass\n```\n\nWhen the quick-fix is applied, the IDE implements an abstract method for the `Triangle` class:\n\n```\nfrom abc import abstractmethod, ABC\n\n\nclass Figure(ABC):\n\n    @abstractmethod\n    def do_figure(self):\n        pass\n\n\nclass Triangle(Figure):\n    def do_figure(self):\n        pass\n\n    def do_triangle(self):\n        pass\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyOldStyleClassesInspection",
                "shortDescription": {
                  "text": "Old-style class contains new-style class features"
                },
                "fullDescription": {
                  "text": "Reports occurrences of new-style class features in old-style classes. The inspection highlights '__slots__', '__getattribute__', and 'super()' inside old-style classes.",
                  "markdown": "Reports occurrences of\n[new-style class features](https://www.python.org/doc/newstyle/)\nin old-style classes. The inspection highlights\n`__slots__`, `__getattribute__`, and `super()`\ninside old-style classes."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DjangoIncompatibleInspection",
                "shortDescription": {
                  "text": "Incompatible code in Django templates"
                },
                "fullDescription": {
                  "text": "Reports features that are not available in the current Django version. Example: {% if my_var is True %}\n{% endif %}\n Available since 1.10. The IDE shows warning when discovered in the earlier versions.",
                  "markdown": "Reports features that are not available in the current Django version.\n\n**Example:**\n\n```\n{% if my_var is True %}\n{% endif %}\n```\n\nAvailable since 1.10. The IDE shows warning when discovered in the earlier versions."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "ExtendsTagPositionInspection",
                "shortDescription": {
                  "text": "Misplaced {% extends %} tag"
                },
                "fullDescription": {
                  "text": "Reports the '{% extends %}' tag that is not the first tag in a Django template. Example: {% load my_custom_tags %}\n{% extends \"../DjangoApp/templatetags/my_custom_tags.py\"%}\n In this example, the '{% extends %}' tag is highlighted, because it should be placed before the '{% load %}' tag.",
                  "markdown": "Reports the `{% extends %}` tag that is not the first tag in a\nDjango template.\n\n**Example:**\n\n```\n{% load my_custom_tags %}\n{% extends \"../DjangoApp/templatetags/my_custom_tags.py\"%}\n```\n\nIn this example, the `{% extends %}` tag is highlighted, because it should be placed before\nthe `{% load %}` tag."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "Query_bound_parameters",
                "shortDescription": {
                  "text": "Query does not have required bound parameters"
                },
                "fullDescription": {
                  "text": "Reports GQL queries with bound parameters that don't have the necessary parameters passed to the query method call.",
                  "markdown": "Reports GQL queries with bound parameters that don't have the necessary\nparameters passed to the query method call."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Google App Engine (Python)",
                      "index": 4,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyArgumentListInspection",
                "shortDescription": {
                  "text": "Incorrect call arguments"
                },
                "fullDescription": {
                  "text": "Reports discrepancies between declared parameters and actual arguments, as well as incorrect arguments, for example, duplicate named arguments, and incorrect argument order. Example: class Foo:\n    def __call__(self, p1: int, *, p2: str = \"%\"):\n        return p2 * p1\n\n\nbar = Foo()\nbar.__call__() # unfilled parameter\nbar(5, \"#\") # unexpected argument\n The correct code fragment looks at follows: class Foo:\n    def __call__(self, p1: int, *, p2: str = \"%\"):\n        return p2 * p1\n\n\nbar = Foo()\nbar.__call__(5)\nbar(5, p2=\"#\")",
                  "markdown": "Reports discrepancies between declared parameters and actual arguments, as well as\nincorrect arguments, for example, duplicate named arguments, and incorrect argument order.\n\n**Example:**\n\n```\nclass Foo:\n    def __call__(self, p1: int, *, p2: str = \"%\"):\n        return p2 * p1\n\n\nbar = Foo()\nbar.__call__() # unfilled parameter\nbar(5, \"#\") # unexpected argument\n```\n\nThe correct code fragment looks at follows:\n\n```\nclass Foo:\n    def __call__(self, p1: int, *, p2: str = \"%\"):\n        return p2 * p1\n\n\nbar = Foo()\nbar.__call__(5)\nbar(5, p2=\"#\")\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyInterpreterInspection",
                "shortDescription": {
                  "text": "An invalid interpreter"
                },
                "fullDescription": {
                  "text": "Reports problems if there is no Python interpreter configured for the project or if the interpreter is invalid. Without a properly configured interpreter, you cannot execute your Python scripts and benefit from some Python code insight features. The IDE provides quick access to the interpreter settings.",
                  "markdown": "Reports problems if there is no Python interpreter configured for the project or if the interpreter is invalid. Without a properly\nconfigured interpreter, you cannot execute your Python scripts and benefit from some Python code insight features.\n\nThe IDE provides quick access to the interpreter settings."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyBroadExceptionInspection",
                "shortDescription": {
                  "text": "Unclear exception clauses"
                },
                "fullDescription": {
                  "text": "Reports exception clauses that do not provide specific information about the problem. Example: Clauses that do not specify an exception class Clauses that are specified as 'Exception'",
                  "markdown": "Reports exception clauses that do not provide specific information\nabout the problem.\n\n**Example:**\n\n* Clauses that do not specify an exception class\n* Clauses that are specified as `Exception`"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyTypeCheckerInspection",
                "shortDescription": {
                  "text": "Incorrect type"
                },
                "fullDescription": {
                  "text": "Reports type errors in function call expressions, targets, and return values. In a dynamically typed language, this is possible in a limited number of cases. Types of function parameters can be specified in docstrings or in Python 3 function annotations. Example: def foo() -> int:\n    return \"abc\" # Expected int, got str\n\n\na: str\na = foo() # Expected str, got int\n With the quick-fix, you can modify the problematic types: def foo() -> str:\n    return \"abc\"\n\n\na: str\na = foo()",
                  "markdown": "Reports type errors in function call expressions, targets, and return values. In a dynamically typed language, this is possible in a limited number of cases.\n\nTypes of function parameters can be specified in\ndocstrings or in Python 3 function annotations.\n\n**Example:**\n\n```\ndef foo() -> int:\n    return \"abc\" # Expected int, got str\n\n\na: str\na = foo() # Expected str, got int\n```\n\nWith the quick-fix, you can modify the problematic types:\n\n```\ndef foo() -> str:\n    return \"abc\"\n\n\na: str\na = foo()\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyPropertyAccessInspection",
                "shortDescription": {
                  "text": "Inappropriate access to properties"
                },
                "fullDescription": {
                  "text": "Reports cases when properties are accessed inappropriately: Read-only properties are set Write-only properties are read Non-deletable properties are deleted Example: class MyClass:\n    @property\n    def read_only(self): return None\n\n    def __write_only_setter(self, value): pass\n\n    write_only = property(None, __write_only_setter)\n\n\na = MyClass()\na.read_only = 10 # property cannot be set\ndel a.read_only # property cannot be deleted\nprint(a.write_only) # property cannot be read",
                  "markdown": "Reports cases when properties are accessed inappropriately:\n\n* Read-only properties are set\n* Write-only properties are read\n* Non-deletable properties are deleted\n\n**Example:**\n\n```\nclass MyClass:\n    @property\n    def read_only(self): return None\n\n    def __write_only_setter(self, value): pass\n\n    write_only = property(None, __write_only_setter)\n\n\na = MyClass()\na.read_only = 10 # property cannot be set\ndel a.read_only # property cannot be deleted\nprint(a.write_only) # property cannot be read\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyStubPackagesAdvertiser",
                "shortDescription": {
                  "text": "Stub packages advertiser"
                },
                "fullDescription": {
                  "text": "Reports availability of stub packages. Stub package is a package that contains type information for the corresponding runtime package. Using stub packages ensures better coding assistance for the corresponding python package.",
                  "markdown": "Reports availability of stub packages.\n\n\n[Stub package](https://www.python.org/dev/peps/pep-0561/) is a package that contains type information for the corresponding\nruntime package.\n\nUsing stub packages ensures better coding assistance for the corresponding python package."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyByteLiteralInspection",
                "shortDescription": {
                  "text": "A byte literal contains a non-ASCII character"
                },
                "fullDescription": {
                  "text": "Reports characters in byte literals that are outside ASCII range. Example: 's = b'№5''",
                  "markdown": "Reports characters in byte literals that are outside ASCII range.\n\n**Example:**\n`s = b'№5'`"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyRelativeImportInspection",
                "shortDescription": {
                  "text": "Suspicious relative imports"
                },
                "fullDescription": {
                  "text": "Reports usages of relative imports inside plain directories, for example, directories neither containing '__init__.py' nor explicitly marked as namespace packages.",
                  "markdown": "Reports usages of relative imports inside plain directories, for example, directories neither containing `__init__.py` nor\nexplicitly marked as namespace packages."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyAugmentAssignmentInspection",
                "shortDescription": {
                  "text": "Assignment can be replaced with augmented assignment"
                },
                "fullDescription": {
                  "text": "Reports assignments that can be replaced with augmented assignments. Example: a = 23\nb = 3\na = a + b\n After the quick-fix is applied, the code changes to: a = 23\nb = 3\na += b",
                  "markdown": "Reports assignments that can be replaced with augmented assignments.\n\n**Example:**\n\n```\na = 23\nb = 3\na = a + b\n```\n\nAfter the quick-fix is applied, the code changes to:\n\n```\na = 23\nb = 3\na += b\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyDeprecationInspection",
                "shortDescription": {
                  "text": "Deprecated function, class, or module"
                },
                "fullDescription": {
                  "text": "Reports usages of Python functions, or methods that are marked as deprecated and raise the 'DeprecationWarning' or 'PendingDeprecationWarning' warning. Also, this inspection highlights usages of 'abc.abstractstaticmethod', 'abc.abstractproperty', and 'abc.abstractclassmethod' decorators. Example: class Foo:\n    @property\n    def bar(self):\n        import warnings\n        warnings.warn(\"this is deprecated\", DeprecationWarning, 2)\n        return 5\n\n\nfoo = Foo()\nprint(foo.bar)",
                  "markdown": "Reports usages of Python functions, or methods that are marked as\ndeprecated and raise the `DeprecationWarning` or `PendingDeprecationWarning` warning.\n\nAlso, this inspection highlights usages of `abc.abstractstaticmethod`, `abc.abstractproperty`, and `abc.abstractclassmethod`\ndecorators.\n\n**Example:**\n\n```\nclass Foo:\n    @property\n    def bar(self):\n        import warnings\n        warnings.warn(\"this is deprecated\", DeprecationWarning, 2)\n        return 5\n\n\nfoo = Foo()\nprint(foo.bar)\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyUnnecessaryBackslashInspection",
                "shortDescription": {
                  "text": "Unnecessary backslash"
                },
                "fullDescription": {
                  "text": "Reports backslashes in places where line continuation is implicit inside '()', '[]', and '{}'. Example: a = ('first', \\\n     'second', 'third')\n When the quick-fix is applied, the redundant backslash is deleted.",
                  "markdown": "Reports backslashes in places where line continuation is implicit inside `()`,\n`[]`, and `{}`.\n\n**Example:**\n\n```\na = ('first', \\\n     'second', 'third')\n```\n\nWhen the quick-fix is applied, the redundant backslash is deleted."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyRedeclarationInspection",
                "shortDescription": {
                  "text": "Redeclared names without usages"
                },
                "fullDescription": {
                  "text": "Reports unconditional redeclarations of names without being used in between. Example: def x(): pass\n\n\nx = 2\n It applies to function and class declarations, and top-level assignments. When the warning is shown, you can try a recommended action, for example, you might be prompted to rename the variable.",
                  "markdown": "Reports unconditional redeclarations of names without being used in between.\n\n**Example:**\n\n```\ndef x(): pass\n\n\nx = 2\n```\n\nIt applies to function and class declarations, and top-level assignments.\n\nWhen the warning is shown, you can try a recommended action, for example, you might be prompted to\nrename the variable."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyShadowingNamesInspection",
                "shortDescription": {
                  "text": "Shadowing names from outer scopes"
                },
                "fullDescription": {
                  "text": "Reports shadowing names defined in outer scopes. Example: def outer(p):\n    def inner(p):\n        pass\n As a quick-fix, the IDE offers to remove a parameter or rename it.",
                  "markdown": "Reports shadowing names defined in outer scopes.\n\n**Example:**\n\n```\ndef outer(p):\n    def inner(p):\n        pass\n```\n\nAs a quick-fix, the IDE offers to remove a parameter or rename it."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyFinalInspection",
                "shortDescription": {
                  "text": "Invalid usages of final classes, methods, and variables"
                },
                "fullDescription": {
                  "text": "Reports invalid usages of final classes, methods and variables. Example: from typing import final\n\n\n@final\nclass A:\n    def a_method(self):\n        pass\n\n\nclass B(A):\n    def a_method(self):\n        pass",
                  "markdown": "Reports invalid usages of final classes,\nmethods and variables.\n\n**Example:**\n\n```\nfrom typing import final\n\n\n@final\nclass A:\n    def a_method(self):\n        pass\n\n\nclass B(A):\n    def a_method(self):\n        pass\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyramidSetupInspection",
                "shortDescription": {
                  "text": "Project is not installed for development"
                },
                "fullDescription": {
                  "text": "Reports cases when no 'python setup.py develop' command was executed for the Pyramid project. You need to execute this command to install the newly created project for development.",
                  "markdown": "Reports cases when no `python setup.py develop` command was executed for the Pyramid project.\n\nYou need to execute this command to install the newly created project for development."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Pyramid",
                      "index": 27,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyProtectedMemberInspection",
                "shortDescription": {
                  "text": "Accessing a protected member of a class or a module"
                },
                "fullDescription": {
                  "text": "Reports cases when a protected member is accessed outside the class, a descendant of the class where it is defined, or a module. class Foo:\n    def _protected_method(self):\n        pass\n\n\nclass Bar(Foo):\n    def public_method(self):\n        self._protected_method()\n\n\nfoo = Foo()\nfoo._protected_method() # Access to a protected method",
                  "markdown": "Reports cases when a protected member is accessed outside the class,\na descendant of the class where it is defined, or a module.\n\n```\nclass Foo:\n    def _protected_method(self):\n        pass\n\n\nclass Bar(Foo):\n    def public_method(self):\n        self._protected_method()\n\n\nfoo = Foo()\nfoo._protected_method() # Access to a protected method\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DjangoCloseTagInspection",
                "shortDescription": {
                  "text": "Mismatched opening and closing tags"
                },
                "fullDescription": {
                  "text": "Reports cases when opening tags in Django templates are not correctly matched by closing tags. Example: {% if error_message %}<p><strong>{{ error_message }}</p>{% endif %}\n The IDE reports an error on the 'strong' tag not being closed.",
                  "markdown": "Reports cases when opening tags in Django templates are not correctly matched by closing tags.\n\n**Example:**\n\n```\n{% if error_message %}<p><strong>{{ error_message }}</p>{% endif %}\n```\n\nThe IDE reports an error on the `strong` tag not being closed."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyStubPackagesCompatibilityInspection",
                "shortDescription": {
                  "text": "Incompatible stub packages"
                },
                "fullDescription": {
                  "text": "Reports stub packages that do not support the version of the corresponding runtime package. A stub package contains type information for some runtime package.",
                  "markdown": "Reports stub packages that do not support the version of the corresponding runtime package.\n\nA [stub package](https://www.python.org/dev/peps/pep-0561/) contains type information for some runtime package."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyUnboundLocalVariableInspection",
                "shortDescription": {
                  "text": "Unbound local variables"
                },
                "fullDescription": {
                  "text": "Reports local variables referenced before assignment. Example: x = 0\nif x > 10:\n    b = 3\nprint(b)\n The IDE reports a problem for 'print(b)'. A possible fix is: x = 0\nif x > 10:\n    b = 3\n    print(b)",
                  "markdown": "Reports local variables referenced before assignment.\n\n**Example:**\n\n```\nx = 0\nif x > 10:\n    b = 3\nprint(b)\n```\n\nThe IDE reports a problem for `print(b)`. A possible fix is:\n\n```\nx = 0\nif x > 10:\n    b = 3\n    print(b)\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyNamedTupleInspection",
                "shortDescription": {
                  "text": "Invalid definition of 'typing.NamedTuple'"
                },
                "fullDescription": {
                  "text": "Reports invalid definition of a typing.NamedTuple. Example: import typing\n\n\nclass FullName(typing.NamedTuple):\n    first: str\n    last: str = \"\"\n    middle: str\n As a fix, place the field with the default value after the fields without default values: import typing\n\n\nclass FullName(typing.NamedTuple):\n    first: str\n    middle: str\n    last: str = \"\"",
                  "markdown": "Reports invalid definition of a\n[typing.NamedTuple](https://docs.python.org/3/library/typing.html#typing.NamedTuple).\n\n**Example:**\n\n```\nimport typing\n\n\nclass FullName(typing.NamedTuple):\n    first: str\n    last: str = \"\"\n    middle: str\n```\n\nAs a fix, place the field with the default value after the fields without default values:\n\n```\nimport typing\n\n\nclass FullName(typing.NamedTuple):\n    first: str\n    middle: str\n    last: str = \"\"\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PySingleQuotedDocstringInspection",
                "shortDescription": {
                  "text": "Single quoted docstring"
                },
                "fullDescription": {
                  "text": "Reports docstrings that do not adhere to the triple double-quoted string format. Example: def calc(self, balance=0):\n    'param: balance'\n    self.balance = balance\n When the quick-fix is applied, the code changes to: def calc(self, balance=0):\n    \"\"\"param: balance\"\"\"\n    self.balance = balance",
                  "markdown": "Reports docstrings that do not adhere to the triple double-quoted string format.\n\n**Example:**\n\n```\ndef calc(self, balance=0):\n    'param: balance'\n    self.balance = balance\n```\n\nWhen the quick-fix is applied, the code changes to:\n\n```\ndef calc(self, balance=0):\n    \"\"\"param: balance\"\"\"\n    self.balance = balance\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyUnusedLocalInspection",
                "shortDescription": {
                  "text": "Unused local symbols"
                },
                "fullDescription": {
                  "text": "Reports local variables, parameters, and functions that are locally defined, but not used name in a function.",
                  "markdown": "Reports local variables, parameters, and functions that are locally defined, but not used name in a function."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyReturnFromInitInspection",
                "shortDescription": {
                  "text": "__init__ method that returns a value"
                },
                "fullDescription": {
                  "text": "Reports occurrences of 'return' statements with a return value inside '__init__' methods of classes. Example: class Sum:\n    def __init__(self, a, b):\n        self.a = a\n        self.b = b\n        self.sum = a + b\n        return self.sum\n A constructor should not return any value. The '__init__' method should only initialize the values of instance members for news objects. As a quick-fix, the IDE offers to remove the 'return' statement.",
                  "markdown": "Reports occurrences of `return` statements with a return value inside\n`__init__` methods of classes.\n\n**Example:**\n\n```\nclass Sum:\n    def __init__(self, a, b):\n        self.a = a\n        self.b = b\n        self.sum = a + b\n        return self.sum\n```\n\nA constructor should not return any value. The `__init__` method should\nonly initialize the values of instance members for news objects.\n\nAs a quick-fix, the IDE offers to remove the `return` statement."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyNestedDecoratorsInspection",
                "shortDescription": {
                  "text": "Problematic nesting of decorators"
                },
                "fullDescription": {
                  "text": "Reports problems with nesting decorators. The inspection highlights the cases when 'classmethod' or 'staticmethod' is applied before another decorator. Example: def innocent(f):\n    return f\n\n\nclass A:\n    @innocent  # Decorator will not receive a callable it may expect\n    @classmethod\n    def f2(cls):\n        pass\n\n    @innocent  # Decorator will not receive a callable it may expect\n    @staticmethod\n    def f1():\n        pass\n As a quick-fix, the IDE offers to remove the decorator.",
                  "markdown": "Reports problems with nesting decorators. The inspection highlights the cases when `classmethod` or `staticmethod`\nis applied before another decorator.\n\n**Example:**\n\n```\ndef innocent(f):\n    return f\n\n\nclass A:\n    @innocent  # Decorator will not receive a callable it may expect\n    @classmethod\n    def f2(cls):\n        pass\n\n    @innocent  # Decorator will not receive a callable it may expect\n    @staticmethod\n    def f1():\n        pass\n```\n\nAs a quick-fix, the IDE offers to remove the decorator."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "Query_restricted",
                "shortDescription": {
                  "text": "Query does not comply with the query restrictions"
                },
                "fullDescription": {
                  "text": "Reports GQL queries that do not comply with the restrictions for queries allowed on the Google App Engine server. See the App Engine documentation for more information.",
                  "markdown": "Reports GQL queries that do not comply with the restrictions for queries allowed\non the Google App Engine server.\nSee the [App Engine documentation](http://code.google.com/appengine/docs/python/datastore/queriesandindexes.html#Restrictions_on_Queries) for more information."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Google App Engine (Python)",
                      "index": 4,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyMissingOrEmptyDocstringInspection",
                "shortDescription": {
                  "text": "Missing or empty docstring"
                },
                "fullDescription": {
                  "text": "Reports missing and empty docstrings. Example of a missing docstring def demo(a):\n    c = a ** 2\n Example of an empty docstring def demo(a):\n    \"\"\"\n    \"\"\"\n    c = a ** 2\n When the quick-fix is applied, the code fragments change to: def demo(a):\n    \"\"\"\n\n    :param a:\n    \"\"\"\n    c = a ** 2\n You need to provide some details about the parameter in the generated template.",
                  "markdown": "Reports missing and empty docstrings.\n\n**Example of a missing docstring**\n\n```\ndef demo(a):\n    c = a ** 2\n```\n\n**Example of an empty docstring**\n\n```\ndef demo(a):\n    \"\"\"\n    \"\"\"\n    c = a ** 2\n```\n\nWhen the quick-fix is applied, the code fragments change to:\n\n```\ndef demo(a):\n    \"\"\"\n\n    :param a:\n    \"\"\"\n    c = a ** 2\n```\n\nYou need to provide some details about the parameter in the generated template."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DuplicatedBlockNamesInspection",
                "shortDescription": {
                  "text": "Duplicated block names"
                },
                "fullDescription": {
                  "text": "Reports duplicated block names in Django templates. Example: <!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <link rel=\"stylesheet\" href=\"style.css\">\n    <title>{% block title %}My amazing site{% endblock %}</title>\n</head>\n\n<body>\n    <div id=\"sidebar\">\n        {% block title %}\n        <ul>\n            <li><a href=\"/\">Home</a></li>\n            <li><a href=\"/blog/\">Blog</a></li>\n        </ul>\n        {% endblock %}\n    </div>\n\n    <div id=\"content\">\n        {% block content %}{% endblock %}\n    </div>\n</body>\n</html>",
                  "markdown": "Reports duplicated block names in Django templates.\n\n**Example:**\n\n```\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <link rel=\"stylesheet\" href=\"style.css\">\n    <title>{% block title %}My amazing site{% endblock %}</title>\n</head>\n\n<body>\n    <div id=\"sidebar\">\n        {% block title %}\n        <ul>\n            <li><a href=\"/\">Home</a></li>\n            <li><a href=\"/blog/\">Blog</a></li>\n        </ul>\n        {% endblock %}\n    </div>\n\n    <div id=\"content\">\n        {% block content %}{% endblock %}\n    </div>\n</body>\n</html>\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyOverloadsInspection",
                "shortDescription": {
                  "text": "Overloads in regular Python files"
                },
                "fullDescription": {
                  "text": "Reports cases when overloads in regular Python files are placed after the implementation or when their signatures are not compatible with the implementation. Example: from typing import overload\n\n\n@overload\ndef foo(p1, p2): # Overload signature is not compatible with the implementation\n    pass\n\n\n@overload\ndef foo(p1): # Overload signature is not compatible with the implementation\n    pass\n\n\ndef foo(p1, p2, p3):\n    print(p1, p2, p3)",
                  "markdown": "Reports cases when overloads in regular Python files are placed after the implementation or when their signatures are\nnot compatible with the implementation.\n\n**Example:**\n\n```\nfrom typing import overload\n\n\n@overload\ndef foo(p1, p2): # Overload signature is not compatible with the implementation\n    pass\n\n\n@overload\ndef foo(p1): # Overload signature is not compatible with the implementation\n    pass\n\n\ndef foo(p1, p2, p3):\n    print(p1, p2, p3)\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "AppEngineThreadsafeInspection",
                "shortDescription": {
                  "text": "Threadsafe is not available or set inappropriately"
                },
                "fullDescription": {
                  "text": "Reports cases when threadsafe is not present or it is not set to either 'yes' or 'no'.",
                  "markdown": "Reports cases when threadsafe is not present or it is not set to either `yes` or `no`."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Google App Engine (Python)",
                      "index": 4,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyPep8NamingInspection",
                "shortDescription": {
                  "text": "PEP 8 naming convention violation"
                },
                "fullDescription": {
                  "text": "Reports violations of the PEP8 naming conventions. Example: class mammalia(object):\n    extremities = 4\n\n    def feeds(self):\n        print(\"milk\")\n In this code fragment, IDE offers to rename 'mammalia' to 'Mammalia'. When the quick-fix is applied, the code change to: class Mammalia(object):\n    extremities = 4\n\n    def feeds(self):\n        print(\"milk\")",
                  "markdown": "Reports violations of the\n[PEP8](https://www.python.org/dev/peps/pep-0008/) naming conventions.\n\n**Example:**\n\n```\nclass mammalia(object):\n    extremities = 4\n\n    def feeds(self):\n        print(\"milk\")\n```\n\nIn this code fragment, IDE offers to rename `mammalia` to `Mammalia`.\nWhen the quick-fix is applied, the code change to:\n\n```\nclass Mammalia(object):\n    extremities = 4\n\n    def feeds(self):\n        print(\"milk\")\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DjangoUnresolvedLoadInspection",
                "shortDescription": {
                  "text": "Unresolved library inspection"
                },
                "fullDescription": {
                  "text": "Reports unresolved references in Django load tags. Example:   {% load something_nonexistent %}",
                  "markdown": "Reports unresolved references in Django load tags.\n\n**Example:**\n\n```\n  {% load something_nonexistent %}\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyDictDuplicateKeysInspection",
                "shortDescription": {
                  "text": "Dictionary contains duplicate keys"
                },
                "fullDescription": {
                  "text": "Reports using the same value as the dictionary key twice. Example: dic = {\"a\": [1, 2], \"a\": [3, 4]}",
                  "markdown": "Reports using the same value as the dictionary key twice.\n\n**Example:**\n\n```\ndic = {\"a\": [1, 2], \"a\": [3, 4]}\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyExceptClausesOrderInspection",
                "shortDescription": {
                  "text": "Wrong order of 'except' clauses"
                },
                "fullDescription": {
                  "text": "Reports cases when 'except' clauses are not in the proper order, from the more specific to the more generic, or one exception class is caught twice. If you do not fix the order, some exceptions may not be caught by the most specific handler. Example: try:\n    call()\nexcept ValueError:\n    pass\nexcept UnicodeError:\n    pass\n The IDE recommends moving the clause up. When the quick-fix is applied, the code changes to: try:\n    call()\nexcept UnicodeError:\n    pass\nexcept ValueError:\n    pass",
                  "markdown": "Reports cases when `except` clauses are not in the proper order,\nfrom the more specific to the more generic, or one exception class is caught twice.\n\n\nIf you do not fix the order, some exceptions may not be caught by the most specific handler.\n\n**Example:**\n\n```\ntry:\n    call()\nexcept ValueError:\n    pass\nexcept UnicodeError:\n    pass\n```\n\nThe IDE recommends moving the clause up. When the quick-fix is applied, the code changes to:\n\n```\ntry:\n    call()\nexcept UnicodeError:\n    pass\nexcept ValueError:\n    pass\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyDataclassInspection",
                "shortDescription": {
                  "text": "Invalid definition and usage of Data Classes"
                },
                "fullDescription": {
                  "text": "Reports invalid definitions and usages of classes created with 'dataclasses' or 'attr' modules. Example: import dataclasses\n\n\n@dataclasses.dataclass\nclass FullName:\n    first: str\n    middle: str = \"\"\n    last: str",
                  "markdown": "Reports invalid definitions and usages of classes created with\n`dataclasses` or `attr` modules.\n\n**Example:**\n\n```\nimport dataclasses\n\n\n@dataclasses.dataclass\nclass FullName:\n    first: str\n    middle: str = \"\"\n    last: str\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyClassicStyleClassInspection",
                "shortDescription": {
                  "text": "Classic style class usage"
                },
                "fullDescription": {
                  "text": "Reports classic style classes usage. This inspection applies only to Python 2. Example: class A:\n    pass\n With quick-fixes provided by the IDE, this code fragment changes to: class A(object):\n    def __init__(self):\n        pass",
                  "markdown": "Reports [classic style classes](https://docs.python.org/2/reference/datamodel.html#new-style-and-classic-classes) usage. This inspection applies only to Python 2.\n\n**Example:**\n\n```\nclass A:\n    pass\n```\n\nWith quick-fixes provided by the IDE, this code fragment changes to:\n\n```\nclass A(object):\n    def __init__(self):\n        pass\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DjangoUrlArgumentsInspection",
                "shortDescription": {
                  "text": "Incorrect arguments in the ' {% url %}' tag"
                },
                "fullDescription": {
                  "text": "Reports missing parameters in the template file if the 'url()' function has parameters in its URL path. Example: In the 'url.py' file url(r'^(?P<question_id>[0-9]+)/', views.detail, name='detail')\n In the template file {% url 'polls:detail' %}",
                  "markdown": "Reports missing parameters in the template file if the `url()`\nfunction has parameters in its URL path.\n\n**Example:**\n\nIn the `url.py` file\n\n```\nurl(r'^(?P<question_id>[0-9]+)/', views.detail, name='detail')\n```\n\nIn the template file\n\n```\n{% url 'polls:detail' %}\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Django",
                      "index": 14,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyNoneFunctionAssignmentInspection",
                "shortDescription": {
                  "text": "Assigning function calls that don't return anything"
                },
                "fullDescription": {
                  "text": "Reports cases when an assignment is done on a function that does not return anything. This inspection is similar to pylint inspection E1111. Example: def just_print():\n    print(\"Hello!\")\n\n\naction = just_print()\n As a quick-fix, the IDE offers to remove the assignment.",
                  "markdown": "Reports cases when an assignment is done on a function that does not return anything.\nThis inspection is similar to [pylint inspection E1111](https://docs.pylint.org/en/1.6.0/features.html#id6).\n\n\n**Example:**\n\n```\ndef just_print():\n    print(\"Hello!\")\n\n\naction = just_print()\n```\n\nAs a quick-fix, the IDE offers to remove the assignment."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyPropertyDefinitionInspection",
                "shortDescription": {
                  "text": "Incorrect property definition"
                },
                "fullDescription": {
                  "text": "Reports problems with the arguments of 'property()' and functions annotated with '@property'. class C:\n    @property\n    def abc(self):  # Getter should return or yield something\n        pass\n\n    @abc.setter\n    def foo(self, value):  # Names of function and decorator don't match\n        pass\n\n    @abc.setter\n    def abc(self, v1, v2):  # Setter signature should be (self, value)\n        pass\n\n    @abc.deleter\n    def abc(self, v1):  # Delete signature should be (self)\n        pass\n A quick-fix offers to update parameters.",
                  "markdown": "Reports problems with the arguments of `property()` and functions\nannotated with `@property`.\n\n```\nclass C:\n    @property\n    def abc(self):  # Getter should return or yield something\n        pass\n\n    @abc.setter\n    def foo(self, value):  # Names of function and decorator don't match\n        pass\n\n    @abc.setter\n    def abc(self, v1, v2):  # Setter signature should be (self, value)\n        pass\n\n    @abc.deleter\n    def abc(self, v1):  # Delete signature should be (self)\n        pass\n```\n\nA quick-fix offers to update parameters."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyIncorrectDocstringInspection",
                "shortDescription": {
                  "text": "Incorrect docstring"
                },
                "fullDescription": {
                  "text": "Reports mismatched parameters in a docstring. For example, 'b' is highlighted, because there is no such a parameter in the 'add' function.     def add(a, c):\n    \"\"\"\n    @param a:\n    @param b:\n    @return:\n    \"\"\"\n    pass\n The inspection does not warn you of missing parameters if none of them is mentioned in a docstring: def mult(a, c):\n    \"\"\"\n    @return:\n    \"\"\"\n    pass",
                  "markdown": "Reports mismatched parameters in a docstring. For example, `b` is highlighted, because there is no\nsuch a parameter in the `add` function.\n\n```\n    def add(a, c):\n    \"\"\"\n    @param a:\n    @param b:\n    @return:\n    \"\"\"\n    pass\n```\n\nThe inspection does not warn you of missing parameters if none of them is mentioned in a docstring:\n\n```\ndef mult(a, c):\n    \"\"\"\n    @return:\n    \"\"\"\n    pass\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "PyListCreationInspection",
                "shortDescription": {
                  "text": "Non-optimal list declaration"
                },
                "fullDescription": {
                  "text": "Reports cases when a list declaration can be rewritten with a list literal. This ensures better performance of your application. Example: l = [1]\nl.append(2)\n When the quick-fix is applied, the code changes to: l = [1, 2]",
                  "markdown": "Reports cases when a list declaration\ncan be rewritten with a list literal.\n\nThis ensures better performance of your application.\n\n**Example:**\n\n```\nl = [1]\nl.append(2)\n```\n\nWhen the quick-fix is applied, the code changes to:\n\n```\nl = [1, 2]\n```"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Python",
                      "index": 2,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          },
          {
            "name": "com.intellij.database",
            "version": "223.8782",
            "rules": [
              {
                "id": "PgSelectFromProcedureInspection",
                "shortDescription": {
                  "text": "Postgres: Select from procedure call"
                },
                "fullDescription": {
                  "text": "Reports situations when you make SELECT from a function or a DBLINK without an alias with a type (for example, 'AS t1(s VARCHAR)'). This requirement does not apply to scalar functions. Example (PostgreSQL): 'CREATE FUNCTION produce_a_table() RETURNS RECORD AS $$\nSELECT 1;\n$$ LANGUAGE sql;\nSELECT * FROM produce_a_table() AS s (c1 INT);\nSELECT * FROM produce_a_table() AS s (c1);\nSELECT * FROM DBLINK('dbname=mydb', 'SELECT proname, prosrc FROM pg_proc') AS t1;' The 'AS s (c1 INT)' has a typed alias, while 'AS s (c1)' and 'AS t1' do not. In this case, the second call of 'produce_a_table()' and 'DBLINK()' will be highlighted.",
                  "markdown": "Reports situations when you make SELECT from a function or a DBLINK without an alias with a type (for example, `AS t1(s VARCHAR)`).\n\nThis requirement does not apply to scalar functions.\n\nExample (PostgreSQL):\n\n    CREATE FUNCTION produce_a_table() RETURNS RECORD AS $$\n    SELECT 1;\n    $$ LANGUAGE sql;\n    SELECT * FROM produce_a_table() AS s (c1 INT);\n    SELECT * FROM produce_a_table() AS s (c1);\n    SELECT * FROM DBLINK('dbname=mydb', 'SELECT proname, prosrc FROM pg_proc') AS t1;\n\nThe `AS s (c1 INT)` has a typed alias, while `AS s (c1)` and `AS t1` do not.\nIn this case, the second call of `produce_a_table()` and `DBLINK()` will be highlighted."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "PostgreSQL",
                      "index": 3,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlCurrentSchemaInspection",
                "shortDescription": {
                  "text": "Current console schema introspected"
                },
                "fullDescription": {
                  "text": "Reports schemas and databases in the current session that are not introspected. For example, this warning might occur when you try to create a table in the schema that is not introspected. Introspection is a method of inspecting a data source. When you perform introspection, structural information in the data source is inspected to detect tables, columns, functions, and other elements with their attributes.",
                  "markdown": "Reports schemas and databases in the current session that are not introspected.\n\nFor example, this warning might occur when you try to create a table in the schema that is not introspected.\n\nIntrospection is a method of inspecting a data source. When you perform introspection, structural information in the data source is\ninspected to detect tables, columns, functions, and other elements with their attributes."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlMisleadingReferenceInspection",
                "shortDescription": {
                  "text": "Misleading references"
                },
                "fullDescription": {
                  "text": "Reports ambiguous references in SQL code. For example, when a name refer to both a table column and a routine parameter. The execution of such code might lead to errors or unexpected results due to counter-intuitive resolution logic. Usually, names with a more local scope have higher priority. Example (PostgreSQL): 'CREATE TABLE foo\n(\n    id   INT,\n    name VARCHAR(5)\n);\nCREATE FUNCTION func(name VARCHAR(5)) RETURNS INT AS\n$$\nDECLARE\n    b INT;\nBEGIN\n      -- `name` is ambiguous as it is used as a column name and a parameter\n    SELECT COUNT(*) INTO b FROM foo t WHERE t.name = name;\n    RETURN b;\nEND;\n$$ LANGUAGE plpgsql;' In PostgreSQL, you can use the '#variable_conflict' directives to explicitly specify a correct reference. For example, use '#variable_conflict use_column' to refer to a column name, or '#variable_conflict use_variable' to refer to a parameter. 'CREATE TABLE foo\n(\n    id   INT,\n    name VARCHAR(5)\n);\nCREATE FUNCTION func(name VARCHAR(5)) RETURNS INT AS\n$$\n    #variable_conflict use_column\nDECLARE\n    b INT;\nBEGIN\n    SELECT COUNT(*) INTO b FROM foo t WHERE t.name = name;\n    RETURN b;\nEND;\n$$ LANGUAGE plpgsql;'",
                  "markdown": "Reports ambiguous references in SQL code.\n\nFor example, when a name refer to both a table column and a routine parameter. The execution of such code might lead to errors or unexpected\nresults due to counter-intuitive resolution logic. Usually, names with a more local scope have higher priority.\n\nExample (PostgreSQL):\n\n    CREATE TABLE foo\n    (\n        id   INT,\n        name VARCHAR(5)\n    );\n    CREATE FUNCTION func(name VARCHAR(5)) RETURNS INT AS\n    $$\n    DECLARE\n        b INT;\n    BEGIN\n          -- `name` is ambiguous as it is used as a column name and a parameter\n        SELECT COUNT(*) INTO b FROM foo t WHERE t.name = name;\n        RETURN b;\n    END;\n    $$ LANGUAGE plpgsql;\n\nIn PostgreSQL, you can use the `#variable_conflict` directives to explicitly specify a correct reference. For example,\nuse `#variable_conflict use_column` to refer to a column name, or `#variable_conflict use_variable` to refer to a\nparameter.\n\n    CREATE TABLE foo\n    (\n        id   INT,\n        name VARCHAR(5)\n    );\n    CREATE FUNCTION func(name VARCHAR(5)) RETURNS INT AS\n    $$\n        #variable_conflict use_column\n    DECLARE\n        b INT;\n    BEGIN\n        SELECT COUNT(*) INTO b FROM foo t WHERE t.name = name;\n        RETURN b;\n    END;\n    $$ LANGUAGE plpgsql;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlInsertIntoGeneratedColumnInspection",
                "shortDescription": {
                  "text": "Insertion into generated columns"
                },
                "fullDescription": {
                  "text": "Reports INSERT statements that assign values to generated columns. Generated columns can be read, but their values can not be directly written. Example (PostgreSQL): 'CREATE TABLE foo\n(\n   col1 INT,\n   col2 INT GENERATED ALWAYS AS (col1 + 1) STORED\n);\nINSERT INTO foo(col1, col2) VALUES (1, 2);'\n You cannot insert '2' into the 'col2' column because this column is generated. For this script to work, you can change '2' to DEFAULT. 'INSERT INTO foo(col1, col2) VALUES (1, DEFAULT);'",
                  "markdown": "Reports INSERT statements that assign values to generated columns. Generated columns can be read, but their values can not be directly written.\n\nExample (PostgreSQL):\n\n    CREATE TABLE foo\n    (\n       col1 INT,\n       col2 INT GENERATED ALWAYS AS (col1 + 1) STORED\n    );\n    INSERT INTO foo(col1, col2) VALUES (1, 2);\n\nYou cannot insert `2` into the `col2` column because this column is generated.\nFor this script to work, you can change `2` to DEFAULT.\n`INSERT INTO foo(col1, col2) VALUES (1, DEFAULT);`"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "MongoJSSideEffectsInspection",
                "shortDescription": {
                  "text": "Statement with side effects"
                },
                "fullDescription": {
                  "text": "Reports statements that can cause side effects while the data source is in read-only mode. For more information about enabling read-only mode, see Enable read-only mode for a connection in the IDE documentation. The Disable read-only mode quick-fix turns off the read-only mode for the respective data source. Example: 'db.my_collection.insertOne()'",
                  "markdown": "Reports statements that can cause side effects while the data source is in read-only mode.\n\nFor more information about enabling read-only mode, see\n[Enable\nread-only mode for a connection in the IDE documentation](https://www.jetbrains.com/help/datagrip/configuring-database-connections.html#enable-read-only-mode-for-a-connection).\n\nThe **Disable read-only mode** quick-fix turns off the read-only mode for the respective data source.\n\nExample:\n\n\n    db.my_collection.insertOne()\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "MongoJS",
                      "index": 9,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "MysqlLoadDataPathInspection",
                "shortDescription": {
                  "text": "LOAD statement path"
                },
                "fullDescription": {
                  "text": "Reports paths that start with the tilde character in LOAD statements. Example (MySQL): 'CREATE TABLE table_name (id int);\nLOAD DATA LOCAL INFILE '~/Documents/some_file.txt'\nINTO TABLE table_name FIELDS TERMINATED BY ',' LINES TERMINATED BY '\\n'\nIGNORE 1 LINES;' Instead of the tilde character, use a full path to the file.",
                  "markdown": "Reports paths that start with the tilde character in LOAD statements.\n\nExample (MySQL):\n\n    CREATE TABLE table_name (id int);\n    LOAD DATA LOCAL INFILE '~/Documents/some_file.txt'\n    INTO TABLE table_name FIELDS TERMINATED BY ',' LINES TERMINATED BY '\\n'\n    IGNORE 1 LINES;\n\nInstead of the tilde character, use a full path to the file."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "MySQL",
                      "index": 12,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlRedundantLimitInspection",
                "shortDescription": {
                  "text": "Redundant row limiting in queries"
                },
                "fullDescription": {
                  "text": "Reports redundant row limiting clauses like FETCH and LIMIT in queries. Example (PostgreSQL): 'CREATE TABLE foo(a INT);\n\nSELECT * FROM foo WHERE EXISTS(SELECT * FROM foo LIMIT 2);\nSELECT * FROM foo WHERE EXISTS(SELECT * FROM foo FETCH FIRST 2 ROWS ONLY);' To fix the warning, you can add OFFSET to limiting clauses. If OFFSET is missing, then LIMIT is redundant because the usage of LIMIT does not influence the operation result of EXISTS. In case with OFFSET, we skip first 'N' rows and this will influence the output. 'SELECT * FROM foo WHERE EXISTS(SELECT * FROM foo OFFSET 1 ROW LIMIT 2);\nSELECT * FROM foo WHERE EXISTS(SELECT * FROM foo OFFSET 1 ROW FETCH FIRST 2 ROWS ONLY);'",
                  "markdown": "Reports redundant row limiting clauses like FETCH and LIMIT in queries.\n\nExample (PostgreSQL):\n\n    CREATE TABLE foo(a INT);\n\n    SELECT * FROM foo WHERE EXISTS(SELECT * FROM foo LIMIT 2);\n    SELECT * FROM foo WHERE EXISTS(SELECT * FROM foo FETCH FIRST 2 ROWS ONLY);\n\nTo fix the warning, you can add OFFSET to limiting clauses. If OFFSET is missing, then LIMIT is redundant because\nthe usage of LIMIT does not influence the operation result of EXISTS. In case with OFFSET, we skip first `N` rows and this will\ninfluence the output.\n\n    SELECT * FROM foo WHERE EXISTS(SELECT * FROM foo OFFSET 1 ROW LIMIT 2);\n    SELECT * FROM foo WHERE EXISTS(SELECT * FROM foo OFFSET 1 ROW FETCH FIRST 2 ROWS ONLY);\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlInsertNullIntoNotNullInspection",
                "shortDescription": {
                  "text": "Insert NULL into NOT NULL column"
                },
                "fullDescription": {
                  "text": "Reports cases when you insert NULL values into columns that accept only NOT NULL values. Example (Microsoft SQL Server): 'CREATE TABLE br2 (\nid INT NOT NULL,\ncol1 NVARCHAR (20) NOT NULL,\ncol2 NVARCHAR (20) NOT NULL,\n);\n--\nINSERT INTO br2 (id, col1, col2)\nVALUES (1, NULL, NULL);' You cannot insert NULL values in 'col1' and 'col2' because they are defined as NOT NULL. If you run the script as is, you will receive an error. To fix this code, replace NULL in the VALUES part with some values (for example, '42' and ''bird''). INSERT INTO br2 (id, col1, col2)\nVALUES (1, 42, 'bird');",
                  "markdown": "Reports cases when you insert NULL values into columns that accept only NOT NULL values.\n\nExample (Microsoft SQL Server):\n\n    CREATE TABLE br2 (\n    id INT NOT NULL,\n    col1 NVARCHAR (20) NOT NULL,\n    col2 NVARCHAR (20) NOT NULL,\n    );\n    --\n    INSERT INTO br2 (id, col1, col2)\n    VALUES (1, NULL, NULL);\n\nYou cannot insert NULL values in `col1` and `col2` because they are defined as NOT NULL. If you run the script as\nis,\nyou will receive an error. To fix this code, replace NULL in the VALUES part with some values (for example, `42` and\n`'bird'`).\n\n```\nINSERT INTO br2 (id, col1, col2)\nVALUES (1, 42, 'bird');\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlDerivedTableAliasInspection",
                "shortDescription": {
                  "text": "Each derived table should have alias"
                },
                "fullDescription": {
                  "text": "Reports derived tables without aliases. Example (MySQL): 'CREATE TABLE table1 (id INT, name VARCHAR(20), cats FLOAT);\nCREATE TABLE table2 (id INT, age INTEGER);\n\nSELECT id AS ID, name, cats, age\nFROM (SELECT table1.id, name, cats, age\nFROM table1\nJOIN table2 ON table1.id = table2.id);' According to Derived Tables at dev.mysql.com, an alias is mandatory. You can add the alias by using the Introduce alias quick-fix. After the quick-fix is applied: 'SELECT id AS ID, name, cats, age\nFROM (SELECT table1.id, name, cats, age\nFROM table1\nJOIN table2 ON table1.id = table2.id);'",
                  "markdown": "Reports derived tables without aliases.\n\nExample (MySQL):\n\n    CREATE TABLE table1 (id INT, name VARCHAR(20), cats FLOAT);\n    CREATE TABLE table2 (id INT, age INTEGER);\n\n    SELECT id AS ID, name, cats, age\n    FROM (SELECT table1.id, name, cats, age\n    FROM table1\n    JOIN table2 ON table1.id = table2.id);\n\nAccording to [Derived Tables at dev.mysql.com](https://dev.mysql.com/doc/refman/8.0/en/derived-tables.html), an alias is\nmandatory. You can add the alias by using the **Introduce alias** quick-fix.\n\nAfter the quick-fix is applied:\n\n    SELECT id AS ID, name, cats, age\n    FROM (SELECT table1.id, name, cats, age\n    FROM table1\n    JOIN table2 ON table1.id = table2.id);\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "MsBuiltinInspection",
                "shortDescription": {
                  "text": "Builtin functions"
                },
                "fullDescription": {
                  "text": "Reports truncations of string arguments in ISNULL functions. The ISNULL syntax is 'ISNULL(check_expression, replacement_value)'. According to ISNULL at docs.microsoft.com, 'replacement_value' will be truncated if 'replacement_value' is longer than 'check_expression'. Example (Microsoft SQL Server): 'DECLARE @name1 VARCHAR(2) = NULL;\nDECLARE @name2 VARCHAR(10) = 'Example';\nDECLARE @name3 VARCHAR(2) = 'Hi';\n\n  -- `@name2` is VARCHAR(10) and will be truncated\nSELECT ISNULL(@name1, @name2);\n\n  -- `@name3` is VARCHAR(2) as `@name1` and will not be truncated\nSELECT ISNULL(@name1, @name3);'",
                  "markdown": "Reports truncations of string arguments in ISNULL functions.\n\nThe ISNULL syntax is `ISNULL(check_expression, replacement_value)`.\n\nAccording to [ISNULL at\ndocs.microsoft.com](https://docs.microsoft.com/en-us/sql/t-sql/functions/isnull-transact-sql), `replacement_value` will be truncated if `replacement_value` is longer than\n`check_expression`.\n\nExample (Microsoft SQL Server):\n\n    DECLARE @name1 VARCHAR(2) = NULL;\n    DECLARE @name2 VARCHAR(10) = 'Example';\n    DECLARE @name3 VARCHAR(2) = 'Hi';\n\n      -- `@name2` is VARCHAR(10) and will be truncated\n    SELECT ISNULL(@name1, @name2);\n\n      -- `@name3` is VARCHAR(2) as `@name1` and will not be truncated\n    SELECT ISNULL(@name1, @name3);\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL server",
                      "index": 19,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlMissingReturnInspection",
                "shortDescription": {
                  "text": "Missing return statement"
                },
                "fullDescription": {
                  "text": "Reports functions that have no RETURN statements. Example (Oracle): 'CREATE FUNCTION foo RETURN int AS\nBEGIN\nEND;' The 'foo' function must return the integer value but the function body returns nothing. To fix the error, add a RETURN statement (for example, 'return 1;'). 'CREATE FUNCTION foo RETURN int AS\nBEGIN\n RETURN 1;\nEND;'",
                  "markdown": "Reports functions that have no RETURN statements.\n\nExample (Oracle):\n\n    CREATE FUNCTION foo RETURN int AS\n    BEGIN\n    END;\n\nThe `foo` function must return the integer value but the function body returns nothing. To fix the error,\nadd a RETURN statement (for example, `return 1;`).\n\n    CREATE FUNCTION foo RETURN int AS\n    BEGIN\n     RETURN 1;\n    END;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlUnusedSubqueryItemInspection",
                "shortDescription": {
                  "text": "Unused subquery item"
                },
                "fullDescription": {
                  "text": "Reports columns, aliases, and other subquery items that are not referenced in the outer query expression. Example (PostgreSQL): 'CREATE TABLE for_subquery(id INT);\nSELECT a, q FROM (SELECT 1 AS a, 10 AS b, 2 + 3 AS q, id\n      FROM for_subquery) x;' We reference 'a' and 'q' aliases from a subquery. But the 'b' alias and the 'id' column are not referenced in the outer SELECT statement. Therefore, 'b' and 'id' are grayed out.",
                  "markdown": "Reports columns, aliases, and other subquery items that are not referenced in the outer query expression.\n\nExample (PostgreSQL):\n\n    CREATE TABLE for_subquery(id INT);\n    SELECT a, q FROM (SELECT 1 AS a, 10 AS b, 2 + 3 AS q, id\n          FROM for_subquery) x;\n\nWe reference `a` and `q` aliases from a subquery. But the `b` alias and the `id` column are\nnot referenced in the outer SELECT statement. Therefore, `b` and `id` are grayed out."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlTriggerTransitionInspection",
                "shortDescription": {
                  "text": "Suspicious code in triggers"
                },
                "fullDescription": {
                  "text": "Reports incorrect usages of transition table variables in triggers. Example (HSQLDB): 'CREATE TABLE foo(a INT);\n\nCREATE TRIGGER trg\n AFTER DELETE ON foo\nBEGIN\n   SELECT * FROM NEW;\nEND;\n\nCREATE TRIGGER trig AFTER INSERT ON foo\n   REFERENCING OLD ROW AS newrow\n   FOR EACH ROW WHEN (a > 1)\n   INSERT INTO foo VALUES (1)' In HSQLDB, DELETE triggers may be used only with the OLD state while INSERT triggers may have only the NEW state. So, in the previous example, NEW in 'SELECT * FROM NEW;' will be highlighted as well as OLD in 'REFERENCING OLD ROW AS newrow'.",
                  "markdown": "Reports incorrect usages of transition table variables in triggers.\n\nExample (HSQLDB):\n\n    CREATE TABLE foo(a INT);\n\n    CREATE TRIGGER trg\n     AFTER DELETE ON foo\n    BEGIN\n       SELECT * FROM NEW;\n    END;\n\n    CREATE TRIGGER trig AFTER INSERT ON foo\n       REFERENCING OLD ROW AS newrow\n       FOR EACH ROW WHEN (a > 1)\n       INSERT INTO foo VALUES (1)\n\nIn HSQLDB, DELETE triggers may be used only with the OLD state while INSERT triggers may have only the NEW state. So, in the previous\nexample, NEW in `SELECT * FROM NEW;` will be highlighted as well as OLD in `REFERENCING OLD ROW AS newrow`."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlMultipleLimitClausesInspection",
                "shortDescription": {
                  "text": "Multiple row limiting/offset clauses in queries"
                },
                "fullDescription": {
                  "text": "Reports usages of multiple row limiting clauses in a single query. Example (Microsoft SQL Server): 'create table foo(a int);\nselect top 1 * from foo order by a offset 10 rows fetch next 20 rows only;' The SELECT TOP clause is used to specify that only 1 record must be returned. The FETCH clause specifies the number of rows to return after the OFFSET clause has been processed. But as we already have the SELECT TOP limiting clause, the FETCH clause might be redundant.",
                  "markdown": "Reports usages of multiple row limiting clauses in a single query.\n\nExample (Microsoft SQL Server):\n\n    create table foo(a int);\n    select top 1 * from foo order by a offset 10 rows fetch next 20 rows only;\n\nThe SELECT TOP clause is used to specify that only 1 record must be\nreturned. The FETCH clause specifies the number of rows to return after the OFFSET\nclause has been processed. But as we already have the SELECT TOP limiting clause, the FETCH clause might be redundant."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlNamedArgumentsInspection",
                "shortDescription": {
                  "text": "Named arguments should be used"
                },
                "fullDescription": {
                  "text": "Reports arguments that are used without names in routine calls. By default, this inspection is disabled. For more information about the difference between named and unnamed parameters, see Binding Parameters by Name (Named Parameters) at docs.microsoft.com . Example (Microsoft SQL Server): 'CREATE FUNCTION foo(n INT, m INT) RETURNS INT AS\nBEGIN\n    RETURN n + m;\nEND;\n\nCREATE PROCEDURE test AS\nBEGIN\n    foo n = 1, m = 2;\n\n--- The following call misses parameter names and will be highlighted\n    foo 1, 2;\nEND;' Parameters '1, 2' in the 'foo 1, 2;' call are highlighted because they miss names.",
                  "markdown": "Reports arguments that are used without names in routine calls. By default, this inspection is disabled.\n\nFor more information about the difference between named and unnamed parameters, see [Binding Parameters by Name (Named Parameters) at docs.microsoft.com](https://docs.microsoft.com/en-us/sql/odbc/reference/develop-app/binding-parameters-by-name-named-parameters).\n\nExample (Microsoft SQL Server):\n\n    CREATE FUNCTION foo(n INT, m INT) RETURNS INT AS\n    BEGIN\n        RETURN n + m;\n    END;\n\n    CREATE PROCEDURE test AS\n    BEGIN\n        foo n = 1, m = 2;\n\n    --- The following call misses parameter names and will be highlighted\n        foo 1, 2;\n    END;\n\nParameters `1, 2` in the `foo 1, 2;` call are highlighted because they miss names."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlCaseVsCoalesceInspection",
                "shortDescription": {
                  "text": "Using CASE instead of COALESCE function and vice versa"
                },
                "fullDescription": {
                  "text": "Reports situations when CASE and COALESCE calls are interchangeable. This inspection has the following intention actions: Replace with 'COALESCE' call and the opposite one Replace with CASE expression. Example (MySQL): 'SELECT\n  -- this CASE may be replaced by COALESCE\n\tCASE\n\t\tWHEN C1 IS NOT NULL THEN C1\n\t\tELSE 0\n\t\tEND\nFROM dual;' In the example, the CASE statement can be replaced with 'SELECT COALESCE(C1, 0)' that produces the same output. If you prefer using CASE expressions, select the Prefer CASE expressions over COALESCE function option on the inspection page.",
                  "markdown": "Reports situations when CASE and COALESCE calls are interchangeable. This inspection has the following intention actions: **Replace\nwith 'COALESCE' call** and the opposite one **Replace with CASE expression** .\n\nExample (MySQL):\n\n    SELECT\n      -- this CASE may be replaced by COALESCE\n    \tCASE\n    \t\tWHEN C1 IS NOT NULL THEN C1\n    \t\tELSE 0\n    \t\tEND\n    FROM dual;\n\nIn the example, the CASE statement can be replaced with `SELECT COALESCE(C1, 0)` that produces the same output.\n\nIf you prefer using CASE expressions, select the **Prefer CASE expressions over COALESCE function** option on\nthe inspection page."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlCaseVsIfInspection",
                "shortDescription": {
                  "text": "Using CASE instead of conditional function and vice versa"
                },
                "fullDescription": {
                  "text": "Reports situations when CASE and IF are interchangeable. Example (MySQL): 'SELECT CASE\nWHEN C1 IS NULL THEN 1\nELSE 0\nEND\nFROM dual;' To keep your code short, you can replace the CASE structure with IF. You can do that by applying the Replace with 'IF' call intention action. The example code will look as follows: 'SELECT IF(C1 IS NULL, 1, 0)\nFROM dual;' To revert IF to CASE, click IF and apply the Replace with CASE expression intention action.",
                  "markdown": "Reports situations when CASE and IF are interchangeable.\n\nExample (MySQL):\n\n    SELECT CASE\n    WHEN C1 IS NULL THEN 1\n    ELSE 0\n    END\n    FROM dual;\n\nTo keep your code short, you can replace the CASE structure with IF. You can do that by applying the **Replace with 'IF' call**\nintention action. The example code will look as follows:\n\n    SELECT IF(C1 IS NULL, 1, 0)\n    FROM dual;\n\nTo revert IF to CASE, click IF and apply the **Replace with CASE expression** intention action."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlShouldBeInGroupByInspection",
                "shortDescription": {
                  "text": "Column should be in group by clause"
                },
                "fullDescription": {
                  "text": "Reports columns that are not in the GROUP BY clause or inside an aggregate function call. Example (Microsoft SQL Server): 'CREATE TABLE t1 (a INT, b INT);\nSELECT a, b FROM t1 GROUP BY a;' If you run the SELECT query, you will receive an error because Microsoft SQL Server expects the 'b' column in GROUP BY or used inside an aggregate function. The following two examples will fix the error. 'SELECT a, b FROM t1 GROUP BY a, b;\nSELECT a, max(b) max_b FROM t1 GROUP BY a;'",
                  "markdown": "Reports columns that are not in the GROUP BY clause or inside an aggregate function call.\n\nExample (Microsoft SQL Server):\n\n    CREATE TABLE t1 (a INT, b INT);\n    SELECT a, b FROM t1 GROUP BY a;\n\nIf you run the SELECT query, you will receive an error because Microsoft SQL Server expects the `b` column in GROUP BY or used\ninside an aggregate function. The following two examples will fix the error.\n\n    SELECT a, b FROM t1 GROUP BY a, b;\n    SELECT a, max(b) max_b FROM t1 GROUP BY a;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlRedundantAliasInspection",
                "shortDescription": {
                  "text": "Redundant alias expressions"
                },
                "fullDescription": {
                  "text": "Reports alias expressions that duplicate names of columns in tables and might be redundant. Example (PostgreSQL): 'CREATE TABLE foo(a INT, b INT);\n\nSELECT * FROM foo foo(a, b);\nSELECT * FROM foo foo(a);\nSELECT * FROM foo foo(x);\nSELECT * FROM foo foo(x, y);' The first two aliases use the same column names as in the 'foo' table. They are considered redundant because they column names are identical.",
                  "markdown": "Reports alias expressions that duplicate names of columns in tables and might be redundant.\n\nExample (PostgreSQL):\n\n    CREATE TABLE foo(a INT, b INT);\n\n    SELECT * FROM foo foo(a, b);\n    SELECT * FROM foo foo(a);\n    SELECT * FROM foo foo(x);\n    SELECT * FROM foo foo(x, y);\n\nThe first two aliases use the same column names as in the `foo` table. They are considered redundant because they\ncolumn names are identical."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlIdentifierInspection",
                "shortDescription": {
                  "text": "Identifier should be quoted"
                },
                "fullDescription": {
                  "text": "Reports situations when you use SQL reserved keywords as identifier names in your query. Example (Microsoft SQL Server): 'CREATE TABLE select (identity INT IDENTITY NOT NULL, order INT NOT NULL);' We use 'select', 'identity', and 'order' as table and column names. But they are also reserved keywords in Microsoft SQL Server. Therefore, in order to use them as object names in the query, you must quote these identifiers. To quote them, you can use the Quote identifier quick-fix. After the quick-fix is applied: 'CREATE TABLE [select] ([identity] INT IDENTITY NOT NULL, [order] INT NOT NULL);'",
                  "markdown": "Reports situations when you use SQL reserved keywords as identifier names in your query.\n\nExample (Microsoft SQL Server):\n\n    CREATE TABLE select (identity INT IDENTITY NOT NULL, order INT NOT NULL);\n\nWe use `select`, `identity`, and `order` as table and column names.\nBut they are also reserved keywords in Microsoft SQL Server.\nTherefore, in order to use them as object names in the query, you must quote these identifiers. To quote them, you can use the\n**Quote identifier** quick-fix.\n\nAfter the quick-fix is applied:\n\n    CREATE TABLE [select] ([identity] INT IDENTITY NOT NULL, [order] INT NOT NULL);\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlAutoIncrementDuplicateInspection",
                "shortDescription": {
                  "text": "Auto-increment duplicate"
                },
                "fullDescription": {
                  "text": "Reports tables that contain two columns with an automatic increment. In MySQL, Microsoft SQL Server, and Db2 dialects, a table can have only one field with a auto-increment option, and this field must be a key. Example (MySQL): 'CREATE TABLE my_table\n(\n    id INT AUTO_INCREMENT,\n    c2 INT AUTO_INCREMENT,\n);' The AUTO_INCREMENT constraint for 'c2' will be highlighted as 'c1' already has this constraint. To fix the warning, you can make 'id' a primary key and delete AUTO_INCREMENT for 'c2'. 'CREATE TABLE my_table\n(\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    c2 INT,\n);'",
                  "markdown": "Reports tables that contain two columns with an automatic increment. In MySQL, Microsoft SQL Server, and Db2 dialects, a table can have only one field with a auto-increment option, and this field must be a key.\n\nExample (MySQL):\n\n    CREATE TABLE my_table\n    (\n        id INT AUTO_INCREMENT,\n        c2 INT AUTO_INCREMENT,\n    );\n\nThe AUTO_INCREMENT constraint for `c2` will be highlighted as `c1` already has this constraint. To fix the warning,\nyou can make `id` a primary key and delete AUTO_INCREMENT for `c2`.\n\n    CREATE TABLE my_table\n    (\n        id INT AUTO_INCREMENT PRIMARY KEY,\n        c2 INT,\n    );\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlStringLengthExceededInspection",
                "shortDescription": {
                  "text": "Implicit string truncation"
                },
                "fullDescription": {
                  "text": "Reports variables that exceed the defined length in characters. Example (Microsoft SQL Server): 'CREATE PROCEDURE test() AS\nBEGIN\nDECLARE myVarOk VARCHAR(5) = 'abcde';\nDECLARE myVarExceeded VARCHAR(5) = 'abcde12345';\n\nSET myVarOk = 'xyz';\nSET myVarExceeded = '123456789';\nEND;' The 'myVarExceeded' variable is defined as 'VARCHAR(5)' but both assigned values (''abcde12345'' and ''123456789'') exceed this limitation. You can truncate assigned values or increase the defined length. To increase the length, use the Increase type length quick-fix. After the quick-fix is applied: 'CREATE PROCEDURE test() AS\nBEGIN\nDECLARE myVarOk VARCHAR(5) = 'abcde';\nDECLARE myVarExceeded VARCHAR(10) = 'abcde12345';\n\nSET myVarOk = 'xyz';\nSET myVarExceeded = '123456789';\nEND;'",
                  "markdown": "Reports variables that exceed the defined length in characters.\n\nExample (Microsoft SQL Server):\n\n    CREATE PROCEDURE test() AS\n    BEGIN\n    DECLARE myVarOk VARCHAR(5) = 'abcde';\n    DECLARE myVarExceeded VARCHAR(5) = 'abcde12345';\n\n    SET myVarOk = 'xyz';\n    SET myVarExceeded = '123456789';\n    END;\n\nThe `myVarExceeded` variable is defined as `VARCHAR(5)` but both assigned values (`'abcde12345'` and\n`'123456789'`) exceed this limitation. You can truncate assigned values or increase the defined length.\nTo increase the length, use the **Increase type length** quick-fix.\n\nAfter the quick-fix is applied:\n\n    CREATE PROCEDURE test() AS\n    BEGIN\n    DECLARE myVarOk VARCHAR(5) = 'abcde';\n    DECLARE myVarExceeded VARCHAR(10) = 'abcde12345';\n\n    SET myVarOk = 'xyz';\n    SET myVarExceeded = '123456789';\n    END;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlTransactionStatementInTriggerInspection",
                "shortDescription": {
                  "text": "Use of transaction management statements in triggers"
                },
                "fullDescription": {
                  "text": "Reports usages of transaction management statements like COMMIT or ROLLBACK in trigger bodies. With COMMIT or ROLLBACK statements in a trigger body, the trigger will not compile. The fail happens because triggers start during transactions. When the trigger starts the current transaction is still not complete. As COMMIT terminates a transaction, both statements (COMMIT and ROLLBACK) would lead to an exception. Changes that are executed in a trigger should be committed (or rolled back) by the owning transaction that started the trigger. Example (Oracle): 'CREATE TABLE employee_audit\n(\n    id          INT  NOT NULL,\n    update_date DATE NOT NULL,\n    old_name    VARCHAR2(100),\n    new_name    VARCHAR2(100)\n);\n\nCREATE TABLE employees\n(\n    id   INT           NOT NULL,\n    name VARCHAR2(100) NOT NULL\n);\n\nCREATE OR REPLACE TRIGGER trig_commit\n    AFTER UPDATE OF name\n    ON employees\n    FOR EACH ROW\nBEGIN\n    INSERT INTO employee_audit VALUES (:old.id, SYSDATE, :old.name, :new.name);\n    COMMIT;\nEND;\n\nCREATE OR REPLACE TRIGGER trig_rollback\n    AFTER UPDATE OF name\n    ON employees\n    FOR EACH ROW\nBEGIN\n    INSERT INTO employee_audit VALUES (:old.id, SYSDATE, :old.name, :new.name);\n    ROLLBACK;\nEND;'",
                  "markdown": "Reports usages of transaction management statements like COMMIT or ROLLBACK in trigger bodies.\n\nWith COMMIT or ROLLBACK statements in a trigger body, the trigger will not compile.\nThe fail happens because triggers start during transactions. When the trigger starts the current transaction is still not complete. As\nCOMMIT\nterminates a transaction, both statements (COMMIT and ROLLBACK) would lead to an exception.\nChanges that are executed in a trigger should be committed (or rolled back) by the owning transaction that started the trigger.\n\nExample (Oracle):\n\n    CREATE TABLE employee_audit\n    (\n        id          INT  NOT NULL,\n        update_date DATE NOT NULL,\n        old_name    VARCHAR2(100),\n        new_name    VARCHAR2(100)\n    );\n\n    CREATE TABLE employees\n    (\n        id   INT           NOT NULL,\n        name VARCHAR2(100) NOT NULL\n    );\n\n    CREATE OR REPLACE TRIGGER trig_commit\n        AFTER UPDATE OF name\n        ON employees\n        FOR EACH ROW\n    BEGIN\n        INSERT INTO employee_audit VALUES (:old.id, SYSDATE, :old.name, :new.name);\n        COMMIT;\n    END;\n\n    CREATE OR REPLACE TRIGGER trig_rollback\n        AFTER UPDATE OF name\n        ON employees\n        FOR EACH ROW\n    BEGIN\n        INSERT INTO employee_audit VALUES (:old.id, SYSDATE, :old.name, :new.name);\n        ROLLBACK;\n    END;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlRedundantCodeInCoalesceInspection",
                "shortDescription": {
                  "text": "Redundant code in COALESCE call"
                },
                "fullDescription": {
                  "text": "Reports all the arguments except for the first expression that does not evaluate to NULL in COALESCE functions. Example (MySQL): 'SELECT COALESCE(NULL, NULL, NULL, 42, NULL, 'string') as a;' The first NOT NULL argument is '42', all other arguments will be grayed out.",
                  "markdown": "Reports all the arguments except for the first expression that does not evaluate to NULL in COALESCE functions.\n\nExample (MySQL):\n\n    SELECT COALESCE(NULL, NULL, NULL, 42, NULL, 'string') as a;\n\nThe first NOT NULL argument is `42`, all other arguments will be grayed out."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlStorageInspection",
                "shortDescription": {
                  "text": "SQL source modification detection"
                },
                "fullDescription": {
                  "text": "Reports situations when source code of a database object has been changed. The inspection is triggered when you perform database or object introspection. The introspection is run when you open source code of an object, run statements, and perform code refactoring. Also, you can run introspection by right-clicking an object and selecting Refresh. The inspection covers the following situations: Object source code was changed in the database but code in the editor was not updated. Works in PostgreSQL, Microsoft SQL Server, Oracle, and Sybase ASE. You changed the object source code, introspected the database, but source code has been already changed by someone else. The database introspector was updated in the IDE and you need to download new object properties that were missing in the previous introspector version.",
                  "markdown": "Reports situations when source code of a database object has been changed.\n\nThe inspection is triggered when you perform database or object introspection. The introspection is run when you open source code of an\nobject, run statements, and perform code refactoring.\nAlso, you can run introspection by right-clicking an object and selecting **Refresh**.\n\nThe inspection covers the following situations:\n\n* Object source code was changed in the database but code in the editor was not updated. Works in PostgreSQL, Microsoft SQL Server, Oracle, and Sybase ASE.\n* You changed the object source code, introspected the database, but source code has been already changed by someone else.\n* The database introspector was updated in the IDE and you need to download new object properties that were missing in the previous introspector version."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "MsOrderByInspection",
                "shortDescription": {
                  "text": "ORDER BY in queries"
                },
                "fullDescription": {
                  "text": "Reports usages when the 'ORDER BY' clause is used without 'TOP', 'OFFSET', or 'FOR XML' in views, inline functions, derived tables, subqueries, and common table expressions. For more information about usages of 'ORDER BY', see SELECT - ORDER BY Clause (Transact-SQL) at docs.microsoft.com. Example (Microsoft SQL server): 'CREATE TABLE foo (a INT NOT NULL, b  INT NOT NULL);\n\nSELECT *\nFROM (SELECT a, b\nFROM foo A\nWHERE a < 89\nORDER BY b) ALIAS;' In a subquery, ORDER BY will be highlighted as an error. You can add TOP, OFFSET, or FOR XML to a subquery. Alternatively, use the Delete element quick-fix to delete the ORDER BY section. After the quick-fix is applied: 'SELECT *\nFROM (SELECT a, b\nFROM foo A\nWHERE a < 89) ALIAS;'",
                  "markdown": "Reports usages when the `ORDER BY` clause is used without `TOP`, `OFFSET`, or `FOR XML` in views, inline functions, derived tables, subqueries, and common table expressions.\n\nFor more information about usages of `ORDER BY`, see [SELECT - ORDER BY Clause (Transact-SQL) at\ndocs.microsoft.com](https://docs.microsoft.com/en-us/sql/t-sql/queries/select-order-by-clause-transact-sql).\n\nExample (Microsoft SQL server):\n\n    CREATE TABLE foo (a INT NOT NULL, b  INT NOT NULL);\n\n    SELECT *\n    FROM (SELECT a, b\n    FROM foo A\n    WHERE a < 89\n    ORDER BY b) ALIAS;\n\nIn a subquery, ORDER BY will be highlighted as an error. You can add TOP, OFFSET, or FOR XML to a subquery.\nAlternatively, use the **Delete element** quick-fix to delete the ORDER BY section.\n\nAfter the quick-fix is applied:\n\n    SELECT *\n    FROM (SELECT a, b\n    FROM foo A\n    WHERE a < 89) ALIAS;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL server",
                      "index": 19,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlDtInspection",
                "shortDescription": {
                  "text": "Ill-formed date/time literals"
                },
                "fullDescription": {
                  "text": "Reports errors in date and time literals. This inspection is available in MySQL, Oracle, Db2, and H2. Example (MySQL): 'SELECT TIME '10 -12:13:14' FROM dual;\nSELECT TIME ' 12 : 13 : 14 ' FROM dual;\nSELECT TIME '12 13 14' FROM dual;\nSELECT TIME '12-13-14' FROM dual;\nSELECT TIME '12.13.14' FROM dual;\nSELECT TIME '12:13:' FROM dual;\nSELECT TIME '12:13' FROM dual;\nSELECT TIME '12:' FROM dual;' In this example, dates ignore the MySQL standard for date and time literals. Therefore, they will be highlighted. For more information about date and time literals in MySQL, see Date and Time Literals at dev.mysql.com. The following date and type literals are valid for MySQL. 'SELECT TIME '12:13:14' FROM dual;\nSELECT TIME '12:13:14.555' FROM dual;\nSELECT TIME '12:13:14.' FROM dual;\nSELECT TIME '-12:13:14' FROM dual;\nSELECT TIME '10 12:13:14' FROM dual;\nSELECT TIME '-10 12:13:14' FROM dual;'",
                  "markdown": "Reports errors in date and time literals. This inspection is available in MySQL, Oracle, Db2, and H2.\n\nExample (MySQL):\n\n    SELECT TIME '10 -12:13:14' FROM dual;\n    SELECT TIME ' 12 : 13 : 14 ' FROM dual;\n    SELECT TIME '12 13 14' FROM dual;\n    SELECT TIME '12-13-14' FROM dual;\n    SELECT TIME '12.13.14' FROM dual;\n    SELECT TIME '12:13:' FROM dual;\n    SELECT TIME '12:13' FROM dual;\n    SELECT TIME '12:' FROM dual;\n\nIn this example, dates ignore the MySQL standard for date and time literals. Therefore, they will be highlighted.\nFor more information about date and time literals in MySQL, see [Date and Time Literals at dev.mysql.com](https://dev.mysql.com/doc/refman/8.0/en/date-and-time-literals.html).\n\nThe following date and type literals are valid for MySQL.\n\n    SELECT TIME '12:13:14' FROM dual;\n    SELECT TIME '12:13:14.555' FROM dual;\n    SELECT TIME '12:13:14.' FROM dual;\n    SELECT TIME '-12:13:14' FROM dual;\n    SELECT TIME '10 12:13:14' FROM dual;\n    SELECT TIME '-10 12:13:14' FROM dual;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlSideEffectsInspection",
                "shortDescription": {
                  "text": "Statement with side effects"
                },
                "fullDescription": {
                  "text": "Reports statements that might lead to modification of a database during a read-only connection. To enable read-only mode for a connection, right-click a data source in the Database tool window (View | Tool Windows | Database) and select Properties. In the Data Sources and Drivers dialog, click the Options tab and select the Read-only checkbox. Example (MySQL): 'CREATE TABLE foo(a INT);\nINSERT INTO foo VALUES (1);' As 'CREATE TABLE' and 'INSERT INTO' statements lead to a database modification, these statements will be highlighted in read-only connection mode.",
                  "markdown": "Reports statements that might lead to modification of a database during a read-only connection.\n\nTo enable read-only mode for a\nconnection,\nright-click a data source in the **Database** tool window (**View \\| Tool Windows \\| Database** ) and select **Properties** .\nIn the **Data Sources and Drivers** dialog, click the **Options** tab and select the **Read-only** checkbox.\n\nExample (MySQL):\n\n    CREATE TABLE foo(a INT);\n    INSERT INTO foo VALUES (1);\n\nAs `CREATE TABLE` and `INSERT INTO` statements lead to a database modification, these statements will be highlighted\nin read-only connection mode."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlIllegalCursorStateInspection",
                "shortDescription": {
                  "text": "Illegal cursor state"
                },
                "fullDescription": {
                  "text": "Reports illegal cursor states inside SQL routines. A routine has CLOSE or FETCH statements but a cursor might be closed. A routine has the OPEN statement but a cursor might be opened. Example (Microsoft SQL Server): 'CREATE TABLE t(col INT);\n\nCREATE PROCEDURE foo() AS\nBEGIN\nDECLARE my_cursor CURSOR FOR SELECT * FROM t;\nDECLARE a INT;\nFETCH my_cursor INTO a;\nCLOSE my_cursor;\nEND;' According to CLOSE (Transact-SQL) at docs.microsoft.com, CLOSE must be issued on an open cursor, and CLOSE is not allowed on cursors that have only been declared or are already closed. So, we need to open the cursor to fix the warning. 'CREATE PROCEDURE foo() AS\nBEGIN\nDECLARE my_cursor CURSOR FOR SELECT * FROM t;\nDECLARE a INT;\nOPEN my_cursor;\nFETCH my_cursor INTO a;\nCLOSE my_cursor;\nEND;'",
                  "markdown": "Reports illegal cursor states inside SQL routines.\n\n* A routine has CLOSE or FETCH statements but a cursor might be closed.\n* A routine has the OPEN statement but a cursor might be opened.\n\nExample (Microsoft SQL Server):\n\n    CREATE TABLE t(col INT);\n\n    CREATE PROCEDURE foo() AS\n    BEGIN\n    DECLARE my_cursor CURSOR FOR SELECT * FROM t;\n    DECLARE a INT;\n    FETCH my_cursor INTO a;\n    CLOSE my_cursor;\n    END;\n\nAccording to [CLOSE (Transact-SQL) at\ndocs.microsoft.com](https://docs.microsoft.com/en-us/sql/t-sql/language-elements/close-transact-sql), CLOSE must be issued on an open cursor, and CLOSE is not allowed on cursors that have only been declared or are\nalready closed. So, we need to open the cursor to fix the warning.\n\n    CREATE PROCEDURE foo() AS\n    BEGIN\n    DECLARE my_cursor CURSOR FOR SELECT * FROM t;\n    DECLARE a INT;\n    OPEN my_cursor;\n    FETCH my_cursor INTO a;\n    CLOSE my_cursor;\n    END;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlJoinWithoutOnInspection",
                "shortDescription": {
                  "text": "Unsafe 'join' clause in 'delete' statement"
                },
                "fullDescription": {
                  "text": "Reports missing conditional checks for statements that might modify the whole database. For example, usages of JOIN clauses inside DELETE statements without ON or WHERE. Without conditional checks on JOIN, DELETE drops contents of the entire table. Example (MySQL): 'CREATE TABLE foo (a INT,b INT,c INT);\nCREATE TABLE bar (a INT,b INT,c INT);\n\nDELETE table1 FROM foo table1  INNER JOIN bar table2;'",
                  "markdown": "Reports missing conditional checks for statements that might modify the whole database.\n\nFor example, usages of JOIN clauses inside DELETE statements without ON or WHERE. Without conditional checks on JOIN, DELETE drops\ncontents of the entire table.\n\nExample (MySQL):\n\n    CREATE TABLE foo (a INT,b INT,c INT);\n    CREATE TABLE bar (a INT,b INT,c INT);\n\n    DELETE table1 FROM foo table1  INNER JOIN bar table2;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlDropIndexedColumnInspection",
                "shortDescription": {
                  "text": "Index is dependent on column"
                },
                "fullDescription": {
                  "text": "Reports cases when you try to drop columns from indexed tables. This inspection is available in Microsoft SQL Server and Sybase ASE. Example (Microsoft SQL Server): 'CREATE TABLE test_index\n(\ncol  INT NOT NULL,\ncol2 INT NOT NULL,\ncol3 INT NOT NULL UNIQUE,\ncol4 VARCHAR(200)\n);\n\nCREATE UNIQUE INDEX aaaa ON test_index (col, col2);\n\nALTER TABLE test_index\nDROP COLUMN col;' You cannot delete the 'col' column because it is in the indexed table. To delete the column, you need to delete the 'aaaa' index first (for example, DROP INDEX aaaa).",
                  "markdown": "Reports cases when you try to drop columns from indexed tables. This inspection is available in Microsoft SQL Server and Sybase ASE.\n\nExample (Microsoft SQL Server):\n\n    CREATE TABLE test_index\n    (\n    col  INT NOT NULL,\n    col2 INT NOT NULL,\n    col3 INT NOT NULL UNIQUE,\n    col4 VARCHAR(200)\n    );\n\n    CREATE UNIQUE INDEX aaaa ON test_index (col, col2);\n\n    ALTER TABLE test_index\n    DROP COLUMN col;\n\nYou cannot delete the `col` column because it is in the indexed table. To delete the column, you need to delete the\n`aaaa` index first (for example, DROP INDEX aaaa)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlCheckUsingColumnsInspection",
                "shortDescription": {
                  "text": "Check using clause columns"
                },
                "fullDescription": {
                  "text": "Reports columns in the USING clause that does not exist in both tables. Example (MySQL): 'CREATE TABLE t1 (i INT, j INT);\nCREATE TABLE t2 (k INT, l INT);\nSELECT * FROM t1 JOIN t2 USING (j);' In USING clauses, a column name must be present in both tables, and the SELECT query will automatically join those tables by using the given column name. As we do not have the 'j' column in 't2', we can rewrite the query using ON. The ON clause can join tables where the column names do not match in both tables. 'SELECT * FROM t1 JOIN t2 ON t1.j = t2.l;'",
                  "markdown": "Reports columns in the USING clause that does not exist in both tables.\n\nExample (MySQL):\n\n    CREATE TABLE t1 (i INT, j INT);\n    CREATE TABLE t2 (k INT, l INT);\n    SELECT * FROM t1 JOIN t2 USING (j);\n\nIn USING clauses, a column name must be present in both tables, and the SELECT query will automatically join\nthose tables by using the given column name. As we do not have the `j` column in `t2`, we can\nrewrite the query using ON. The ON clause can join tables where the column names do not match in both tables.\n\n    SELECT * FROM t1 JOIN t2 ON t1.j = t2.l;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlSignatureInspection",
                "shortDescription": {
                  "text": "Function signature"
                },
                "fullDescription": {
                  "text": "Reports signature issues for built-in functions. The inspection will report a wrong number of arguments, invalid keywords, wrong data types, and other issues. Example (MySQL): 'CREATE TABLE foo (a INT, b INT, c INT)\n\nSELECT IFNULL() FROM foo; -- error\nSELECT IFNULL(a) FROM foo; -- error\nSELECT IFNULL(a, b) FROM foo; -- OK\nSELECT IFNULL(a, b, c) FROM foo; -- error' In MySQL, the 'IFNULL()' function accepts strictly two arguments. So, only the 'SELECT IFNULL(a, b) FROM foo;' query is correct.",
                  "markdown": "Reports signature issues for built-in functions.\n\nThe inspection will report a wrong number of arguments, invalid keywords, wrong data types, and other issues.\n\nExample (MySQL):\n\n    CREATE TABLE foo (a INT, b INT, c INT)\n\n    SELECT IFNULL() FROM foo; -- error\n    SELECT IFNULL(a) FROM foo; -- error\n    SELECT IFNULL(a, b) FROM foo; -- OK\n    SELECT IFNULL(a, b, c) FROM foo; -- error\n\nIn MySQL, the `IFNULL()` function accepts strictly two arguments. So, only the `SELECT IFNULL(a, b) FROM foo;`\nquery is correct."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlRedundantOrderingDirectionInspection",
                "shortDescription": {
                  "text": "Redundant ordering direction"
                },
                "fullDescription": {
                  "text": "Reports redundant ordering directions like ASC and DESC in ORDER BY clauses. Example (MySQL): 'CREATE TABLE foo(a INT, b INT, c INT);\nSELECT * FROM foo ORDER BY a ASC, b DESC, c ASC;' The ORDER BY keyword sorts the records in the ascending order by default. So, the 'ASC' keyword for 'a' and 'c' columns is redundant.",
                  "markdown": "Reports redundant ordering directions like ASC and DESC in ORDER BY clauses.\n\nExample (MySQL):\n\n    CREATE TABLE foo(a INT, b INT, c INT);\n    SELECT * FROM foo ORDER BY a ASC, b DESC, c ASC;\n\nThe ORDER BY keyword sorts the records in the ascending order by default. So, the `ASC` keyword for `a` and\n`c` columns is redundant."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlInsertValuesInspection",
                "shortDescription": {
                  "text": "VALUES clause cardinality"
                },
                "fullDescription": {
                  "text": "Reports situations when a number of parameters in VALUES does not match a number of columns in a target table. Example (MySQL): 'CREATE TABLE foo(a INT, b INT, c INT);\n\nINSERT INTO foo VALUES (1,2,3,4)' The 'foo' table has three columns but in the INSERT INTO statement we pass four.",
                  "markdown": "Reports situations when a number of parameters in VALUES does not match a number of columns in a target table.\n\nExample (MySQL):\n\n    CREATE TABLE foo(a INT, b INT, c INT);\n\n    INSERT INTO foo VALUES (1,2,3,4)\n\nThe `foo` table has three columns but in the INSERT INTO statement we pass four."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlConstantConditionInspection",
                "shortDescription": {
                  "text": "Constant condition"
                },
                "fullDescription": {
                  "text": "Reports conditions in WHERE or JOIN clauses that are always TRUE or always FALSE. Example (MySQL): 'CREATE TABLE t1 (a TEXT, b INT, c BOOLEAN);\nSELECT a FROM t1 WHERE 'Cat' = 'Cat';' The ''Cat' = 'Cat'' is always true and will be reported.",
                  "markdown": "Reports conditions in WHERE or JOIN clauses that are always TRUE or always FALSE.\n\nExample (MySQL):\n\n    CREATE TABLE t1 (a TEXT, b INT, c BOOLEAN);\n    SELECT a FROM t1 WHERE 'Cat' = 'Cat';\n\nThe `'Cat' = 'Cat'` is always true and will be reported."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlDialectInspection",
                "shortDescription": {
                  "text": "SQL dialect detection"
                },
                "fullDescription": {
                  "text": "Reports situations when a dialect is not assigned to an SQL file. For example, when you open a new SQL file without assigning a dialect to it, you see a notification where the best matching dialect is advised. Click the Use <dialect> link to use the advised dialect. Alternatively, click the Change dialect to link to select the other dialect.",
                  "markdown": "Reports situations when a dialect is not assigned to an SQL file.\n\nFor example, when you open a new SQL file without assigning a dialect\nto it, you see a notification where the best matching dialect is advised. Click the **Use \\<dialect\\>** link to use the advised\ndialect. Alternatively, click the **Change dialect to** link to select the other dialect."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlRedundantElseNullInspection",
                "shortDescription": {
                  "text": "Redundant ELSE NULL clause"
                },
                "fullDescription": {
                  "text": "Reports redundant ELSE NULL clauses. Example (MySQL): 'SELECT CASE WHEN 2 > 1 THEN 'OK' ELSE NULL END AS alias FROM foo;' The 'ELSE NULL' part will never be executed and may be omitted.",
                  "markdown": "Reports redundant ELSE NULL clauses.\n\nExample (MySQL):\n\n    SELECT CASE WHEN 2 > 1 THEN 'OK' ELSE NULL END AS alias FROM foo;\n\nThe `ELSE NULL` part will never be executed and may be omitted."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlDeprecateTypeInspection",
                "shortDescription": {
                  "text": "Deprecated type"
                },
                "fullDescription": {
                  "text": "Reports usages of types that are deprecated and might disappear in future versions of DBMS. Reported types: LONG in Oracle (see Deprecated and Desupported Features at docs.oracle.com). TEXT, NTEXT, and IMAGE in Microsoft SQL Server (see Deprecated Database Engine Features in SQL Server 2016 at docs.microsoft.com). Example (Oracle): 'CREATE TABLE ot.foo(\na NUMBER GENERATED BY DEFAULT AS IDENTITY,\nb LONG NOT NULL\n);'",
                  "markdown": "Reports usages of types that are deprecated and might disappear in future versions of DBMS.\n\nReported types:\n\n* LONG in Oracle (see [Deprecated\n  and Desupported Features at docs.oracle.com](https://docs.oracle.com/cd/A91202_01/901_doc/server.901/a90120/ch4_dep.htm#6690)).\n* TEXT, NTEXT, and IMAGE in Microsoft SQL Server (see [Deprecated Database Engine Features in SQL Server 2016 at docs.microsoft.com](https://docs.microsoft.com/en-us/sql/database-engine/deprecated-database-engine-features-in-sql-server-2016?view=sql-server-ver15)).\n\nExample (Oracle):\n\n    CREATE TABLE ot.foo(\n    a NUMBER GENERATED BY DEFAULT AS IDENTITY,\n    b LONG NOT NULL\n    );\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlAggregatesInspection",
                "shortDescription": {
                  "text": "Aggregate-related problems"
                },
                "fullDescription": {
                  "text": "Reports invalid usages of SQL aggregate functions. The following situations are considered: Columns that are used in HAVING and ORDER BY clauses but are missed in GROUP BY clauses. 'CREATE TABLE foo(id INT PRIMARY KEY, a INT, b INT);\nSELECT a, MAX(b) FROM foo GROUP BY a HAVING b > 0;\nSELECT * FROM foo GROUP BY a ORDER BY b;' This rule does not apply when grouping is made by the primary key. 'SELECT * FROM foo GROUP BY id ORDER BY b;' Aggregate functions in a wrong context. Usually, you can use aggregate functions in the following contexts: a list of expressions in SELECT; in HAVING and ORDER BY sections; and other dialect-specific cases. The following queries will display an error. 'SELECT a FROM foo WHERE MAX(b) > 0;\nSELECT a FROM foo GROUP BY MAX(a);' Nested calls of aggregate functions. 'SELECT MAX(SUM(a)) FROM foo GROUP BY a;' This rule does not apply to analytic functions. The following query is valid and correct. 'SELECT MAX(SUM(a) OVER ()) FROM foo;' Usages of HAVING without aggregate functions. In this case, consider rewriting your code using the WHERE section. 'SELECT a, MAX(b) FROM foo GROUP BY a HAVING a > 0;'",
                  "markdown": "Reports invalid usages of SQL aggregate functions.\n\nThe following situations are considered:\n\n* Columns that are used in HAVING and ORDER BY clauses but are missed in GROUP BY clauses.\n\n      CREATE TABLE foo(id INT PRIMARY KEY, a INT, b INT);\n      SELECT a, MAX(b) FROM foo GROUP BY a HAVING b > 0;\n      SELECT * FROM foo GROUP BY a ORDER BY b;\n\n  This rule does not apply when grouping is made by the primary key.\n\n      SELECT * FROM foo GROUP BY id ORDER BY b;\n\n* Aggregate functions in a wrong context. Usually, you can use aggregate functions in the following contexts: a list of expressions in\n  SELECT; in HAVING and ORDER BY sections; and other dialect-specific cases. The following queries will display an error.\n\n      SELECT a FROM foo WHERE MAX(b) > 0;\n      SELECT a FROM foo GROUP BY MAX(a);\n\n* Nested calls of aggregate functions.\n\n      SELECT MAX(SUM(a)) FROM foo GROUP BY a;\n\n  This rule does not apply to analytic functions. The following query is valid and correct.\n\n      SELECT MAX(SUM(a) OVER ()) FROM foo;\n\n* Usages of HAVING without aggregate functions. In this case, consider rewriting your code using the WHERE section.\n\n      SELECT a, MAX(b) FROM foo GROUP BY a HAVING a > 0;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlCallNotationInspection",
                "shortDescription": {
                  "text": "Using of named and positional arguments"
                },
                "fullDescription": {
                  "text": "Reports calls in which positional arguments go after the named ones. Works in PostgreSQL, Oracle, and Db2. Example (In PostgreSQL): 'CREATE FUNCTION foo(a int, b int, c int) RETURNS int\n    LANGUAGE plpgsql AS\n$$\nBEGIN\n    RETURN a + b + c;\nEND\n$$;\nSELECT foo(a => 1, b => 2, c => 3);\n  -- `3` goes after the named argument\nSELECT foo(1, b => 2, 3);\n  -- `1` and `3` go after the named argument\nSELECT foo(b => 2, 1, 3);'",
                  "markdown": "Reports calls in which positional arguments go after the named ones. Works in PostgreSQL, Oracle, and Db2.\n\nExample (In PostgreSQL):\n\n    CREATE FUNCTION foo(a int, b int, c int) RETURNS int\n        LANGUAGE plpgsql AS\n    $$\n    BEGIN\n        RETURN a + b + c;\n    END\n    $$;\n    SELECT foo(a => 1, b => 2, c => 3);\n      -- `3` goes after the named argument\n    SELECT foo(1, b => 2, 3);\n      -- `1` and `3` go after the named argument\n    SELECT foo(b => 2, 1, 3);\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "MysqlParsingInspection",
                "shortDescription": {
                  "text": "Unsupported syntax in pre-8.0 versions"
                },
                "fullDescription": {
                  "text": "Reports invalid usages of UNION in queries. The inspection works in MySQL versions that are earlier than 8.0. Example (MySQL): 'SELECT * FROM (SELECT 1 UNION (SELECT 1 UNION SELECT 2)) a;'",
                  "markdown": "Reports invalid usages of UNION in queries.\n\nThe inspection works in MySQL versions that are earlier than 8.0.\n\nExample (MySQL):\n\n\n    SELECT * FROM (SELECT 1 UNION (SELECT 1 UNION SELECT 2)) a;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "MySQL",
                      "index": 12,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlConstantExpressionInspection",
                "shortDescription": {
                  "text": "Constant expression"
                },
                "fullDescription": {
                  "text": "Reports conditions and expressions that are always true, false or null. Example (MySQL): 'CREATE TABLE t1 (a TEXT, b INT, c BOOLEAN);\nSELECT a FROM t1 WHERE 'Cat' = 'Cat';\nSELECT a FROM t1 WHERE 'Cat' = null;' The ''Cat' = 'Cat'' is always true and will be reported. The ''Cat' = null' is always null and will be reported.",
                  "markdown": "Reports conditions and expressions that are always true, false or null.\n\nExample (MySQL):\n\n    CREATE TABLE t1 (a TEXT, b INT, c BOOLEAN);\n    SELECT a FROM t1 WHERE 'Cat' = 'Cat';\n    SELECT a FROM t1 WHERE 'Cat' = null;\n\nThe `'Cat' = 'Cat'` is always true and will be reported.\n\nThe `'Cat' = null` is always null and will be reported."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlMissingColumnAliasesInspection",
                "shortDescription": {
                  "text": "Missing column aliases"
                },
                "fullDescription": {
                  "text": "Reports queries without explicit aliases in output expressions (for example, in the SELECT statement). Example (PostgreSQL): 'CREATE TABLE foo(a INT, b INT);\n\nSELECT 1, a + 1 AS A2, MAX(b) AS M\nFROM foo;'",
                  "markdown": "Reports queries without explicit aliases in output expressions (for example, in the SELECT statement).\n\nExample (PostgreSQL):\n\n    CREATE TABLE foo(a INT, b INT);\n\n    SELECT 1, a + 1 AS A2, MAX(b) AS M\n    FROM foo;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlAddNotNullColumnInspection",
                "shortDescription": {
                  "text": "Adding not null column without default value"
                },
                "fullDescription": {
                  "text": "Reports attempts to create NOT NULL columns without DEFAULT values. Example (Microsoft SQL Server): 'CREATE TABLE foo (a INT, b  INT)\n\nALTER TABLE foo ADD c INT NOT NULL;' By default, a column holds NULL values. In the example, we use the NOT NULL constraint that enforces a column not to accept NULL values. If we prohibit to use NULL values, we must set the DEFAULT value that SQL can use when we create a new record. 'ALTER TABLE foo ADD c INT NOT NULL DEFAULT 42;' You can quickly add the DEFAULT value by using the Add DEFAULT value quick-fix.",
                  "markdown": "Reports attempts to create NOT NULL columns without DEFAULT values.\n\nExample (Microsoft SQL Server):\n\n    CREATE TABLE foo (a INT, b  INT)\n\n    ALTER TABLE foo ADD c INT NOT NULL;\n\nBy default, a column holds NULL values. In the example, we use the NOT NULL constraint that enforces a column not to accept NULL values.\nIf we prohibit to use NULL values, we must set the DEFAULT value that SQL can use when we create a new record.\n\n    ALTER TABLE foo ADD c INT NOT NULL DEFAULT 42;\n\nYou can quickly add the DEFAULT value by using the **Add DEFAULT value** quick-fix."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlDuplicateColumnInspection",
                "shortDescription": {
                  "text": "Duplicating column name in SELECT"
                },
                "fullDescription": {
                  "text": "Reports duplicated names of column aliases in SELECT lists. Example (Sybase ASE): 'CREATE TABLE t1 (a TEXT, b INT, c INT);\n\nSELECT a AS x, b AS x FROM t1;' The 'x' alias name is used for 'a' and 'b' columns. These assignments are highlighted as errors because you cannot use identical alias names for columns in Sybase ASE.",
                  "markdown": "Reports duplicated names of column aliases in SELECT lists.\n\nExample (Sybase ASE):\n\n    CREATE TABLE t1 (a TEXT, b INT, c INT);\n\n    SELECT a AS x, b AS x FROM t1;\n\nThe `x` alias name is used for `a` and `b` columns. These assignments are highlighted as errors because\nyou cannot use identical alias names for columns in Sybase ASE."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlShadowingAliasInspection",
                "shortDescription": {
                  "text": "Column is shadowed by alias"
                },
                "fullDescription": {
                  "text": "Reports SELECT aliases with names that match column names in the FROM clause. Example (MySQL): 'CREATE TABLE foo (a INT, b INT, c INT);\nSELECT a b, c FROM foo;' The 'a' column uses the 'b' alias but the 'b' name is also used by the column from the 'foo' table.",
                  "markdown": "Reports SELECT aliases with names that match column names in the FROM clause.\n\nExample (MySQL):\n\n    CREATE TABLE foo (a INT, b INT, c INT);\n    SELECT a b, c FROM foo;\n\nThe `a` column uses the `b` alias but the `b` name is also used by the column from the `foo`\ntable."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "MongoJSDeprecationInspection",
                "shortDescription": {
                  "text": "Deprecated element"
                },
                "fullDescription": {
                  "text": "Reports usages of deprecated methods in MongoDB and JavaScript code. The quick-fix replaces deprecated methods with recommended alternatives. Example: 'db.my_collection.insert()' After the quick-fix is applied: 'db.my_collection.insertOne()'",
                  "markdown": "Reports usages of deprecated methods in MongoDB and JavaScript code.\n\nThe quick-fix replaces deprecated methods with recommended alternatives.\n\nExample:\n\n    db.my_collection.insert()\n\nAfter the quick-fix is applied:\n\n    db.my_collection.insertOne()\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "MongoJS",
                      "index": 9,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlTypeInspection",
                "shortDescription": {
                  "text": "Types compatibility"
                },
                "fullDescription": {
                  "text": "Reports type-related errors.",
                  "markdown": "Reports type-related errors."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "OraOverloadInspection",
                "shortDescription": {
                  "text": "Overloading errors"
                },
                "fullDescription": {
                  "text": "Reports invalid cases of subprogram overloading in Oracle. Example (Oracle): 'DECLARE\n    SUBTYPE fff IS BINARY_INTEGER;\n    SUBTYPE ggg IS NATURAL;\n    PROCEDURE foo (a IN ggg) IS BEGIN NULL; END;\n    PROCEDURE foo (a IN fff) IS BEGIN NULL; END;\nBEGIN\n    NULL;\nEND;' You cannot overload subprograms which parameters differ only in subtypes. For example, you cannot overload procedures where one accepts a BINARY INTEGER parameter and the other accepts a NATURAL parameter. For more information about restrictions on procedure overloading, see Restrictions on Overloading at docs.oracle.com.",
                  "markdown": "Reports invalid cases of subprogram overloading in Oracle.\n\nExample (Oracle):\n\n    DECLARE\n        SUBTYPE fff IS BINARY_INTEGER;\n        SUBTYPE ggg IS NATURAL;\n        PROCEDURE foo (a IN ggg) IS BEGIN NULL; END;\n        PROCEDURE foo (a IN fff) IS BEGIN NULL; END;\n    BEGIN\n        NULL;\n    END;\n\nYou cannot overload subprograms which parameters differ only in subtypes. For example, you cannot overload procedures where one accepts a\nBINARY INTEGER parameter and the other accepts a NATURAL parameter. For more information about restrictions on procedure overloading,\nsee [Restrictions on Overloading at docs.oracle.com](https://docs.oracle.com/cd/B19306_01/appdev.102/b14261/subprograms.htm)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Oracle",
                      "index": 28,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlUnreachableCodeInspection",
                "shortDescription": {
                  "text": "Unreachable code"
                },
                "fullDescription": {
                  "text": "Reports unreachable statements inside SQL routines. Example (Microsoft SQL Server): 'CREATE FUNCTION foo() RETURNS INT AS\nBEGIN\n    THROW;\n    RETURN 1;\nEND;' In Microsoft SQL Server, the 'THROW' statement raises an exception and transfers execution to the CATCH block of the TRY...CATCH construct. Therefore, the 'RETURN 1;' part will never be executed.",
                  "markdown": "Reports unreachable statements inside SQL routines.\n\nExample (Microsoft SQL Server):\n\n    CREATE FUNCTION foo() RETURNS INT AS\n    BEGIN\n        THROW;\n        RETURN 1;\n    END;\n\nIn Microsoft SQL Server, the `THROW` statement raises an exception and transfers execution to the CATCH block of the TRY...CATCH\nconstruct. Therefore, the `RETURN 1;` part will never be executed."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "OraMissingBodyInspection",
                "shortDescription": {
                  "text": "Missing body for package/object type specification"
                },
                "fullDescription": {
                  "text": "Reports package and object type specifications that are missing body declarations. Package specifications and object types that declare routines as well as package specifications with cursors must have body declarations where those routines and cursors are implemented. Absence of a body leads to a runtime error when routines or cursors are invoked in program code. Example (Oracle): 'CREATE OR REPLACE PACKAGE ppp IS\n    FUNCTION foo(a INT) RETURN INT;\nEND;'",
                  "markdown": "Reports package and object type specifications that are missing body declarations.\n\nPackage specifications and object types that declare routines as well as package specifications with cursors must have body\ndeclarations where those routines and cursors are implemented. Absence of a body leads to a runtime error when routines or cursors are\ninvoked in program code.\n\nExample (Oracle):\n\n    CREATE OR REPLACE PACKAGE ppp IS\n        FUNCTION foo(a INT) RETURN INT;\n    END;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Oracle",
                      "index": 28,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "OraUnmatchedForwardDeclarationInspection",
                "shortDescription": {
                  "text": "Forward declaration without definition"
                },
                "fullDescription": {
                  "text": "Reports declarations of procedures and functions that are missing their implementation in code. In Oracle, you can declare a procedure or a function without its body, and write the implementation later. The inspection will report names of such procedures or functions that are left without implementation. Example (Oracle): 'DECLARE PROCEDURE foo(a int, b varchar2);\nBEGIN\n    NULL;\nEND;' The 'foo' procedure is declared but is missing implementation. We can add the implementation to get rid of the error. 'DECLARE PROCEDURE foo(a int, b varchar2);\n  PROCEDURE foo(a int, b varchar2) IS\nBEGIN\n    NULL;\nEND;\nBEGIN\n    NULL;\nEND;'",
                  "markdown": "Reports declarations of procedures and functions that are missing their implementation in code.\n\nIn Oracle, you can declare a procedure or a function without its body, and write the implementation later. The inspection will report names\nof such procedures or functions that are left without implementation.\n\nExample (Oracle):\n\n    DECLARE PROCEDURE foo(a int, b varchar2);\n    BEGIN\n        NULL;\n    END;\n\nThe `foo` procedure is declared but is missing implementation. We can add the implementation to get rid of the error.\n\n    DECLARE PROCEDURE foo(a int, b varchar2);\n      PROCEDURE foo(a int, b varchar2) IS\n    BEGIN\n        NULL;\n    END;\n    BEGIN\n        NULL;\n    END;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Oracle",
                      "index": 28,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlUnicodeStringLiteralInspection",
                "shortDescription": {
                  "text": "Unicode usage in SQL"
                },
                "fullDescription": {
                  "text": "Reports string literals that use national characters without the 'N' prefix. Without the N prefix, the string is converted to the default code page of the database. This default code page may not recognize certain characters. For more information, see nchar and nvarchar (Transact-SQL) at docs.microsoft.com. Example (Microsoft SQL Server): 'SELECT 'abcde' AS a;\nSELECT N'abcde' AS b;\nSELECT 'абвгд' AS c;\nSELECT N'абвгд' AS d;' The 'SELECT 'абвгд' AS c;' does not have the 'N' prefix, the ''абвгд'' part will be highlighted.",
                  "markdown": "Reports string literals that use national characters without the `N` prefix.\n\nWithout the N prefix, the string is converted to the default\ncode page of the database. This default code page may not recognize certain characters. For more information, see\n[nchar and nvarchar\n(Transact-SQL)\nat docs.microsoft.com](https://docs.microsoft.com/en-us/sql/t-sql/data-types/nchar-and-nvarchar-transact-sql).\n\nExample (Microsoft SQL Server):\n\n    SELECT 'abcde' AS a;\n    SELECT N'abcde' AS b;\n    SELECT 'абвгд' AS c;\n    SELECT N'абвгд' AS d;\n\nThe `SELECT 'абвгд' AS c;` does not have the `N` prefix, the `'абвгд'` part will be highlighted."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlGotoInspection",
                "shortDescription": {
                  "text": "Usages of GOTO statements"
                },
                "fullDescription": {
                  "text": "Reports usages of backward GOTO statements and GOTO statements used to exit a loop. The extensive use of GOTO statements is generally not recommended. For details, see GOTO statement in SQL procedures at ibm.com. Instead of jumping back to a previous statement using GOTO, consider using a loop. Instead of exiting the WHILE loop with GOTO, consider using other control-of-flow statements (for example, RETURN or BREAK). Example (Oracle): 'CREATE PROCEDURE test(n INT) AS\nDECLARE\n    x INT;\nBEGIN\n    x := 0;\n    GOTO a;\n    <<a>> x := 1;\n    IF (n = 0) THEN\n        GOTO a;\n    END IF;\n    WHILE TRUE\n        LOOP\n            GOTO b;\n        END LOOP;\n    <<b>> x := 3;\nEND;'",
                  "markdown": "Reports usages of backward GOTO statements and GOTO statements used to exit a loop.\n\nThe extensive use of GOTO statements is generally\nnot recommended. For details, see [GOTO statement in\nSQL\nprocedures at ibm.com](https://www.ibm.com/docs/no/db2/11.5?topic=procedures-goto-statement-in-sql).\n\nInstead of jumping back to a previous statement using GOTO, consider using a loop.\n\nInstead of exiting the WHILE loop with GOTO, consider using other control-of-flow statements (for example, RETURN or BREAK).\n\nExample (Oracle):\n\n    CREATE PROCEDURE test(n INT) AS\n    DECLARE\n        x INT;\n    BEGIN\n        x := 0;\n        GOTO a;\n        <<a>> x := 1;\n        IF (n = 0) THEN\n            GOTO a;\n        END IF;\n        WHILE TRUE\n            LOOP\n                GOTO b;\n            END LOOP;\n        <<b>> x := 3;\n    END;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlUnusedVariableInspection",
                "shortDescription": {
                  "text": "Unused variable"
                },
                "fullDescription": {
                  "text": "Reports unused arguments, variables, or parameters. Example (PostgreSQL): 'CREATE FUNCTION foo(PARAMUSED INT, PARAMUNUSED INT) RETURNS INT AS\n$$\nBEGIN\n    RETURN PARAMUSED;\nEND\n$$ LANGUAGE plpgsql;' The 'PARAMUNUSED' parameter is not used in the function and might be deleted.",
                  "markdown": "Reports unused arguments, variables, or parameters.\n\nExample (PostgreSQL):\n\n    CREATE FUNCTION foo(PARAMUSED INT, PARAMUNUSED INT) RETURNS INT AS\n    $$\n    BEGIN\n        RETURN PARAMUSED;\n    END\n    $$ LANGUAGE plpgsql;\n\nThe `PARAMUNUSED` parameter is not used in the function and might be deleted."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlNoDataSourceInspection",
                "shortDescription": {
                  "text": "No data sources configured"
                },
                "fullDescription": {
                  "text": "Reports the absence of data sources in the Database tool window (View | Tool Windows | Database).",
                  "markdown": "Reports the absence of data sources in the **Database** tool window (**View \\| Tool Windows \\| Database**)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlWithoutWhereInspection",
                "shortDescription": {
                  "text": "Delete or update statement without where clauses"
                },
                "fullDescription": {
                  "text": "Reports usages of DELETE or UPDATE statements without WHERE clauses. Without WHERE clauses, DELETE drops all the data from the table, and UPDATE overwrites values for all the table rows. Example (MySQL): 'CREATE TABLE t1 (a TEXT, b INT, c BOOLEAN);\nupdate t1 set  a = 'Smith';\ndelete from t1;'",
                  "markdown": "Reports usages of DELETE or UPDATE statements without WHERE clauses.\n\nWithout WHERE clauses, DELETE drops all the data from the table, and UPDATE overwrites values for all the table rows.\n\nExample (MySQL):\n\n    CREATE TABLE t1 (a TEXT, b INT, c BOOLEAN);\n    update t1 set  a = 'Smith';\n    delete from t1;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlAmbiguousColumnInspection",
                "shortDescription": {
                  "text": "Ambiguous reference"
                },
                "fullDescription": {
                  "text": "Reports columns that have identical names but belong to different tables. Example (MySQL): 'CREATE TABLE foo(id INT PRIMARY KEY);\nCREATE TABLE bar(id INT PRIMARY KEY);\n\nSELECT foo.id, bar.id FROM foo, bar WHERE id > 0;' The 'id' column appears in 'foo' and 'bar' tables. You need to qualify the column name to make the query correct. 'SELECT foo.id, bar.id FROM foo, bar WHERE foo.id > 0;'",
                  "markdown": "Reports columns that have identical names but belong to different tables.\n\nExample (MySQL):\n\n    CREATE TABLE foo(id INT PRIMARY KEY);\n    CREATE TABLE bar(id INT PRIMARY KEY);\n\n    SELECT foo.id, bar.id FROM foo, bar WHERE id > 0;\n\nThe `id` column appears in `foo` and `bar` tables. You need to qualify the column name to\nmake the query correct.\n\n    SELECT foo.id, bar.id FROM foo, bar WHERE foo.id > 0;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlUnusedCteInspection",
                "shortDescription": {
                  "text": "Unused common table expression"
                },
                "fullDescription": {
                  "text": "Reports unused common table expressions (CTE) inside the query. Example (PostgreSQL): 'CREATE TABLE foo(a INT);\n\nWITH a AS (SELECT 1 AS x FROM foo)\nSELECT 1 + 2 FROM foo;' By using WITH, we create a temporary named result set with the name 'a', also known as a common table expression (CTE). But we do not use this CTE later in the code. The unused CTE is greyed out.",
                  "markdown": "Reports unused common table expressions (CTE) inside the query.\n\nExample (PostgreSQL):\n\n    CREATE TABLE foo(a INT);\n\n    WITH a AS (SELECT 1 AS x FROM foo)\n    SELECT 1 + 2 FROM foo;\n\nBy using WITH, we create a temporary named result set with the name `a`, also known as a common table expression (CTE). But\nwe do not use this CTE later in the code. The unused CTE is greyed out."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "MongoJSResolveInspection",
                "shortDescription": {
                  "text": "Resolution problems"
                },
                "fullDescription": {
                  "text": "Reports unresolved references in MongoDB and JavaScript code. Example: 'db\nuse foo\n  -- a reference to a non-existing collection\ndb.non_existing_collection\ndb['non_existing_collection']\ndb['non_existing_collection'].find().hasNext()' The 'non_existing_collection' collection does not exist in the database and will be reported.",
                  "markdown": "Reports unresolved references in MongoDB and JavaScript code.\n\nExample:\n\n    db\n    use foo\n      -- a reference to a non-existing collection\n    db.non_existing_collection\n    db['non_existing_collection']\n    db['non_existing_collection'].find().hasNext()\n\nThe `non_existing_collection` collection does not exist in the database and will be reported."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "MongoJS",
                      "index": 9,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlResolveInspection",
                "shortDescription": {
                  "text": "Unresolved reference"
                },
                "fullDescription": {
                  "text": "Reports unresolved SQL references. Example (MySQL): 'CREATE TABLE users(id INT, name VARCHAR(40));\nCREATE TABLE admins(id INT, col1 INT);\n\nSELECT users.id, admins.id FROM admins WHERE admins.id > 1;' The 'users.id' column is unresolved because the 'users' table is missing in the FROM clause.",
                  "markdown": "Reports unresolved SQL references.\n\nExample (MySQL):\n\n    CREATE TABLE users(id INT, name VARCHAR(40));\n    CREATE TABLE admins(id INT, col1 INT);\n\n    SELECT users.id, admins.id FROM admins WHERE admins.id > 1;\n\nThe `users.id` column is unresolved because the `users` table is missing in the FROM clause."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SqlNullComparisonInspection",
                "shortDescription": {
                  "text": "Null comparison"
                },
                "fullDescription": {
                  "text": "Reports comparisons with NULL that can be replaced with IS NULL or IS NOT NULL operators. Example (Microsoft SQL Server): 'CREATE TABLE foo ( id int );\n\nSELECT * FROM foo WHERE NULL = NULL;\nSELECT * FROM foo WHERE NULL != NULL;' The 'NULL = NULL' can be replaced with 'IS NULL', the 'NULL != NULL' comparison with 'IS NOT NULL'. To do this replacement, you can use Use IS NULL operator or Use IS NOT NULL operator quick-fixes. 'SELECT * FROM foo WHERE NULL IS NULL;\nSELECT * FROM foo WHERE NULL IS NOT NULL;'",
                  "markdown": "Reports comparisons with NULL that can be replaced with IS NULL or IS NOT NULL operators.\n\nExample (Microsoft SQL Server):\n\n    CREATE TABLE foo ( id int );\n\n    SELECT * FROM foo WHERE NULL = NULL;\n    SELECT * FROM foo WHERE NULL != NULL;\n\nThe `NULL = NULL` can be replaced with `IS NULL`, the `NULL != NULL` comparison\nwith `IS NOT NULL`. To do this replacement, you can use **Use IS NULL operator** or **Use IS NOT NULL operator**\nquick-fixes.\n\n    SELECT * FROM foo WHERE NULL IS NULL;\n    SELECT * FROM foo WHERE NULL IS NOT NULL;\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "SQL",
                      "index": 5,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          },
          {
            "name": "com.intellij",
            "version": "223.8782.115",
            "rules": [
              {
                "id": "XmlHighlighting",
                "shortDescription": {
                  "text": "XML highlighting"
                },
                "fullDescription": {
                  "text": "Reports XML validation problems in the results of a batch code inspection.",
                  "markdown": "Reports XML validation problems in the results of a batch code inspection."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "XML",
                      "index": 6,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "JsonSchemaDeprecation",
                "shortDescription": {
                  "text": "Deprecated JSON property"
                },
                "fullDescription": {
                  "text": "Reports a deprecated property in a JSON file. Note that deprecation mechanism is not defined in the JSON Schema specification yet, and this inspection uses a non-standard extension 'deprecationMessage'.",
                  "markdown": "Reports a deprecated property in a JSON file.  \nNote that deprecation mechanism is not defined in the JSON Schema specification yet, and this inspection uses a non-standard extension 'deprecationMessage'."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "JSON and JSON5",
                      "index": 8,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "XmlDuplicatedId",
                "shortDescription": {
                  "text": "Duplicate 'id' attribute"
                },
                "fullDescription": {
                  "text": "Reports a duplicate 'id' attribute in XML.",
                  "markdown": "Reports a duplicate `id` attribute in XML."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "XML",
                      "index": 6,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpDuplicateCharacterInClass",
                "shortDescription": {
                  "text": "Duplicate character in character class"
                },
                "fullDescription": {
                  "text": "Reports duplicate characters inside a RegExp character class. Duplicate characters are unnecessary and can be removed without changing the semantics of the regex. Example: '[aabc]' After the quick-fix is applied: '[abc]'",
                  "markdown": "Reports duplicate characters inside a RegExp character class. Duplicate characters are unnecessary and can be removed without changing the semantics of the regex.\n\n**Example:**\n\n\n      [aabc]\n\nAfter the quick-fix is applied:\n\n\n      [abc]\n"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "JsonSchemaRefReference",
                "shortDescription": {
                  "text": "Unresolved '$ref' and '$schema' references"
                },
                "fullDescription": {
                  "text": "Reports an unresolved '$ref' or '$schema' path in a JSON schema.",
                  "markdown": "Reports an unresolved `$ref` or `$schema` path in a JSON schema.  "
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "JSON and JSON5",
                      "index": 8,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlUnknownBooleanAttribute",
                "shortDescription": {
                  "text": "Incorrect boolean attribute"
                },
                "fullDescription": {
                  "text": "Reports an HTML non-boolean attribute without a value. Suggests configuring attributes that should not be reported.",
                  "markdown": "Reports an HTML non-boolean attribute without a value. Suggests configuring attributes that should not be reported."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "XmlInvalidId",
                "shortDescription": {
                  "text": "Unresolved 'id' reference"
                },
                "fullDescription": {
                  "text": "Reports an unresolved 'id' reference in XML.",
                  "markdown": "Reports an unresolved `id` reference in XML."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "XML",
                      "index": 6,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "XmlUnboundNsPrefix",
                "shortDescription": {
                  "text": "Unbound namespace prefix"
                },
                "fullDescription": {
                  "text": "Reports an unbound namespace prefix in XML.",
                  "markdown": "Reports an unbound namespace prefix in XML."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "XML",
                      "index": 6,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RequiredAttributes",
                "shortDescription": {
                  "text": "Missing required attribute"
                },
                "fullDescription": {
                  "text": "Reports a missing mandatory attribute in an XML/HTML tag. Suggests configuring attributes that should not be reported.",
                  "markdown": "Reports a missing mandatory attribute in an XML/HTML tag. Suggests configuring attributes that should not be reported."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DuplicatedCode",
                "shortDescription": {
                  "text": "Duplicated code fragment"
                },
                "fullDescription": {
                  "text": "Reports duplicated blocks of code from the selected scope: the same file or the entire project. The inspection features quick-fixes that help you to set the size of detected duplicates, navigate to repetitive code fragments, and compare them in a tool window. The inspection options allow you to select the scope of the reported duplicated fragments and set the initial size for the duplicated language constructs. You can also configure the constructs that you want to anonymize in File | Settings | Editor | Duplicates.",
                  "markdown": "Reports duplicated blocks of code from the selected scope: the same file or the entire project. The inspection features quick-fixes that help you to set the size of detected duplicates, navigate to repetitive code fragments, and compare them in a tool window. The inspection options allow you to select the scope of the reported duplicated fragments and set the initial size for the duplicated language constructs. You can also configure the constructs that you want to anonymize in [File \\| Settings \\| Editor \\| Duplicates](settings://duplicates.index)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "InconsistentLineSeparators",
                "shortDescription": {
                  "text": "Inconsistent line separators"
                },
                "fullDescription": {
                  "text": "Reports files with line separators different from the ones that are specified in the project's settings. For example, the inspection will be triggered if you set the line separator to '\\n' in Settings | Editor | Code Style | Line separator, while the file you are editing uses '\\r\\n' as a line separator. The inspection also warns you about mixed line separators within a file.",
                  "markdown": "Reports files with line separators different from the ones that are specified in the project's settings.\n\nFor example, the inspection will be triggered if you set the line separator to `\\n` in\n[Settings \\| Editor \\| Code Style \\| Line separator](settings://preferences.sourceCode?Line%20separator),\nwhile the file you are editing uses `\\r\\n` as a line separator.\n\nThe inspection also warns you about mixed line separators within a file."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "ReassignedToPlainText",
                "shortDescription": {
                  "text": "Reassigned to plain text"
                },
                "fullDescription": {
                  "text": "Reports files that were explicitly re-assigned to Plain Text File Type. This association is unnecessary because the platform auto-detects text files by content automatically. You can dismiss this warning by removing the file type association in Settings | Editor | File Types | Text.",
                  "markdown": "Reports files that were explicitly re-assigned to Plain Text File Type. This association is unnecessary because the platform auto-detects text files by content automatically.\n\nYou can dismiss this warning by removing the file type association\nin **Settings \\| Editor \\| File Types \\| Text**."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RedundantSuppression",
                "shortDescription": {
                  "text": "Redundant suppression"
                },
                "fullDescription": {
                  "text": "Reports usages of the following elements that can be safely removed because the inspection they affect is no longer applicable in this context: '@SuppressWarning' annotation, or '// noinspection' line comment, or '/** noinspection */' JavaDoc comment Example: 'public class C {\n // symbol is already private,\n // but annotation is still around\n  @SuppressWarnings({\"WeakerAccess\"})\n private boolean CONST = true;\n void f() {\n    CONST = false;\n  }\n}'",
                  "markdown": "Reports usages of the following elements that can be safely removed because the inspection they affect is no longer applicable in this context:\n\n* `@SuppressWarning` annotation, or\n* `// noinspection` line comment, or\n* `/** noinspection */` JavaDoc comment\n\nExample:\n\n\n    public class C {\n     // symbol is already private,\n     // but annotation is still around\n      @SuppressWarnings({\"WeakerAccess\"})\n     private boolean CONST = true;\n     void f() {\n        CONST = false;\n      }\n    }\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "ProblematicWhitespace",
                "shortDescription": {
                  "text": "Problematic whitespace"
                },
                "fullDescription": {
                  "text": "Reports the following problems: Tabs used for indentation when the code style is configured to use only spaces. Spaces used for indentation when the code style is configured to use only tabs. Spaces used for indentation and tabs used for alignment when the code style is configured to use smart tabs.",
                  "markdown": "Reports the following problems:\n\n* Tabs used for indentation when the code style is configured to use only spaces.\n* Spaces used for indentation when the code style is configured to use only tabs.\n* Spaces used for indentation and tabs used for alignment when the code style is configured to use smart tabs."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlUnknownTarget",
                "shortDescription": {
                  "text": "Unresolved file in a link"
                },
                "fullDescription": {
                  "text": "Reports an unresolved file in a link.",
                  "markdown": "Reports an unresolved file in a link."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SSBasedInspection",
                "shortDescription": {
                  "text": "Structural search inspection"
                },
                "fullDescription": {
                  "text": "Allows configuring Structural Search/Structural Replace templates that you can apply to the file you are editing. All matches will be highlighted and marked with the template name that you have configured. If you configure the Structural Replace pattern as well, the corresponding replace option will be available as a quick-fix.",
                  "markdown": "Allows configuring **Structural Search/Structural Replace** templates that you can apply to the file you are editing.\n\nAll matches will be highlighted and marked with the template name that you have configured.\nIf you configure the **Structural Replace** pattern as well, the corresponding replace option will be available as a quick-fix."
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Structural search",
                      "index": 21,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "LongLine",
                "shortDescription": {
                  "text": "Line is longer than allowed by code style"
                },
                "fullDescription": {
                  "text": "Reports lines that are longer than the Hard wrap at parameter specified in Settings | Editor | Code Style | General.",
                  "markdown": "Reports lines that are longer than the **Hard wrap at** parameter specified in [Settings \\| Editor \\| Code Style \\| General](settings://preferences.sourceCode?Hard%20wrap%20at)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "XmlUnusedNamespaceDeclaration",
                "shortDescription": {
                  "text": "Unused schema declaration"
                },
                "fullDescription": {
                  "text": "Reports an unused namespace declaration or location hint in XML.",
                  "markdown": "Reports an unused namespace declaration or location hint in XML."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "XML",
                      "index": 6,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpRedundantClassElement",
                "shortDescription": {
                  "text": "Redundant '\\d', '[:digit:]', or '\\D' class elements"
                },
                "fullDescription": {
                  "text": "Reports redundant '\\d' or '[:digit:]' that are used in one class with '\\w' or '[:word:]' ('\\D' with '\\W') and can be removed. Example: '[\\w\\d]' After the quick-fix is applied: '[\\w]' New in 2022.2",
                  "markdown": "Reports redundant `\\d` or `[:digit:]` that are used in one class with `\\w` or `[:word:]` (`\\D` with `\\W`) and can be removed.\n\n**Example:**\n\n\n      [\\w\\d]\n\nAfter the quick-fix is applied:\n\n\n      [\\w]\n\nNew in 2022.2"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpSimplifiable",
                "shortDescription": {
                  "text": "Regular expression can be simplified"
                },
                "fullDescription": {
                  "text": "Reports regular expressions that can be simplified. Example: '[a] xx* [ah-hz]' After the quick-fix is applied: 'a x+ [ahz]' New in 2022.1",
                  "markdown": "Reports regular expressions that can be simplified.\n\n**Example:**\n\n\n      [a] xx* [ah-hz]\n\nAfter the quick-fix is applied:\n\n\n      a x+ [ahz]\n\nNew in 2022.1"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "XmlWrongRootElement",
                "shortDescription": {
                  "text": "Wrong root element"
                },
                "fullDescription": {
                  "text": "Reports a root tag name different from the name specified in the '<doctype>' tag.",
                  "markdown": "Reports a root tag name different from the name specified in the `<doctype>` tag."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "XML",
                      "index": 6,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpEmptyAlternationBranch",
                "shortDescription": {
                  "text": "Empty branch in alternation"
                },
                "fullDescription": {
                  "text": "Reports empty branches in a RegExp alternation. An empty branch will only match the empty string, and in most cases that is not what is desired. This inspection will not report a single empty branch at the start or the end of an alternation. Example: '(alpha||bravo)' After the quick-fix is applied: '(alpha|bravo)' New in 2017.2",
                  "markdown": "Reports empty branches in a RegExp alternation. An empty branch will only match the empty string, and in most cases that is not what is desired. This inspection will not report a single empty branch at the start or the end of an alternation.\n\n**Example:**\n\n\n      (alpha||bravo)\n\nAfter the quick-fix is applied:\n\n\n      (alpha|bravo)\n\nNew in 2017.2"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "JsonPathEvaluateUnknownKey",
                "shortDescription": {
                  "text": "Unknown property key used for JSONPath evaluate expression"
                },
                "fullDescription": {
                  "text": "Reports a key in a JSONPath expression that is missing in the source JSON document to evaluate.",
                  "markdown": "Reports a key in a JSONPath expression that is missing in the source JSON document to evaluate."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "JSON and JSON5",
                      "index": 8,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CheckValidXmlInScriptTagBody",
                "shortDescription": {
                  "text": "Malformed content of 'script' tag"
                },
                "fullDescription": {
                  "text": "Reports contents of 'script' tags that are invalid XML. Example: '<script type=\"text/javascript\">\n    console.log('<');\n  </script>' After the quick-fix is applied: '<script type=\"text/javascript\">\n    console.log('&lt;');\n  </script>'",
                  "markdown": "Reports contents of `script` tags that are invalid XML.  \n\n**Example:**\n\n\n      <script type=\"text/javascript\">\n        console.log('<');\n      </script>\n\nAfter the quick-fix is applied:\n\n\n      <script type=\"text/javascript\">\n        console.log('&lt;');\n      </script>\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "Annotator",
                "shortDescription": {
                  "text": "Annotator"
                },
                "fullDescription": {
                  "text": "Reports problems that are found by language annotators in the result of a batch code inspection run.",
                  "markdown": "Reports problems that are found by language annotators in the result of a batch code inspection run."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpSuspiciousBackref",
                "shortDescription": {
                  "text": "Suspicious back reference"
                },
                "fullDescription": {
                  "text": "Reports back references that will not be resolvable at runtime. This means that the back reference can never match anything. A back reference will not be resolvable when the group is defined after the back reference, or if the group is defined in a different branch of an alternation. Example of a group defined after its back reference: '\\1(abc)' Example of a group and a back reference in different branches: 'a(b)c|(xy)\\1z' New in 2022.1",
                  "markdown": "Reports back references that will not be resolvable at runtime. This means that the back reference can never match anything. A back reference will not be resolvable when the group is defined after the back reference, or if the group is defined in a different branch of an alternation.\n\n**Example of a group defined after its back reference:**\n\n\n      \\1(abc)\n\n**Example of a group and a back reference in different branches:**\n\n\n      a(b)c|(xy)\\1z\n\nNew in 2022.1"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "XmlPathReference",
                "shortDescription": {
                  "text": "Unresolved file reference"
                },
                "fullDescription": {
                  "text": "Reports an unresolved file reference in XML.",
                  "markdown": "Reports an unresolved file reference in XML."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "XML",
                      "index": 6,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpSingleCharAlternation",
                "shortDescription": {
                  "text": "Single character alternation"
                },
                "fullDescription": {
                  "text": "Reports single char alternation in a RegExp. It is simpler to use a character class instead. This may also provide better matching performance. Example: 'a|b|c|d' After the quick-fix is applied: '[abcd]' New in 2017.1",
                  "markdown": "Reports single char alternation in a RegExp. It is simpler to use a character class instead. This may also provide better matching performance.\n\n**Example:**\n\n\n      a|b|c|d\n\nAfter the quick-fix is applied:\n\n\n      [abcd]\n\n\nNew in 2017.1"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpUnnecessaryNonCapturingGroup",
                "shortDescription": {
                  "text": "Unnecessary non-capturing group"
                },
                "fullDescription": {
                  "text": "Reports unnecessary non-capturing groups, which have no influence on the match result. Example: 'Everybody be cool, (?:this) is a robbery!' After the quick-fix is applied: 'Everybody be cool, this is a robbery!' New in 2021.1",
                  "markdown": "Reports unnecessary non-capturing groups, which have no influence on the match result.\n\n**Example:**\n\n\n      Everybody be cool, (?:this) is a robbery!\n\nAfter the quick-fix is applied:\n\n\n      Everybody be cool, this is a robbery!\n\nNew in 2021.1"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "TodoComment",
                "shortDescription": {
                  "text": "TODO comment"
                },
                "fullDescription": {
                  "text": "Reports TODO comments in your code. You can configure the format for TODO comments in Settings | Editor | TODO. Enable the Only warn on TODO comments without any details option to only warn on empty TODO comments, that don't provide any description on the task that should be done. Disable to report all TODO comments.",
                  "markdown": "Reports **TODO** comments in your code.\n\nYou can configure the format for **TODO** comments in [Settings \\| Editor \\| TODO](settings://preferences.toDoOptions).\n\nEnable the **Only warn on TODO comments without any details** option to only warn on empty TODO comments, that\ndon't provide any description on the task that should be done. Disable to report all TODO comments."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlUnknownAttribute",
                "shortDescription": {
                  "text": "Unknown attribute"
                },
                "fullDescription": {
                  "text": "Reports an unknown HTML attribute. Suggests configuring attributes that should not be reported.",
                  "markdown": "Reports an unknown HTML attribute. Suggests configuring attributes that should not be reported."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CheckTagEmptyBody",
                "shortDescription": {
                  "text": "Empty element content"
                },
                "fullDescription": {
                  "text": "Reports XML elements without contents. Example: '<user>\n    <name></name>\n  </user>' After the quick-fix is applied: '<user>\n    <name/>\n  </user>'",
                  "markdown": "Reports XML elements without contents.\n\n**Example:**\n\n\n      <user>\n        <name></name>\n      </user>\n\nAfter the quick-fix is applied:\n\n\n      <user>\n        <name/>\n      </user>\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "XML",
                      "index": 6,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpRedundantEscape",
                "shortDescription": {
                  "text": "Redundant character escape"
                },
                "fullDescription": {
                  "text": "Reports redundant character escape sequences that can be replaced with unescaped characters preserving the meaning. Many escape sequences that are necessary outside of a character class are redundant inside square brackets '[]' of a character class. Although unescaped opening curly braces '{' outside of character classes are allowed in some dialects (JavaScript, Python, and so on), it can cause confusion and make the pattern less portable, because there are dialects that require escaping curly braces as characters. For this reason the inspection does not report escaped opening curly braces. Example: '\\-\\;[\\.]' After the quick-fix is applied: '-;[.]' The Ignore escaped closing brackets '}' and ']' option specifies whether to report '\\}' and '\\]' outside of a character class when they are allowed to be unescaped by the RegExp dialect. New in 2017.3",
                  "markdown": "Reports redundant character escape sequences that can be replaced with unescaped characters preserving the meaning. Many escape sequences that are necessary outside of a character class are redundant inside square brackets `[]` of a character class.\n\n\nAlthough unescaped opening curly braces `{` outside of character classes are allowed in some dialects (JavaScript, Python, and so on),\nit can cause confusion and make the pattern less portable, because there are dialects that require escaping curly braces as characters.\nFor this reason the inspection does not report escaped opening curly braces.\n\n**Example:**\n\n\n      \\-\\;[\\.]\n\nAfter the quick-fix is applied:\n\n\n      -;[.]\n\n\nThe **Ignore escaped closing brackets '}' and '\\]'** option specifies whether to report `\\}` and `\\]` outside of a character class\nwhen they are allowed to be unescaped by the RegExp dialect.\n\nNew in 2017.3"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "Json5StandardCompliance",
                "shortDescription": {
                  "text": "Compliance with JSON5 standard"
                },
                "fullDescription": {
                  "text": "Reports inconsistency with the language specification in a JSON5 file.",
                  "markdown": "Reports inconsistency with [the language specification](http://json5.org) in a JSON5 file."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "JSON and JSON5",
                      "index": 8,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "JsonDuplicatePropertyKeys",
                "shortDescription": {
                  "text": "Duplicate keys in object literals"
                },
                "fullDescription": {
                  "text": "Reports a duplicate key in an object literal.",
                  "markdown": "Reports a duplicate key in an object literal."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "JSON and JSON5",
                      "index": 8,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "UnresolvedReference",
                "shortDescription": {
                  "text": "Unresolved reference"
                },
                "fullDescription": {
                  "text": "Reports an unresolved reference to a named pattern ('define') in RELAX-NG files that use XML syntax. Suggests creating the referenced 'define' element.",
                  "markdown": "Reports an unresolved reference to a named pattern (`define`) in RELAX-NG files that use XML syntax. Suggests creating the referenced `define` element."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RELAX NG",
                      "index": 25,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "JsonPathUnknownFunction",
                "shortDescription": {
                  "text": "Unknown JSONPath function"
                },
                "fullDescription": {
                  "text": "Reports an unknown name in a JSONPath function call instead of known standard function names: 'concat', 'keys', 'length', 'min', 'max', 'avg', 'stddev', 'sum'.",
                  "markdown": "Reports an unknown name in a JSONPath function call instead of known standard function names: `concat`, `keys`, `length`, `min`, `max`, `avg`, `stddev`, `sum`."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "JSON and JSON5",
                      "index": 8,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlMissingClosingTag",
                "shortDescription": {
                  "text": "Missing closing tag"
                },
                "fullDescription": {
                  "text": "Reports an HTML element without a closing tag. Some coding styles require that HTML elements have closing tags even where this is optional. Example: '<html>\n    <body>\n      <p>Behold!\n    </body>\n  </html>' After the quick-fix is applied: '<html>\n    <body>\n      <p>Behold!</p>\n    </body>\n  </html>'",
                  "markdown": "Reports an HTML element without a closing tag. Some coding styles require that HTML elements have closing tags even where this is optional.\n\n**Example:**\n\n\n      <html>\n        <body>\n          <p>Behold!\n        </body>\n      </html>\n\nAfter the quick-fix is applied:\n\n\n      <html>\n        <body>\n          <p>Behold!</p>\n        </body>\n      </html>\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "INFORMATION"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpRedundantNestedCharacterClass",
                "shortDescription": {
                  "text": "Redundant nested character class"
                },
                "fullDescription": {
                  "text": "Reports unnecessary nested character classes. Example: '[a-c[x-z]]' After the quick-fix is applied: '[a-cx-z]' New in 2020.2",
                  "markdown": "Reports unnecessary nested character classes.\n\n**Example:**\n\n\n      [a-c[x-z]]\n\nAfter the quick-fix is applied:\n\n\n      [a-cx-z]\n\nNew in 2020.2"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "XmlDeprecatedElement",
                "shortDescription": {
                  "text": "Deprecated symbol"
                },
                "fullDescription": {
                  "text": "Reports a deprecated XML element or attribute. Symbols can be marked by XML comment or documentation tag with text 'deprecated'.",
                  "markdown": "Reports a deprecated XML element or attribute.\n\nSymbols can be marked by XML comment or documentation tag with text 'deprecated'."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "XML",
                      "index": 6,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "IncorrectFormatting",
                "shortDescription": {
                  "text": "Incorrect formatting"
                },
                "fullDescription": {
                  "text": "Reports formatting issues that appear if your code doesn't follow your project's code style settings. This inspection is not compatible with languages that require third-party formatters for code formatting, for example, Go or C with CLangFormat enabled.",
                  "markdown": "Reports formatting issues that appear if your code doesn't\nfollow your project's code style settings.\n\n\nThis inspection is not compatible with languages that require\nthird-party formatters for code formatting, for example, Go or\nC with CLangFormat enabled."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlWrongAttributeValue",
                "shortDescription": {
                  "text": "Wrong attribute value"
                },
                "fullDescription": {
                  "text": "Reports an incorrect HTML attribute value.",
                  "markdown": "Reports an incorrect HTML attribute value."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "XmlDefaultAttributeValue",
                "shortDescription": {
                  "text": "Redundant attribute with default value"
                },
                "fullDescription": {
                  "text": "Reports a redundant assignment of the default value to an XML attribute.",
                  "markdown": "Reports a redundant assignment of the default value to an XML attribute."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "XML",
                      "index": 6,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlExtraClosingTag",
                "shortDescription": {
                  "text": "Redundant closing tag"
                },
                "fullDescription": {
                  "text": "Reports redundant closing tags on empty elements, for example, 'img' or 'br'. Example: '<html>\n    <body>\n      <br></br>\n    </body>\n  </html>' After the quick-fix is applied: '<html>\n    <body>\n      <br>\n    </body>\n  </html>'",
                  "markdown": "Reports redundant closing tags on empty elements, for example, `img` or `br`.\n\n**Example:**\n\n\n      <html>\n        <body>\n          <br></br>\n        </body>\n      </html>\n\nAfter the quick-fix is applied:\n\n\n      <html>\n        <body>\n          <br>\n        </body>\n      </html>\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpOctalEscape",
                "shortDescription": {
                  "text": "Octal escape"
                },
                "fullDescription": {
                  "text": "Reports octal escapes, which are easily confused with back references. Use hexadecimal escapes to avoid confusion. Example: '\\07' After the quick-fix is applied: '\\x07' New in 2017.1",
                  "markdown": "Reports octal escapes, which are easily confused with back references. Use hexadecimal escapes to avoid confusion.\n\n**Example:**\n\n\n      \\07\n\nAfter the quick-fix is applied:\n\n\n      \\x07\n\nNew in 2017.1"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "INFORMATION"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "UnusedDefine",
                "shortDescription": {
                  "text": "Unused define"
                },
                "fullDescription": {
                  "text": "Reports an unused named pattern ('define') in a RELAX-NG file (XML or Compact Syntax). 'define' elements that are used through an include in another file are ignored.",
                  "markdown": "Reports an unused named pattern (`define`) in a RELAX-NG file (XML or Compact Syntax). `define` elements that are used through an include in another file are ignored."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RELAX NG",
                      "index": 25,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlUnknownAnchorTarget",
                "shortDescription": {
                  "text": "Unresolved fragment in a link"
                },
                "fullDescription": {
                  "text": "Reports an unresolved last part of an URL after the '#' sign.",
                  "markdown": "Reports an unresolved last part of an URL after the `#` sign."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "JsonSchemaCompliance",
                "shortDescription": {
                  "text": "Compliance with JSON schema"
                },
                "fullDescription": {
                  "text": "Reports inconsistence between a JSON file and the JSON schema that is assigned to it.",
                  "markdown": "Reports inconsistence between a JSON file and the [JSON schema](https://json-schema.org) that is assigned to it.  "
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "JSON and JSON5",
                      "index": 8,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpUnexpectedAnchor",
                "shortDescription": {
                  "text": "Begin or end anchor in unexpected position"
                },
                "fullDescription": {
                  "text": "Reports '^' or '\\A' anchors not at the beginning of the pattern and '$', '\\Z' or '\\z' anchors not at the end of the pattern. In the wrong position these RegExp anchors prevent the pattern from matching anything. In case of the '^' and '$' anchors, most likely the literal character was meant and the escape forgotten. Example: '(Price $10)' New in 2018.1",
                  "markdown": "Reports `^` or `\\A` anchors not at the beginning of the pattern and `$`, `\\Z` or `\\z` anchors not at the end of the pattern. In the wrong position these RegExp anchors prevent the pattern from matching anything. In case of the `^` and `$` anchors, most likely the literal character was meant and the escape forgotten.\n\n**Example:**\n\n\n      (Price $10)\n\n\nNew in 2018.1"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "EmptyDirectory",
                "shortDescription": {
                  "text": "Empty directory"
                },
                "fullDescription": {
                  "text": "Reports empty directories. Available only from Code | Inspect Code or Code | Analyze Code | Run Inspection by Name and isn't reported in the editor. Use the Only report empty directories located under a source folder option to have only directories under source roots reported.",
                  "markdown": "Reports empty directories.\n\nAvailable only from **Code \\| Inspect Code** or\n**Code \\| Analyze Code \\| Run Inspection by Name** and isn't reported in the editor.\n\nUse the **Only report empty directories located under a source folder** option to have only directories under source\nroots reported."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SyntaxError",
                "shortDescription": {
                  "text": "Syntax error"
                },
                "fullDescription": {
                  "text": "Reports syntax errors that have been found in the result of a batch code inspection run.",
                  "markdown": "Reports syntax errors that have been found in the result of a batch code inspection run."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpAnonymousGroup",
                "shortDescription": {
                  "text": "Anonymous capturing group or numeric back reference"
                },
                "fullDescription": {
                  "text": "Reports anonymous capturing groups and numeric back references in a RegExp. These are only reported when the RegExp dialect supports named group and named group references. Named groups and named back references improve code readability and are recommended to use instead. When a capture is not needed, matching can be more performant and use less memory by using a non-capturing group, i.e. '(?:xxx)' instead of '(xxx)'. Example: '(\\d\\d\\d\\d)\\1' A better regex pattern could look like this: '(?<quad>\\d\\d\\d\\d)\\k<quad>' New in 2017.2",
                  "markdown": "Reports anonymous capturing groups and numeric back references in a RegExp. These are only reported when the RegExp dialect supports named group and named group references. Named groups and named back references improve code readability and are recommended to use instead. When a capture is not needed, matching can be more performant and use less memory by using a non-capturing group, i.e. `(?:xxx)` instead of `(xxx)`.\n\n**Example:**\n\n\n      (\\d\\d\\d\\d)\\1\n\nA better regex pattern could look like this:\n\n\n      (?<quad>\\d\\d\\d\\d)\\k<quad>\n\nNew in 2017.2"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CheckDtdRefs",
                "shortDescription": {
                  "text": "Unresolved DTD reference"
                },
                "fullDescription": {
                  "text": "Reports inconsistency in a DTD-specific reference, for example, in a reference to an XML entity or to a DTD element declaration. Works in DTD an XML files.",
                  "markdown": "Reports inconsistency in a DTD-specific reference, for example, in a reference to an XML entity or to a DTD element declaration. Works in DTD an XML files."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "XML",
                      "index": 6,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "SpellCheckingInspection",
                "shortDescription": {
                  "text": "Typo"
                },
                "fullDescription": {
                  "text": "Reports typos and misspellings in your code, comments, and literals and fixes them with one click.",
                  "markdown": "Reports typos and misspellings in your code, comments, and literals and fixes them with one click."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "TYPO"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Proofreading",
                      "index": 26,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CheckXmlFileWithXercesValidator",
                "shortDescription": {
                  "text": "Failed external validation"
                },
                "fullDescription": {
                  "text": "Reports a discrepancy in an XML file with the specified DTD or schema detected by the Xerces validator.",
                  "markdown": "Reports a discrepancy in an XML file with the specified DTD or schema detected by the Xerces validator."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "XML",
                      "index": 6,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "NonAsciiCharacters",
                "shortDescription": {
                  "text": "Non-ASCII characters"
                },
                "fullDescription": {
                  "text": "Reports code elements that use non-ASCII symbols in an unusual context. Example: Non-ASCII characters used in identifiers, strings, or comments. Identifiers written in different languages, such as 'myСollection' with the letter 'C' written in Cyrillic. Comments or strings containing Unicode symbols, such as long dashes and arrows.",
                  "markdown": "Reports code elements that use non-ASCII symbols in an unusual context.\n\nExample:\n\n* Non-ASCII characters used in identifiers, strings, or comments.\n* Identifiers written in different languages, such as `my`**С**`ollection` with the letter **C** written in Cyrillic.\n* Comments or strings containing Unicode symbols, such as long dashes and arrows."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Internationalization",
                      "index": 29,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlUnknownTag",
                "shortDescription": {
                  "text": "Unknown tag"
                },
                "fullDescription": {
                  "text": "Reports an unknown HTML tag. Suggests configuring tags that should not be reported.",
                  "markdown": "Reports an unknown HTML tag. Suggests configuring tags that should not be reported."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "LossyEncoding",
                "shortDescription": {
                  "text": "Lossy encoding"
                },
                "fullDescription": {
                  "text": "Reports characters that cannot be displayed because of the current document encoding. Examples: If you type international characters in a document with the US-ASCII charset, some characters will be lost on save. If you load a UTF-8-encoded file using the ISO-8859-1 one-byte charset, some characters will be displayed incorrectly. You can fix this by changing the file encoding either by specifying the encoding directly in the file, e.g. by editing 'encoding=' attribute in the XML prolog of XML file, or by changing the corresponding options in Settings | Editor | File Encodings.",
                  "markdown": "Reports characters that cannot be displayed because of the current document encoding.\n\nExamples:\n\n* If you type international characters in a document with the **US-ASCII** charset, some characters will be lost on save.\n* If you load a **UTF-8** -encoded file using the **ISO-8859-1** one-byte charset, some characters will be displayed incorrectly.\n\nYou can fix this by changing the file encoding\neither by specifying the encoding directly in the file, e.g. by editing `encoding=` attribute in the XML prolog of XML file,\nor by changing the corresponding options in **Settings \\| Editor \\| File Encodings**."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Internationalization",
                      "index": 29,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpEscapedMetaCharacter",
                "shortDescription": {
                  "text": "Escaped meta character"
                },
                "fullDescription": {
                  "text": "Reports escaped meta characters. Some RegExp coding styles specify that meta characters should be placed inside a character class, to make the regular expression easier to understand. This inspection does not warn about the meta character '[', ']' and '^', because those would need additional escaping inside a character class. Example: '\\d+\\.\\d+' After the quick-fix is applied: '\\d+[.]\\d+' New in 2017.1",
                  "markdown": "Reports escaped meta characters. Some RegExp coding styles specify that meta characters should be placed inside a character class, to make the regular expression easier to understand. This inspection does not warn about the meta character `[`, `]` and `^`, because those would need additional escaping inside a character class.\n\n**Example:**\n\n\n      \\d+\\.\\d+\n\nAfter the quick-fix is applied:\n\n\n      \\d+[.]\\d+\n\nNew in 2017.1"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "INFORMATION"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpDuplicateAlternationBranch",
                "shortDescription": {
                  "text": "Duplicate branch in alternation"
                },
                "fullDescription": {
                  "text": "Reports duplicate branches in a RegExp alternation. Duplicate branches slow down matching and obscure the intent of the expression. Example: '(alpha|bravo|charlie|alpha)' After the quick-fix is applied: '(alpha|bravo|charlie)' New in 2017.1",
                  "markdown": "Reports duplicate branches in a RegExp alternation. Duplicate branches slow down matching and obscure the intent of the expression.\n\n**Example:**\n\n\n      (alpha|bravo|charlie|alpha)\n\nAfter the quick-fix is applied:\n\n\n      (alpha|bravo|charlie)\n\nNew in 2017.1"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "RegExpRepeatedSpace",
                "shortDescription": {
                  "text": "Consecutive spaces"
                },
                "fullDescription": {
                  "text": "Reports multiple consecutive spaces in a RegExp. Because spaces are not visible by default, it can be hard to see how many spaces are required. The RegExp can be made more clear by replacing the consecutive spaces with a single space and a counted quantifier. Example: '(     )' After the quick-fix is applied: '( {5})' New in 2017.1",
                  "markdown": "Reports multiple consecutive spaces in a RegExp. Because spaces are not visible by default, it can be hard to see how many spaces are required. The RegExp can be made more clear by replacing the consecutive spaces with a single space and a counted quantifier.\n\n**Example:**\n\n\n      (     )\n\nAfter the quick-fix is applied:\n\n\n      ( {5})\n\n\nNew in 2017.1"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "RegExp",
                      "index": 10,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "IgnoreFileDuplicateEntry",
                "shortDescription": {
                  "text": "Ignore file duplicates"
                },
                "fullDescription": {
                  "text": "Reports duplicate entries (patterns) in the ignore file (e.g. .gitignore, .hgignore). Duplicate entries in these files are redundant and can be removed. Example:     # Output directories\n    /out/\n    /target/\n    /out/",
                  "markdown": "Reports duplicate entries (patterns) in the ignore file (e.g. .gitignore, .hgignore). Duplicate entries in these files are redundant and can be removed.\n\nExample:\n\n```\n    # Output directories\n    /out/\n    /target/\n    /out/\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Version control",
                      "index": 30,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "JsonStandardCompliance",
                "shortDescription": {
                  "text": "Compliance with JSON standard"
                },
                "fullDescription": {
                  "text": "Reports the following discrepancies of a JSON file with the language specification: A line or block comment (configurable). Multiple top-level values (expect for JSON Lines files, configurable for others). A trailing comma in an object or array (configurable). A single quoted string. A property key is a not a double quoted strings. A NaN or Infinity/-Infinity numeric value as a floating point literal (configurable).",
                  "markdown": "Reports the following discrepancies of a JSON file with [the language specification](https://tools.ietf.org/html/rfc7159):\n\n* A line or block comment (configurable).\n* Multiple top-level values (expect for JSON Lines files, configurable for others).\n* A trailing comma in an object or array (configurable).\n* A single quoted string.\n* A property key is a not a double quoted strings.\n* A NaN or Infinity/-Infinity numeric value as a floating point literal (configurable)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "JSON and JSON5",
                      "index": 8,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CheckEmptyScriptTag",
                "shortDescription": {
                  "text": "Empty tag"
                },
                "fullDescription": {
                  "text": "Reports empty tags that do not work in some browsers. Example: '<html>\n    <script/>\n  </html>' After the quick-fix is applied: '<html>\n    <script></script>\n  </html>'",
                  "markdown": "Reports empty tags that do not work in some browsers.\n\n**Example:**\n\n\n      <html>\n        <script/>\n      </html>\n\nAfter the quick-fix is applied:\n\n\n      <html>\n        <script></script>\n      </html>\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "JsonPathUnknownOperator",
                "shortDescription": {
                  "text": "Unknown JSONPath operator"
                },
                "fullDescription": {
                  "text": "Reports an unknown operator on a JSONPath expression instead of one of the standard ones: 'in', 'nin', 'subsetof', 'anyof', 'noneof', 'size', 'empty', 'contains'.",
                  "markdown": "Reports an unknown operator on a JSONPath expression instead of one of the standard ones: `in`, `nin`, `subsetof`, `anyof`, `noneof`, `size`, `empty`, `contains`."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "JSON and JSON5",
                      "index": 8,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          },
          {
            "name": "org.jetbrains.plugins.yaml",
            "version": "223.8782",
            "rules": [
              {
                "id": "YAMLRecursiveAlias",
                "shortDescription": {
                  "text": "Recursive alias"
                },
                "fullDescription": {
                  "text": "Reports recursion in YAML aliases. Alias can't be recursive and be used inside the data referenced by a corresponding anchor. Example: 'some_key: &some_anchor\n    sub_key1: value1\n    sub_key2: *some_anchor'",
                  "markdown": "Reports recursion in YAML aliases.\n\nAlias can't be recursive and be used inside the data referenced by a corresponding anchor.\n\n**Example:**\n\n\n      some_key: &some_anchor\n        sub_key1: value1\n        sub_key2: *some_anchor\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "YAML",
                      "index": 7,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "YAMLSchemaValidation",
                "shortDescription": {
                  "text": "Validation by JSON Schema"
                },
                "fullDescription": {
                  "text": "Reports inconsistencies between a YAML file and a JSON Schema if the schema is specified. Scheme example: '{\n    \"properties\": {\n      \"SomeNumberProperty\": {\n        \"type\": \"number\"\n      }\n    }\n  }' The following is an example with the corresponding warning: 'SomeNumberProperty: hello world'",
                  "markdown": "Reports inconsistencies between a YAML file and a JSON Schema if the schema is specified.\n\n**Scheme example:**\n\n\n      {\n        \"properties\": {\n          \"SomeNumberProperty\": {\n            \"type\": \"number\"\n          }\n        }\n      }\n\n**The following is an example with the corresponding warning:**\n\n\n      SomeNumberProperty: hello world\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "YAML",
                      "index": 7,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "YAMLDuplicatedKeys",
                "shortDescription": {
                  "text": "Duplicated YAML keys"
                },
                "fullDescription": {
                  "text": "Reports duplicated keys in YAML files. Example: 'same_key: some value\n  same_key: another value'",
                  "markdown": "Reports duplicated keys in YAML files.\n\n**Example:**\n\n\n      same_key: some value\n      same_key: another value\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "YAML",
                      "index": 7,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "YAMLUnusedAnchor",
                "shortDescription": {
                  "text": "Unused anchor"
                },
                "fullDescription": {
                  "text": "Reports unused anchors. Example: 'some_key: &some_anchor\n    key1: value1'",
                  "markdown": "Reports unused anchors.\n\n**Example:**\n\n\n      some_key: &some_anchor\n        key1: value1\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "YAML",
                      "index": 7,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "YAMLUnresolvedAlias",
                "shortDescription": {
                  "text": "Unresolved alias"
                },
                "fullDescription": {
                  "text": "Reports unresolved aliases in YAML files. Example: 'some_key: *unknown_alias'",
                  "markdown": "Reports unresolved aliases in YAML files.\n\n**Example:**\n\n\n      some_key: *unknown_alias\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "YAML",
                      "index": 7,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "YAMLSchemaDeprecation",
                "shortDescription": {
                  "text": "Deprecated YAML key"
                },
                "fullDescription": {
                  "text": "Reports deprecated keys in YAML files. Deprecation is checked only if there exists a JSON schema associated with the corresponding YAML file. Note that the deprecation mechanism is not defined in the JSON Schema specification yet, and this inspection uses a non-standard 'deprecationMessage' extension. Scheme deprecation example: '{\n    \"properties\": {\n      \"SomeDeprecatedProperty\": {\n        \"deprecationMessage\": \"Baz\",\n        \"description\": \"Foo bar\"\n      }\n    }\n  }' The following is an example with the corresponding warning: 'SomeDeprecatedProperty: some value'",
                  "markdown": "Reports deprecated keys in YAML files.\n\nDeprecation is checked only if there exists a JSON schema associated with the corresponding YAML file.\n\nNote that the deprecation mechanism is not defined in the JSON Schema specification yet,\nand this inspection uses a non-standard `deprecationMessage` extension.\n\n**Scheme deprecation example:**\n\n\n      {\n        \"properties\": {\n          \"SomeDeprecatedProperty\": {\n            \"deprecationMessage\": \"Baz\",\n            \"description\": \"Foo bar\"\n          }\n        }\n      }\n\n**The following is an example with the corresponding warning:**\n\n\n      SomeDeprecatedProperty: some value\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "YAML",
                      "index": 7,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          },
          {
            "name": "com.intellij.properties",
            "version": "223.8782",
            "rules": [
              {
                "id": "DuplicatePropertyInspection",
                "shortDescription": {
                  "text": "Duplicate property"
                },
                "fullDescription": {
                  "text": "Reports duplicate property keys with different values, duplicate keys, or duplicate property values. Example: 'property1=value;\nproperty2=value;' The Options list allows selecting the area in which the inspection should search for duplicates.",
                  "markdown": "Reports duplicate property keys with different values, duplicate keys, or duplicate property values.\n\nExample:\n\n\n    property1=value;\n    property2=value;\n\nThe **Options** list allows selecting the area in which the inspection should search for duplicates."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Properties files",
                      "index": 11,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "UseEllipsisInPropertyInspection",
                "shortDescription": {
                  "text": "Three dot characters instead of the ellipsis"
                },
                "fullDescription": {
                  "text": "Reports three \"dot\" characters which are used instead of the ellipsis character for UTF-8 properties files.",
                  "markdown": "Reports three \"dot\" characters which are used instead of the ellipsis character for UTF-8 properties files."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Properties files",
                      "index": 11,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "AlphaUnsortedPropertiesFile",
                "shortDescription": {
                  "text": "Properties file or resource bundle is alphabetically unsorted"
                },
                "fullDescription": {
                  "text": "Reports alphabetically unsorted resource bundles or .properties files.",
                  "markdown": "Reports alphabetically unsorted resource bundles or .properties files."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "INFO"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Properties files",
                      "index": 11,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "TrailingSpacesInProperty",
                "shortDescription": {
                  "text": "Trailing spaces in property"
                },
                "fullDescription": {
                  "text": "Reports properties whose keys or values end with a whitespace.",
                  "markdown": "Reports properties whose keys or values end with a whitespace."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Properties files",
                      "index": 11,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "UnusedProperty",
                "shortDescription": {
                  "text": "Unused property"
                },
                "fullDescription": {
                  "text": "Reports properties that are not referenced outside of the .properties file they are contained in.",
                  "markdown": "Reports properties that are not referenced outside of the .properties file they are contained in."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Properties files",
                      "index": 11,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "WrongPropertyKeyValueDelimiter",
                "shortDescription": {
                  "text": "Property key/value delimiter doesn't match code style settings"
                },
                "fullDescription": {
                  "text": "Reports properties in which key or value delimiters do not match code style settings.",
                  "markdown": "Reports properties in which key or value delimiters do not match code style settings."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Properties files",
                      "index": 11,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          },
          {
            "name": "com.intellij.css",
            "version": "223.8782",
            "rules": [
              {
                "id": "CssUnusedSymbol",
                "shortDescription": {
                  "text": "Unused selector"
                },
                "fullDescription": {
                  "text": "Reports a CSS class or an element IDs that appears in selectors but is not used in HTML. Note that complete inspection results are available only when running it via Code | Inspect Code or Code | Analyze Code | Run Inspection by Name. Due to performance reasons, style sheet files are not inspected on the fly.",
                  "markdown": "Reports a CSS class or an element IDs that appears in selectors but is not used in HTML.\n\n\nNote that complete inspection results are available only when running it via **Code \\| Inspect Code** or\n**Code \\| Analyze Code \\| Run Inspection by Name**.\nDue to performance reasons, style sheet files are not inspected on the fly."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS",
                      "index": 13,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssNonIntegerLengthInPixels",
                "shortDescription": {
                  "text": "Non-integer length in pixels"
                },
                "fullDescription": {
                  "text": "Reports a non-integer length in pixels. Example: 'width: 3.14px'",
                  "markdown": "Reports a non-integer length in pixels.\n\n**Example:**\n\n     width: 3.14px\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Probable bugs",
                      "index": 16,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssInvalidImport",
                "shortDescription": {
                  "text": "Misplaced @import"
                },
                "fullDescription": {
                  "text": "Reports a misplaced '@import' statement. According to the specification, '@import' rules must precede all other types of rules, except '@charset' rules.",
                  "markdown": "Reports a misplaced `@import` statement.\n\n\nAccording to the [specification](https://developer.mozilla.org/en-US/docs/Web/CSS/@import),\n`@import` rules must precede all other types of rules, except `@charset` rules."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssInvalidHtmlTagReference",
                "shortDescription": {
                  "text": "Invalid type selector"
                },
                "fullDescription": {
                  "text": "Reports a CSS type selector that matches an unknown HTML element.",
                  "markdown": "Reports a CSS [type selector](https://developer.mozilla.org/en-US/docs/Web/CSS/Type_selectors) that matches an unknown HTML element."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssInvalidAtRule",
                "shortDescription": {
                  "text": "Unknown at-rule"
                },
                "fullDescription": {
                  "text": "Reports an unknown CSS at-rule.",
                  "markdown": "Reports an unknown [CSS at-rule](https://developer.mozilla.org/en-US/docs/Web/CSS/At-rule)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssInvalidFunction",
                "shortDescription": {
                  "text": "Invalid function"
                },
                "fullDescription": {
                  "text": "Reports an unknown CSS function or an incorrect function parameter.",
                  "markdown": "Reports an unknown [CSS function](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Functions) or an incorrect function parameter."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssUnresolvedCustomProperty",
                "shortDescription": {
                  "text": "Unresolved custom property"
                },
                "fullDescription": {
                  "text": "Reports an unresolved reference to a custom property among the arguments of the 'var()' function.",
                  "markdown": "Reports an unresolved reference to a [custom property](https://developer.mozilla.org/en-US/docs/Web/CSS/--*) among the arguments of the `var()` function."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssOverwrittenProperties",
                "shortDescription": {
                  "text": "Overwritten property"
                },
                "fullDescription": {
                  "text": "Reports a duplicated CSS property within a ruleset. Respects shorthand properties. Example: '.foo {\n  margin-bottom: 1px;\n  margin-bottom: 1px; /* duplicates margin-bottom */\n  margin: 0; /* overrides margin-bottom */\n}'",
                  "markdown": "Reports a duplicated CSS property within a ruleset. Respects shorthand properties.\n\n**Example:**\n\n\n    .foo {\n      margin-bottom: 1px;\n      margin-bottom: 1px; /* duplicates margin-bottom */\n      margin: 0; /* overrides margin-bottom */\n    }\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS",
                      "index": 13,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssMissingSemicolon",
                "shortDescription": {
                  "text": "Missing semicolon"
                },
                "fullDescription": {
                  "text": "Reports a missing semicolon at the end of a declaration.",
                  "markdown": "Reports a missing semicolon at the end of a declaration."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Code style issues",
                      "index": 23,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssRedundantUnit",
                "shortDescription": {
                  "text": "Redundant measure unit"
                },
                "fullDescription": {
                  "text": "Reports a measure unit of a zero value where units are not required by the specification. Example: 'width: 0px'",
                  "markdown": "Reports a measure unit of a zero value where units are not required by the specification.\n\n**Example:**\n\n    width: 0px\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Code style issues",
                      "index": 23,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssUnknownTarget",
                "shortDescription": {
                  "text": "Unresolved file reference"
                },
                "fullDescription": {
                  "text": "Reports an unresolved file reference, for example, an incorrect path in an '@import' statement.",
                  "markdown": "Reports an unresolved file reference, for example, an incorrect path in an `@import` statement."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssNegativeValue",
                "shortDescription": {
                  "text": "Negative property value"
                },
                "fullDescription": {
                  "text": "Reports a negative value of a CSS property that is not expected to be less than zero, for example, object width or height.",
                  "markdown": "Reports a negative value of a CSS property that is not expected to be less than zero, for example, object width or height."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssNoGenericFontName",
                "shortDescription": {
                  "text": "Missing generic font family name"
                },
                "fullDescription": {
                  "text": "Verifies that the 'font-family' property contains a generic font family name as a fallback alternative. Generic font family names are: 'serif', 'sans-serif', 'cursive', 'fantasy', and 'monospace'.",
                  "markdown": "Verifies that the [font-family](https://developer.mozilla.org/en-US/docs/Web/CSS/font-family) property contains a generic font family name as a fallback alternative.\n\n\nGeneric font family names are: `serif`, `sans-serif`, `cursive`, `fantasy`,\nand `monospace`."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Probable bugs",
                      "index": 16,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssUnresolvedClassInComposesRule",
                "shortDescription": {
                  "text": "Unresolved class in 'composes' rule"
                },
                "fullDescription": {
                  "text": "Reports a CSS class reference in the 'composes' rule that cannot be resolved to any valid target. Example: '.className {/* ... */}\n\n  .otherClassName {\n    composes: className;\n  }'",
                  "markdown": "Reports a CSS class reference in the ['composes'](https://github.com/css-modules/css-modules#composition) rule that cannot be resolved to any valid target.\n\n**Example:**\n\n\n      .className {/* ... */}\n\n      .otherClassName {\n        composes: className;\n      }\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssInvalidCharsetRule",
                "shortDescription": {
                  "text": "Misplaced or incorrect @charset"
                },
                "fullDescription": {
                  "text": "Reports a misplaced '@charset' at-rule or an incorrect charset value.",
                  "markdown": "Reports a misplaced `@charset` at-rule or an incorrect charset value."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssMissingComma",
                "shortDescription": {
                  "text": "Missing comma in selector list"
                },
                "fullDescription": {
                  "text": "Reports a multi-line selector. Most likely this means that several single-line selectors are actually intended but a comma is missing at the end of one or several lines. Example: 'input /* comma has probably been forgotten */\n.button {\n  margin: 1px;\n}'",
                  "markdown": "Reports a multi-line selector. Most likely this means that several single-line selectors are actually intended but a comma is missing at the end of one or several lines.\n\n**Example:**\n\n\n    input /* comma has probably been forgotten */\n    .button {\n      margin: 1px;\n    }\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Probable bugs",
                      "index": 16,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssInvalidPropertyValue",
                "shortDescription": {
                  "text": "Invalid property value"
                },
                "fullDescription": {
                  "text": "Reports an incorrect CSS property value.",
                  "markdown": "Reports an incorrect CSS property value."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssReplaceWithShorthandSafely",
                "shortDescription": {
                  "text": "Properties may be safely replaced with a shorthand"
                },
                "fullDescription": {
                  "text": "Reports a set of longhand properties. Suggests replacing a complete set of longhand CSS properties with an equivalent shorthand form. For example, 4 properties: 'padding-top', 'padding-right', 'padding-bottom', and 'padding-left' can be safely replaced with a single 'padding' property. Note that this inspection doesn't show up if the set of longhand properties is incomplete (e.g. only 3 'padding-xxx' properties in a ruleset) because switching to a shorthand may change the result. For such cases consider the 'Properties may probably be replaced with a shorthand' inspection.",
                  "markdown": "Reports a set of longhand properties. Suggests replacing a complete set of longhand CSS properties with an equivalent shorthand form.\n\n\nFor example, 4 properties: `padding-top`, `padding-right`, `padding-bottom`, and\n`padding-left`\ncan be safely replaced with a single `padding` property.\n\n\nNote that this inspection doesn't show up if the set of longhand properties is incomplete\n(e.g. only 3 `padding-xxx` properties in a ruleset)\nbecause switching to a shorthand may change the result.\nFor such cases consider the 'Properties may probably be replaced with a shorthand'\ninspection."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "WEAK WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS",
                      "index": 13,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssBrowserCompatibilityForProperties",
                "shortDescription": {
                  "text": "Property is incompatible with selected browsers"
                },
                "fullDescription": {
                  "text": "Reports a CSS property that is not supported by the specified browsers. Based on the MDN Compatibility Data.",
                  "markdown": "Reports a CSS property that is not supported by the specified browsers. Based on the [MDN Compatibility Data](https://github.com/mdn/browser-compat-data)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS",
                      "index": 13,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssUnknownProperty",
                "shortDescription": {
                  "text": "Unknown property"
                },
                "fullDescription": {
                  "text": "Reports an unknown CSS property or a property used in a wrong context. Add the unknown property to the 'Custom CSS properties' list to skip validation.",
                  "markdown": "Reports an unknown CSS property or a property used in a wrong context.\n\nAdd the unknown property to the 'Custom CSS properties' list to skip validation."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssInvalidPseudoSelector",
                "shortDescription": {
                  "text": "Invalid pseudo-selector"
                },
                "fullDescription": {
                  "text": "Reports an incorrect CSS pseudo-class pseudo-element.",
                  "markdown": "Reports an incorrect CSS [pseudo-class](https://developer.mozilla.org/en-US/docs/Web/CSS/Pseudo-classes) [pseudo-element](https://developer.mozilla.org/en-US/docs/Web/CSS/Pseudo-elements)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssConvertColorToHexInspection",
                "shortDescription": {
                  "text": "Color could be replaced with #-hex"
                },
                "fullDescription": {
                  "text": "Reports an 'rgb()', 'hsl()', or other color function. Suggests replacing a color function with an equivalent hexadecimal notation. Example: 'rgb(12, 15, 255)' After the quick-fix is applied: '#0c0fff'.",
                  "markdown": "Reports an `rgb()`, `hsl()`, or other color function.\n\nSuggests replacing a color function with an equivalent hexadecimal notation.\n\n**Example:**\n\n    rgb(12, 15, 255)\n\nAfter the quick-fix is applied:\n\n    #0c0fff.\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS",
                      "index": 13,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssReplaceWithShorthandUnsafely",
                "shortDescription": {
                  "text": "Properties may probably be replaced with a shorthand"
                },
                "fullDescription": {
                  "text": "Reports a set of longhand CSS properties and suggests replacing an incomplete set of longhand CSS properties with a shorthand form, which is however not 100% equivalent in this case. For example, 2 properties: 'outline-color' and 'outline-style' may be replaced with a single 'outline'. Such replacement is not 100% equivalent because shorthands reset all omitted sub-values to their initial states. In this example, switching to the 'outline' shorthand means that 'outline-width' is also set to its initial value, which is 'medium'. This inspection doesn't handle full sets of longhand properties (when switching to shorthand is 100% safe). For such cases see the 'Properties may be safely replaced with a shorthand' inspection instead.",
                  "markdown": "Reports a set of longhand CSS properties and suggests replacing an incomplete set of longhand CSS properties with a shorthand form, which is however not 100% equivalent in this case.\n\n\nFor example, 2 properties: `outline-color` and `outline-style` may be replaced with a single `outline`.\nSuch replacement is not 100% equivalent because shorthands reset all omitted sub-values to their initial states.\nIn this example, switching to the `outline` shorthand means that `outline-width` is also set to its initial value,\nwhich is `medium`.\n\n\nThis inspection doesn't handle full sets of longhand properties (when switching to shorthand is 100% safe).\nFor such cases see the 'Properties may be safely replaced with a shorthand' inspection instead."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "INFORMATION"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS",
                      "index": 13,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssInvalidMediaFeature",
                "shortDescription": {
                  "text": "Invalid media feature"
                },
                "fullDescription": {
                  "text": "Reports an unknown CSS media feature or an incorrect media feature value.",
                  "markdown": "Reports an unknown [CSS media feature](https://developer.mozilla.org/en-US/docs/Web/CSS/Media_Queries/Using_media_queries) or an incorrect media feature value."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS/Invalid elements",
                      "index": 20,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CssConvertColorToRgbInspection",
                "shortDescription": {
                  "text": "Color could be replaced with rgb()"
                },
                "fullDescription": {
                  "text": "Reports an 'hsl()' or 'hwb()' color function or a hexadecimal color notation. Suggests replacing such color value with an equivalent 'rgb()' or 'rgba()' color function. Example: '#0c0fff' After the quick-fix is applied: 'rgb(12, 15, 255)'.",
                  "markdown": "Reports an `hsl()` or `hwb()` color function or a hexadecimal color notation.\n\nSuggests replacing such color value with an equivalent `rgb()` or `rgba()` color function.\n\n**Example:**\n\n    #0c0fff\n\nAfter the quick-fix is applied:\n\n    rgb(12, 15, 255).\n"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "CSS",
                      "index": 13,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          },
          {
            "name": "HtmlTools",
            "version": "223.8782",
            "rules": [
              {
                "id": "HtmlRequiredAltAttribute",
                "shortDescription": {
                  "text": "Missing required 'alt' attribute"
                },
                "fullDescription": {
                  "text": "Reports a missing 'alt' attribute in a 'img' or 'applet' tag or in a 'area' element of an image map. Suggests adding a required attribute with a text alternative for the contents of the tag. Based on WCAG 2.0: H24, H35, H36, H37.",
                  "markdown": "Reports a missing `alt` attribute in a `img` or `applet` tag or in a `area` element of an image map. Suggests adding a required attribute with a text alternative for the contents of the tag. Based on WCAG 2.0: [H24](https://www.w3.org/TR/WCAG20-TECHS/H24.html), [H35](https://www.w3.org/TR/WCAG20-TECHS/H35.html), [H36](https://www.w3.org/TR/WCAG20-TECHS/H36.html), [H37](https://www.w3.org/TR/WCAG20-TECHS/H37.html)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML/Accessibility",
                      "index": 18,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlDeprecatedTag",
                "shortDescription": {
                  "text": "Obsolete tag"
                },
                "fullDescription": {
                  "text": "Reports an obsolete HTML5 tag. Suggests replacing the obsolete tag with a CSS or another tag.",
                  "markdown": "Reports an obsolete HTML5 tag. Suggests replacing the obsolete tag with a CSS or another tag."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CheckImageSize",
                "shortDescription": {
                  "text": "Mismatched image size"
                },
                "fullDescription": {
                  "text": "Reports a 'width' and 'height' attribute value of a 'img' tag that is different from the actual width and height of the referenced image.",
                  "markdown": "Reports a `width` and `height` attribute value of a `img` tag that is different from the actual width and height of the referenced image."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlFormInputWithoutLabel",
                "shortDescription": {
                  "text": "Missing associated label"
                },
                "fullDescription": {
                  "text": "Reports a form element ('input', 'textarea', or 'select') without an associated label. Suggests creating a new label. Based on WCAG 2.0: H44.",
                  "markdown": "Reports a form element (`input`, `textarea`, or `select`) without an associated label. Suggests creating a new label. Based on WCAG 2.0: [H44](https://www.w3.org/TR/WCAG20-TECHS/H44.html).  "
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML/Accessibility",
                      "index": 18,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlRequiredSummaryAttribute",
                "shortDescription": {
                  "text": "Missing required 'summary' attribute"
                },
                "fullDescription": {
                  "text": "Reports a missing 'summary' attribute in a 'table' tag. Suggests adding a'summary' attribute. Based on WCAG 2.0: H73.",
                  "markdown": "Reports a missing `summary` attribute in a `table` tag. Suggests adding a`summary` attribute. Based on WCAG 2.0: [H73](https://www.w3.org/TR/WCAG20-TECHS/H73.html)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "INFORMATION"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML/Accessibility",
                      "index": 18,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlRequiredLangAttribute",
                "shortDescription": {
                  "text": "Missing required 'lang' attribute"
                },
                "fullDescription": {
                  "text": "Reports a missing 'lang' (or 'xml:lang') attribute in a 'html' tag. Suggests adding a required attribute to state the default language of the document. Based on WCAG 2.0: H57.",
                  "markdown": "Reports a missing `lang` (or `xml:lang`) attribute in a `html` tag. Suggests adding a required attribute to state the default language of the document. Based on WCAG 2.0: [H57](https://www.w3.org/TR/WCAG20-TECHS/H57.html)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML/Accessibility",
                      "index": 18,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlNonExistentInternetResource",
                "shortDescription": {
                  "text": "Unresolved web link"
                },
                "fullDescription": {
                  "text": "Reports an unresolved web link. Works by making network requests in the background.",
                  "markdown": "Reports an unresolved web link. Works by making network requests in the background."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlRequiredTitleAttribute",
                "shortDescription": {
                  "text": "Missing required 'title' attribute"
                },
                "fullDescription": {
                  "text": "Reports a missing title attribute 'frame', 'iframe', 'dl', and 'a' tags. Suggests adding a title attribute. Based on WCAG 2.0: H33, H40, and H64.",
                  "markdown": "Reports a missing title attribute `frame`, `iframe`, `dl`, and `a` tags. Suggests adding a title attribute. Based on WCAG 2.0: [H33](https://www.w3.org/TR/WCAG20-TECHS/H33.html), [H40](https://www.w3.org/TR/WCAG20-TECHS/H40.html), and [H64](https://www.w3.org/TR/WCAG20-TECHS/H64.html)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "INFORMATION"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML/Accessibility",
                      "index": 18,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlRequiredTitleElement",
                "shortDescription": {
                  "text": "Missing required 'title' element"
                },
                "fullDescription": {
                  "text": "Reports a missing 'title' element inside a 'head' section. Suggests adding a 'title' element. The title should describe the document. Based on WCAG 2.0: H25.",
                  "markdown": "Reports a missing `title` element inside a `head` section. Suggests adding a `title` element. The title should describe the document. Based on WCAG 2.0: [H25](https://www.w3.org/TR/WCAG20-TECHS/H25.html)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML/Accessibility",
                      "index": 18,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlDeprecatedAttribute",
                "shortDescription": {
                  "text": "Obsolete attribute"
                },
                "fullDescription": {
                  "text": "Reports an obsolete HTML5 attribute.",
                  "markdown": "Reports an obsolete HTML5 attribute."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "HtmlPresentationalElement",
                "shortDescription": {
                  "text": "Presentational tag"
                },
                "fullDescription": {
                  "text": "Reports a presentational HTML tag. Suggests replacing the presentational tag with a CSS or another tag.",
                  "markdown": "Reports a presentational HTML tag. Suggests replacing the presentational tag with a CSS or another tag."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "HTML",
                      "index": 15,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          },
          {
            "name": "com.intellij.plugins.dependencyAnalysis",
            "version": "223.8782",
            "rules": [
              {
                "id": "CheckThirdPartySoftwareList",
                "shortDescription": {
                  "text": "Check third party software list"
                },
                "fullDescription": {
                  "text": "Check project for possible problems: user's third party software list does not match the collected project metadata",
                  "markdown": "Check project for possible problems: user's third party software list does not match the collected project metadata"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Dependency analysis",
                      "index": 22,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CheckDependencyLicenses",
                "shortDescription": {
                  "text": "Check dependency licenses"
                },
                "fullDescription": {
                  "text": "Check dependencies licenses for possible problems: missing or prohibited licenses, or other compliance issues",
                  "markdown": "Check dependencies licenses for possible problems: missing or prohibited licenses, or other compliance issues"
                },
                "defaultConfiguration": {
                  "enabled": true,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Dependency analysis",
                      "index": 22,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "CheckModuleLicenses",
                "shortDescription": {
                  "text": "Check module licenses"
                },
                "fullDescription": {
                  "text": "Check module licenses for possible problems: missing licenses or other compliance issues",
                  "markdown": "Check module licenses for possible problems: missing licenses or other compliance issues"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Dependency analysis",
                      "index": 22,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "IncorrectProjectDependenciesConfiguration",
                "shortDescription": {
                  "text": "Check configuration of project dependencies"
                },
                "fullDescription": {
                  "text": "Checking configuration of project dependencies",
                  "markdown": "Checking configuration of project dependencies"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Dependency analysis",
                      "index": 22,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          },
          {
            "name": "org.intellij.intelliLang",
            "version": "223.8782",
            "rules": [
              {
                "id": "InjectedReferences",
                "shortDescription": {
                  "text": "Injected references"
                },
                "fullDescription": {
                  "text": "Reports unresolved references injected by Language Injections. Example:     @Language(\"file-reference\")\n    String fileName = \"/home/user/nonexistent.file\"; // highlighted if file doesn't exist",
                  "markdown": "Reports unresolved references injected by [Language Injections](https://www.jetbrains.com/help/idea/using-language-injections.html).\n\nExample:\n\n```\n    @Language(\"file-reference\")\n    String fileName = \"/home/user/nonexistent.file\"; // highlighted if file doesn't exist\n```"
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          },
          {
            "name": "com.jetbrains.plugins.ini4idea",
            "version": "223.8782",
            "rules": [
              {
                "id": "DuplicateKeyInSection",
                "shortDescription": {
                  "text": "Duplicate directive in section"
                },
                "fullDescription": {
                  "text": "Reports duplicate properties in the 'ini' file section.",
                  "markdown": "Reports duplicate properties in the `ini` file section."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Ini files",
                      "index": 24,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "DuplicateSectionInFile",
                "shortDescription": {
                  "text": "Duplicate section in file"
                },
                "fullDescription": {
                  "text": "Reports duplicate sections in the 'ini' file.",
                  "markdown": "Reports duplicate sections in the `ini` file."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Ini files",
                      "index": 24,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          },
          {
            "name": "tanvd.grazi",
            "version": "223.8782",
            "rules": [
              {
                "id": "LanguageDetectionInspection",
                "shortDescription": {
                  "text": "Natural language detection"
                },
                "fullDescription": {
                  "text": "Detects natural languages and suggests enabling corresponding grammar and spelling checks.",
                  "markdown": "Detects natural languages and suggests enabling corresponding grammar and spelling checks."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "warning",
                  "parameters": {
                    "ideaSeverity": "WARNING"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Proofreading",
                      "index": 26,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              },
              {
                "id": "GrazieInspection",
                "shortDescription": {
                  "text": "Grammar"
                },
                "fullDescription": {
                  "text": "Reports grammar mistakes in your text. You can configure the inspection in Settings | Editor | Natural Languages | Grammar.",
                  "markdown": "Reports grammar mistakes in your text. You can configure the inspection in [Settings \\| Editor \\| Natural Languages \\| Grammar](settings://reference.settingsdialog.project.grazie)."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "note",
                  "parameters": {
                    "ideaSeverity": "TYPO"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "Proofreading",
                      "index": 26,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          },
          {
            "name": "org.intellij.qodana",
            "version": "223.8782",
            "rules": [
              {
                "id": "QodanaServiceMessage",
                "shortDescription": {
                  "text": "Qodana service message"
                },
                "fullDescription": {
                  "text": "Reports the Qodana service messages such as suspending a particular inspection due to a large number of reported problems.",
                  "markdown": "Reports the Qodana service messages such as suspending a particular inspection due to a large number of reported problems."
                },
                "defaultConfiguration": {
                  "enabled": false,
                  "level": "error",
                  "parameters": {
                    "ideaSeverity": "ERROR"
                  }
                },
                "relationships": [
                  {
                    "target": {
                      "id": "General",
                      "index": 17,
                      "toolComponent": {
                        "name": "QDPY"
                      }
                    },
                    "kinds": [
                      "superset"
                    ]
                  }
                ]
              }
            ],
            "language": "en-US",
            "contents": [
              "localizedData",
              "nonLocalizedData"
            ],
            "isComprehensive": false
          }
        ]
      },
      "invocations": [
        {
          "exitCode": 0,
          "toolExecutionNotifications": [
            {
              "message": {
                "text": "Reporting from [\"An invalid interpreter\", \"Unresolved references\"] 'sanity' inspections was suspended due to high problems count."
              },
              "level": "error"
            }
          ],
          "executionSuccessful": true
        }
      ],
      "language": "en-US",
      "versionControlProvenance": [
        {
          "repositoryUri": "https://github.com/Pale-Blue-Dot-97/Minerva.git",
          "revisionId": "fe26deb473ece0889a7c8424abbabe26b4574b0c",
          "branch": "add-knn",
          "properties": {
            "repoUrl": "https://github.com/Pale-Blue-Dot-97/Minerva.git",
            "lastAuthorName": "Harry Baker",
            "vcsType": "Git",
            "lastAuthorEmail": "harry.baker@os.uk"
          }
        }
      ],
      "results": [
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'kwargs' value is not used",
            "markdown": "Parameter 'kwargs' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/modelio.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 54,
                  "startColumn": 5,
                  "charOffset": 2308,
                  "charLength": 8,
                  "snippet": {
                    "text": "**kwargs"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 52,
                  "startColumn": 1,
                  "charOffset": 2233,
                  "charLength": 253,
                  "snippet": {
                    "text": "    device: torch.device,  # type: ignore[name-defined]\n    mode: str,\n    **kwargs,\n) -> Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]], Tensor, Sequence[BoundingBox]]:\n    \"\"\"Provides IO functionality for a supervised model using `torchgeo` datasets."
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "b38f00f71d81293d19d8a883c213e946ad8c3e38ff45fcf2b5c2db21749790a0"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'kwargs' value is not used",
            "markdown": "Parameter 'kwargs' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/modelio.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 106,
                  "startColumn": 5,
                  "charOffset": 4124,
                  "charLength": 8,
                  "snippet": {
                    "text": "**kwargs"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 104,
                  "startColumn": 1,
                  "charOffset": 4049,
                  "charLength": 269,
                  "snippet": {
                    "text": "    device: torch.device,  # type: ignore[name-defined]\n    mode: str,\n    **kwargs,\n) -> Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]], None, Sequence[BoundingBox]]:\n    \"\"\"Provides IO functionality for a self-supervised Siamese model using :mod:`torchgeo` datasets."
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "c6285e25e71956e856a0b83d774fbcc36f19bc0abf9285167a7f9d02de4b105a"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'signum' value is not used",
            "markdown": "Parameter 'signum' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/runner.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 262,
                  "startColumn": 21,
                  "charOffset": 8512,
                  "charLength": 6,
                  "snippet": {
                    "text": "signum"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 260,
                  "startColumn": 1,
                  "charOffset": 8310,
                  "charLength": 338,
                  "snippet": {
                    "text": "#                                                     METHODS\n# =====================================================================================================================\ndef _handle_sigusr1(signum, frame) -> None:  # pragma: no cover\n    subprocess.Popen(  # nosec B602\n        f'scontrol requeue {os.getenv(\"SLURM_JOB_ID\")}',"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "3edb77711825179cca2593e0a520b0c4695abb165cc2b24ade1b62018772234c"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'frame' value is not used",
            "markdown": "Parameter 'frame' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/runner.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 262,
                  "startColumn": 29,
                  "charOffset": 8520,
                  "charLength": 5,
                  "snippet": {
                    "text": "frame"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 260,
                  "startColumn": 1,
                  "charOffset": 8310,
                  "charLength": 338,
                  "snippet": {
                    "text": "#                                                     METHODS\n# =====================================================================================================================\ndef _handle_sigusr1(signum, frame) -> None:  # pragma: no cover\n    subprocess.Popen(  # nosec B602\n        f'scontrol requeue {os.getenv(\"SLURM_JOB_ID\")}',"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "06fcf37da3d662db85e31aaded1ebfafd1ce4ebe653f17f43286912462e62b8d"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'signum' value is not used",
            "markdown": "Parameter 'signum' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/runner.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 270,
                  "startColumn": 21,
                  "charOffset": 8708,
                  "charLength": 6,
                  "snippet": {
                    "text": "signum"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 268,
                  "startColumn": 1,
                  "charOffset": 8686,
                  "charLength": 75,
                  "snippet": {
                    "text": "\n\ndef _handle_sigterm(signum, frame) -> None:  # pragma: no cover\n    pass\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "172c229fa32444afa198b1ea51ffc00941b7b27296d2ac8ed940248c83e0cbf5"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'frame' value is not used",
            "markdown": "Parameter 'frame' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/runner.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 270,
                  "startColumn": 29,
                  "charOffset": 8716,
                  "charLength": 5,
                  "snippet": {
                    "text": "frame"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 268,
                  "startColumn": 1,
                  "charOffset": 8686,
                  "charLength": 75,
                  "snippet": {
                    "text": "\n\ndef _handle_sigterm(signum, frame) -> None:  # pragma: no cover\n    pass\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "246e5833279d720bf718eccdf5f150a408cb6fa2b9c8a61c340bd22560c25832"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'out_shape' value is not used",
            "markdown": "Parameter 'out_shape' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/logger.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 448,
                  "startColumn": 9,
                  "charOffset": 16305,
                  "charLength": 43,
                  "snippet": {
                    "text": "out_shape: Optional[Tuple[int, ...]] = None"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 446,
                  "startColumn": 1,
                  "charOffset": 16248,
                  "charLength": 175,
                  "snippet": {
                    "text": "        batch_size: int,\n        n_samples: int,\n        out_shape: Optional[Tuple[int, ...]] = None,\n        n_classes: Optional[int] = None,\n        record_int: bool = True,"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "080d8f6818265a1f429e05c9c9779ecdcb37315013fd31f1bbf3b6a6f804804e"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'n_classes' value is not used",
            "markdown": "Parameter 'n_classes' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/logger.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 449,
                  "startColumn": 9,
                  "charOffset": 16358,
                  "charLength": 31,
                  "snippet": {
                    "text": "n_classes: Optional[int] = None"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 447,
                  "startColumn": 1,
                  "charOffset": 16273,
                  "charLength": 186,
                  "snippet": {
                    "text": "        n_samples: int,\n        out_shape: Optional[Tuple[int, ...]] = None,\n        n_classes: Optional[int] = None,\n        record_int: bool = True,\n        record_float: bool = False,"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "b519e03d8ff2a9a58c90daa5c5e639368dbb5c81eca5b6773b6d9edb74cae0bc"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Local variable 'weights' value is not used",
            "markdown": "Local variable 'weights' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/core.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 334,
                  "startColumn": 5,
                  "charOffset": 11764,
                  "charLength": 7,
                  "snippet": {
                    "text": "weights"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 332,
                  "startColumn": 1,
                  "charOffset": 11690,
                  "charLength": 204,
                  "snippet": {
                    "text": "        downloading of the weights (if not already in cache).\n    \"\"\"\n    weights: Optional[WeightsEnum] = None\n    try:\n        weights = torch.hub.load(\"pytorch/vision\", \"get_weight\", name=weights_name)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "17f986f33ff5f2a24d9593783c48d1f46d54fce87347a9563b769607b5af6b98"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'params' value is not used",
            "markdown": "Parameter 'params' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/metrics.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 183,
                  "startColumn": 9,
                  "charOffset": 6890,
                  "charLength": 8,
                  "snippet": {
                    "text": "**params"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 181,
                  "startColumn": 1,
                  "charOffset": 6799,
                  "charLength": 156,
                  "snippet": {
                    "text": "        data_size: Tuple[int, int, int],\n        model_type: str = \"segmentation\",\n        **params,\n    ) -> None:\n        super(SPMetrics, self).__init__("
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "ce3ec4db626bdfec3015403d6f245bb102903361bd5fea80cc0956baab1801c9"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'params' value is not used",
            "markdown": "Parameter 'params' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/metrics.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 278,
                  "startColumn": 9,
                  "charOffset": 10347,
                  "charLength": 8,
                  "snippet": {
                    "text": "**params"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 276,
                  "startColumn": 1,
                  "charOffset": 10261,
                  "charLength": 152,
                  "snippet": {
                    "text": "        model_type: str = \"segmentation\",\n        sample_pairs: bool = False,\n        **params,\n    ) -> None:\n        super(SSLMetrics, self).__init__("
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "41fb3ff58b6b63d248ec4ef8d38a9100c260c50639930cc0275af6af2d3b14b2"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'x' value is not used",
            "markdown": "Parameter 'x' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 497,
                  "startColumn": 5,
                  "charOffset": 16779,
                  "charLength": 18,
                  "snippet": {
                    "text": "x: Sequence[float]"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 495,
                  "startColumn": 1,
                  "charOffset": 16738,
                  "charLength": 102,
                  "snippet": {
                    "text": "@overload\ndef transform_coordinates(\n    x: Sequence[float],\n    y: Sequence[float],\n    src_crs: CRS,"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "6168d2e47307c0d869a47da9bb72a8442a39787732f2a520fdbf5f2e17f25a69"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'y' value is not used",
            "markdown": "Parameter 'y' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 498,
                  "startColumn": 5,
                  "charOffset": 16803,
                  "charLength": 18,
                  "snippet": {
                    "text": "y: Sequence[float]"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 496,
                  "startColumn": 1,
                  "charOffset": 16748,
                  "charLength": 118,
                  "snippet": {
                    "text": "def transform_coordinates(\n    x: Sequence[float],\n    y: Sequence[float],\n    src_crs: CRS,\n    new_crs: CRS = WGS84,"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "44d11a180dd295eaeaa96b10a9a99c1a54ee2330a0233217d503c31579a14184"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'src_crs' value is not used",
            "markdown": "Parameter 'src_crs' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 499,
                  "startColumn": 5,
                  "charOffset": 16827,
                  "charLength": 12,
                  "snippet": {
                    "text": "src_crs: CRS"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 497,
                  "startColumn": 1,
                  "charOffset": 16775,
                  "charLength": 137,
                  "snippet": {
                    "text": "    x: Sequence[float],\n    y: Sequence[float],\n    src_crs: CRS,\n    new_crs: CRS = WGS84,\n) -> Tuple[Sequence[float], Sequence[float]]:"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "e24aa60addce27ba6cc8fe46321364dd7559827c15d7dbb44cd8c7e8d79665f6"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'new_crs' value is not used",
            "markdown": "Parameter 'new_crs' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 500,
                  "startColumn": 5,
                  "charOffset": 16845,
                  "charLength": 20,
                  "snippet": {
                    "text": "new_crs: CRS = WGS84"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 498,
                  "startColumn": 1,
                  "charOffset": 16799,
                  "charLength": 141,
                  "snippet": {
                    "text": "    y: Sequence[float],\n    src_crs: CRS,\n    new_crs: CRS = WGS84,\n) -> Tuple[Sequence[float], Sequence[float]]:\n    ...  # pragma: no cover"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "cdef045d98b7faa58c9c821bbee84e8295358040ddeeb1e7939bdad575899093"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'x' value is not used",
            "markdown": "Parameter 'x' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 507,
                  "startColumn": 5,
                  "charOffset": 16984,
                  "charLength": 18,
                  "snippet": {
                    "text": "x: Sequence[float]"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 505,
                  "startColumn": 1,
                  "charOffset": 16943,
                  "charLength": 92,
                  "snippet": {
                    "text": "@overload\ndef transform_coordinates(\n    x: Sequence[float],\n    y: float,\n    src_crs: CRS,"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "642e122a6d58c366f0e0046179dc177fb88eb503d308e92a8c82991908ffc85e"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'y' value is not used",
            "markdown": "Parameter 'y' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 508,
                  "startColumn": 5,
                  "charOffset": 17008,
                  "charLength": 8,
                  "snippet": {
                    "text": "y: float"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 506,
                  "startColumn": 1,
                  "charOffset": 16953,
                  "charLength": 108,
                  "snippet": {
                    "text": "def transform_coordinates(\n    x: Sequence[float],\n    y: float,\n    src_crs: CRS,\n    new_crs: CRS = WGS84,"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "40735eb9bfbddadb269dcff2cb7123ccc762612a4b1b34185607e1907158984b"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'src_crs' value is not used",
            "markdown": "Parameter 'src_crs' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 509,
                  "startColumn": 5,
                  "charOffset": 17022,
                  "charLength": 12,
                  "snippet": {
                    "text": "src_crs: CRS"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 507,
                  "startColumn": 1,
                  "charOffset": 16980,
                  "charLength": 127,
                  "snippet": {
                    "text": "    x: Sequence[float],\n    y: float,\n    src_crs: CRS,\n    new_crs: CRS = WGS84,\n) -> Tuple[Sequence[float], Sequence[float]]:"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "c66b5e0665b7a3f92da6114b6374b2ba8c95e320471e92fafa72ee559588afc2"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'new_crs' value is not used",
            "markdown": "Parameter 'new_crs' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 510,
                  "startColumn": 5,
                  "charOffset": 17040,
                  "charLength": 20,
                  "snippet": {
                    "text": "new_crs: CRS = WGS84"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 508,
                  "startColumn": 1,
                  "charOffset": 17004,
                  "charLength": 131,
                  "snippet": {
                    "text": "    y: float,\n    src_crs: CRS,\n    new_crs: CRS = WGS84,\n) -> Tuple[Sequence[float], Sequence[float]]:\n    ...  # pragma: no cover"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "8612347e24880fe7293f48049feaea1a71f073d3d37e51190d65767f47821439"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'x' value is not used",
            "markdown": "Parameter 'x' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 517,
                  "startColumn": 5,
                  "charOffset": 17179,
                  "charLength": 8,
                  "snippet": {
                    "text": "x: float"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 515,
                  "startColumn": 1,
                  "charOffset": 17138,
                  "charLength": 92,
                  "snippet": {
                    "text": "@overload\ndef transform_coordinates(\n    x: float,\n    y: Sequence[float],\n    src_crs: CRS,"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "abccd5d7ee530a1e5c3fdd3f984bf70ddcfc806a977a6d889d6eeb3a88471e35"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'y' value is not used",
            "markdown": "Parameter 'y' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 518,
                  "startColumn": 5,
                  "charOffset": 17193,
                  "charLength": 18,
                  "snippet": {
                    "text": "y: Sequence[float]"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 516,
                  "startColumn": 1,
                  "charOffset": 17148,
                  "charLength": 108,
                  "snippet": {
                    "text": "def transform_coordinates(\n    x: float,\n    y: Sequence[float],\n    src_crs: CRS,\n    new_crs: CRS = WGS84,"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "2e5506595119333391dade0e82c0f65f9330b507c17a531459c70b0bbf4489a1"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'src_crs' value is not used",
            "markdown": "Parameter 'src_crs' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 519,
                  "startColumn": 5,
                  "charOffset": 17217,
                  "charLength": 12,
                  "snippet": {
                    "text": "src_crs: CRS"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 517,
                  "startColumn": 1,
                  "charOffset": 17175,
                  "charLength": 127,
                  "snippet": {
                    "text": "    x: float,\n    y: Sequence[float],\n    src_crs: CRS,\n    new_crs: CRS = WGS84,\n) -> Tuple[Sequence[float], Sequence[float]]:"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "ef3a4ec985ae8435805d451d507ac2d95c41721755641b94b98768c27ff14252"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'new_crs' value is not used",
            "markdown": "Parameter 'new_crs' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 520,
                  "startColumn": 5,
                  "charOffset": 17235,
                  "charLength": 20,
                  "snippet": {
                    "text": "new_crs: CRS = WGS84"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 518,
                  "startColumn": 1,
                  "charOffset": 17189,
                  "charLength": 141,
                  "snippet": {
                    "text": "    y: Sequence[float],\n    src_crs: CRS,\n    new_crs: CRS = WGS84,\n) -> Tuple[Sequence[float], Sequence[float]]:\n    ...  # pragma: no cover"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "5ace191d4c6a506672065b2535afee34fcc221a2a3238a573cf0ef1e1f0df93b"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'x' value is not used",
            "markdown": "Parameter 'x' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 527,
                  "startColumn": 5,
                  "charOffset": 17374,
                  "charLength": 8,
                  "snippet": {
                    "text": "x: float"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 525,
                  "startColumn": 1,
                  "charOffset": 17333,
                  "charLength": 149,
                  "snippet": {
                    "text": "@overload\ndef transform_coordinates(\n    x: float, y: float, src_crs: CRS, new_crs: CRS = WGS84\n) -> Tuple[float, float]:\n    ...  # pragma: no cover"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "1993424e06923caf54d88f2d7c60494a5b5a62acf3fa7cd9c6e484470038629f"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'y' value is not used",
            "markdown": "Parameter 'y' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 527,
                  "startColumn": 15,
                  "charOffset": 17384,
                  "charLength": 8,
                  "snippet": {
                    "text": "y: float"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 525,
                  "startColumn": 1,
                  "charOffset": 17333,
                  "charLength": 149,
                  "snippet": {
                    "text": "@overload\ndef transform_coordinates(\n    x: float, y: float, src_crs: CRS, new_crs: CRS = WGS84\n) -> Tuple[float, float]:\n    ...  # pragma: no cover"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "e489d4e155b92ee07ee40c06c20361cd42715fae4d1cbadcbbf247cf440b1c15"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'src_crs' value is not used",
            "markdown": "Parameter 'src_crs' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 527,
                  "startColumn": 25,
                  "charOffset": 17394,
                  "charLength": 12,
                  "snippet": {
                    "text": "src_crs: CRS"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 525,
                  "startColumn": 1,
                  "charOffset": 17333,
                  "charLength": 149,
                  "snippet": {
                    "text": "@overload\ndef transform_coordinates(\n    x: float, y: float, src_crs: CRS, new_crs: CRS = WGS84\n) -> Tuple[float, float]:\n    ...  # pragma: no cover"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "1dea04ef1aff49093aac67a1a43271729ebf7ada6c373468edf8d34529bbe0f4"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'new_crs' value is not used",
            "markdown": "Parameter 'new_crs' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 527,
                  "startColumn": 39,
                  "charOffset": 17408,
                  "charLength": 20,
                  "snippet": {
                    "text": "new_crs: CRS = WGS84"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 525,
                  "startColumn": 1,
                  "charOffset": 17333,
                  "charLength": 149,
                  "snippet": {
                    "text": "@overload\ndef transform_coordinates(\n    x: float, y: float, src_crs: CRS, new_crs: CRS = WGS84\n) -> Tuple[float, float]:\n    ...  # pragma: no cover"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "2e49a6873c3dc5ce9994430e0623d6cae6cfbcde5503aa1b18dd3e86fb4072f0"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'array' value is not used",
            "markdown": "Parameter 'array' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 911,
                  "startColumn": 5,
                  "charOffset": 31175,
                  "charLength": 24,
                  "snippet": {
                    "text": "array: NDArray[Any, Int]"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 909,
                  "startColumn": 1,
                  "charOffset": 31141,
                  "charLength": 134,
                  "snippet": {
                    "text": "@overload\ndef mask_transform(\n    array: NDArray[Any, Int], matrix: Dict[int, int]\n) -> NDArray[Any, Int]:\n    ...  # pragma: no cover"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "981983ebf1852c0d250f1fdee50c412e75b6e7d1953ebe4f19c732c3c55f3a94"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'matrix' value is not used",
            "markdown": "Parameter 'matrix' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 911,
                  "startColumn": 31,
                  "charOffset": 31201,
                  "charLength": 22,
                  "snippet": {
                    "text": "matrix: Dict[int, int]"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 909,
                  "startColumn": 1,
                  "charOffset": 31141,
                  "charLength": 134,
                  "snippet": {
                    "text": "@overload\ndef mask_transform(\n    array: NDArray[Any, Int], matrix: Dict[int, int]\n) -> NDArray[Any, Int]:\n    ...  # pragma: no cover"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "b6a31780c8f093e6634b51ce5c746045b9bbb75b30c6f5329b16a15b20c979e7"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'array' value is not used",
            "markdown": "Parameter 'array' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 917,
                  "startColumn": 20,
                  "charOffset": 31307,
                  "charLength": 17,
                  "snippet": {
                    "text": "array: LongTensor"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 915,
                  "startColumn": 1,
                  "charOffset": 31277,
                  "charLength": 116,
                  "snippet": {
                    "text": "\n@overload\ndef mask_transform(array: LongTensor, matrix: Dict[int, int]) -> LongTensor:\n    ...  # pragma: no cover\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "7d67fe439406c8e4f240c6cf2066be04cbf6567faa9c36fa865995fb7ab09cde"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnusedLocalInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Parameter 'matrix' value is not used",
            "markdown": "Parameter 'matrix' value is not used"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 917,
                  "startColumn": 39,
                  "charOffset": 31326,
                  "charLength": 22,
                  "snippet": {
                    "text": "matrix: Dict[int, int]"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 915,
                  "startColumn": 1,
                  "charOffset": 31277,
                  "charLength": 116,
                  "snippet": {
                    "text": "\n@overload\ndef mask_transform(array: LongTensor, matrix: Dict[int, int]) -> LongTensor:\n    ...  # pragma: no cover\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "89581a7af475c18433f18193ab9ece0c70094b257edb710d37c5d3a96a7b93d4"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyShadowingNamesInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Shadows name 'name' from outer scope",
            "markdown": "Shadows name 'name' from outer scope"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/datasets.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 528,
                  "startColumn": 13,
                  "charOffset": 20253,
                  "charLength": 4,
                  "snippet": {
                    "text": "name"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 526,
                  "startColumn": 1,
                  "charOffset": 20227,
                  "charLength": 175,
                  "snippet": {
                    "text": "\n    Example:\n        >>> name = \"RandomResizedCrop\"\n        >>> params = {\"module\": \"torchvision.transforms\", \"size\": 128}\n        >>> transform = get_transform(name, params)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "f83d9eb8a9f296530f589bccb1ce1b02e92515d4b2ddbd805d6473b7a6319bd2"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyShadowingNamesInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Shadows name 'params' from outer scope",
            "markdown": "Shadows name 'params' from outer scope"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/datasets.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 529,
                  "startColumn": 13,
                  "charOffset": 20292,
                  "charLength": 6,
                  "snippet": {
                    "text": "params"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 527,
                  "startColumn": 1,
                  "charOffset": 20228,
                  "charLength": 175,
                  "snippet": {
                    "text": "    Example:\n        >>> name = \"RandomResizedCrop\"\n        >>> params = {\"module\": \"torchvision.transforms\", \"size\": 128}\n        >>> transform = get_transform(name, params)\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "537ede22325cf565e01bec7bf1693bb208c52303938b6dbe9666a1a609f7d7c5"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyShadowingNamesInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Shadows name 'transform' from outer scope",
            "markdown": "Shadows name 'transform' from outer scope"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/datasets.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 530,
                  "startColumn": 13,
                  "charOffset": 20363,
                  "charLength": 9,
                  "snippet": {
                    "text": "transform"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 528,
                  "startColumn": 1,
                  "charOffset": 20241,
                  "charLength": 174,
                  "snippet": {
                    "text": "        >>> name = \"RandomResizedCrop\"\n        >>> params = {\"module\": \"torchvision.transforms\", \"size\": 128}\n        >>> transform = get_transform(name, params)\n\n    Raises:"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "8a9e57bd009eeb8b7fd46bd400ba0a816ba4206f6ea0de9c24653914439b8a63"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyShadowingNamesInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Shadows name 'transform_params' from outer scope",
            "markdown": "Shadows name 'transform_params' from outer scope"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/datasets.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 560,
                  "startColumn": 13,
                  "charOffset": 21542,
                  "charLength": 16,
                  "snippet": {
                    "text": "transform_params"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 558,
                  "startColumn": 1,
                  "charOffset": 21516,
                  "charLength": 213,
                  "snippet": {
                    "text": "\n    Example:\n        >>> transform_params = {\n        >>>    \"CenterCrop\": {\"module\": \"torchvision.transforms\", \"size\": 128},\n        >>>     \"RandomHorizontalFlip\": {\"module\": \"torchvision.transforms\", \"p\": 0.7}"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "a35ebf33c14bff2974288bd1df56adec524415a1e6d7a11fa2ec7ea14eae55ae"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyUnboundLocalVariableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "Local variable 'exit_code' might be referenced before assignment",
            "markdown": "Local variable 'exit_code' might be referenced before assignment"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/bin/MinervaPipe.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 70,
                  "startColumn": 22,
                  "charOffset": 2826,
                  "charLength": 9,
                  "snippet": {
                    "text": "exit_code"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 68,
                  "startColumn": 1,
                  "charOffset": 2725,
                  "charLength": 143,
                  "snippet": {
                    "text": "            print(err)\n            print(f\"Error in {key} experiment -> ABORT\")\n            sys.exit(exit_code)  # type: ignore\n\n        print("
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "49ec8b1fb91ff20152c777675d2f4618f3de12fe19b15f519a6f25c9ccb7cbd9"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyPep8NamingInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Lowercase variable imported as non-lowercase",
            "markdown": "Lowercase variable imported as non-lowercase"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 151,
                  "startColumn": 36,
                  "charOffset": 5251,
                  "charLength": 1,
                  "snippet": {
                    "text": "F"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 149,
                  "startColumn": 1,
                  "charOffset": 5149,
                  "charLength": 171,
                  "snippet": {
                    "text": "from tabulate import tabulate\nfrom torch import LongTensor, Tensor\nfrom torch.nn import functional as F\nfrom torch.nn.modules import Module\nfrom torch.types import _device"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "2d464a2c81685f7916d0f8ad088c43eb0b965d0349d761d33463e4bb86420e02"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyPep8NamingInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Lowercase variable imported as non-lowercase",
            "markdown": "Lowercase variable imported as non-lowercase"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 50,
                  "startColumn": 31,
                  "charOffset": 1913,
                  "charLength": 1,
                  "snippet": {
                    "text": "F"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 48,
                  "startColumn": 1,
                  "charOffset": 1869,
                  "charLength": 100,
                  "snippet": {
                    "text": "\nimport torch\nimport torch.nn.functional as F\nimport torch.nn.modules as nn\nfrom torch import Tensor"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "65725519c05472c1ec4b6469310026a5e9da4bf6eb25ee184236f29ad8716877"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyPep8NamingInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "CamelCase variable imported as constant",
            "markdown": "CamelCase variable imported as constant"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/trainer.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 49,
                  "startColumn": 58,
                  "charOffset": 2217,
                  "charLength": 3,
                  "snippet": {
                    "text": "DDP"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 47,
                  "startColumn": 1,
                  "charOffset": 2099,
                  "charLength": 218,
                  "snippet": {
                    "text": "from torch import Tensor\nfrom torch.nn.modules import Module\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard.writer import SummaryWriter"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "1dd032031ef34438a7adb59462b34501c2f383685b070f8fe5244638dac33f8f"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyTypeHintsInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Literal' may be parameterized with literal ints, byte and unicode strings, bools, Enum values, None, other literal types, or type aliases to other literal types",
            "markdown": "'Literal' may be parameterized with literal ints, byte and unicode strings, bools, Enum values, None, other literal types, or type aliases to other literal types"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/datasets.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 332,
                  "startColumn": 41,
                  "charOffset": 12185,
                  "charLength": 8,
                  "snippet": {
                    "text": "\"params\""
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 330,
                  "startColumn": 1,
                  "charOffset": 12076,
                  "charLength": 198,
                  "snippet": {
                    "text": "        dataset_class: Callable[..., GeoDataset],\n        root: str,\n        subdataset_params: Dict[Literal[\"params\"], Dict[str, Any]],\n        _transformations: Optional[Any],\n    ) -> GeoDataset:"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "7304fd820407e6cec1f8abeffe6a1c4e0a922238d0a8704fba9b3e6962d19f47"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyTypeHintsInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Literal' may be parameterized with literal ints, byte and unicode strings, bools, Enum values, None, other literal types, or type aliases to other literal types",
            "markdown": "'Literal' may be parameterized with literal ints, byte and unicode strings, bools, Enum values, None, other literal types, or type aliases to other literal types"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/datasets.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 549,
                  "startColumn": 53,
                  "charOffset": 21020,
                  "charLength": 5,
                  "snippet": {
                    "text": "False"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 547,
                  "startColumn": 1,
                  "charOffset": 20941,
                  "charLength": 217,
                  "snippet": {
                    "text": "\ndef make_transformations(\n    transform_params: Union[Dict[str, Any], Literal[False]], key: Optional[str] = None\n) -> Optional[Any]:\n    \"\"\"Constructs a transform or series of transforms based on parameters provided."
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "e4f552a21530aaa4888d996c38d70efc673df4a64062b1f2dd6a761898cd5237"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyTypeHintsInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Literal' may be parameterized with literal ints, byte and unicode strings, bools, Enum values, None, other literal types, or type aliases to other literal types",
            "markdown": "'Literal' may be parameterized with literal ints, byte and unicode strings, bools, Enum values, None, other literal types, or type aliases to other literal types"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/fcn.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 94,
                  "startColumn": 34,
                  "charOffset": 4297,
                  "charLength": 15,
                  "snippet": {
                    "text": "\"32\", \"16\", \"8\""
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 92,
                  "startColumn": 1,
                  "charOffset": 4195,
                  "charLength": 217,
                  "snippet": {
                    "text": "        n_classes: int = 8,\n        backbone_name: str = \"ResNet18\",\n        decoder_variant: Literal[\"32\", \"16\", \"8\"] = \"32\",\n        backbone_weight_path: Optional[str] = None,\n        freeze_backbone: bool = False,"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "0edd9e155cd4cf971d363e59f4066dd53e4715bbd7f925d99ff07b9369483e69"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyTypeHintsInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Literal' may be parameterized with literal ints, byte and unicode strings, bools, Enum values, None, other literal types, or type aliases to other literal types",
            "markdown": "'Literal' may be parameterized with literal ints, byte and unicode strings, bools, Enum values, None, other literal types, or type aliases to other literal types"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/fcn.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 195,
                  "startColumn": 26,
                  "charOffset": 9258,
                  "charLength": 15,
                  "snippet": {
                    "text": "\"32\", \"16\", \"8\""
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 193,
                  "startColumn": 1,
                  "charOffset": 9173,
                  "charLength": 125,
                  "snippet": {
                    "text": "        in_channel: int = 512,\n        n_classes: int = 21,\n        variant: Literal[\"32\", \"16\", \"8\"] = \"32\",\n    ) -> None:\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "bb46a7211be63d69bce3379f6e3a9006ac99270616cb77a53a2e85bd631d828a"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyTypeHintsInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Literal' may be parameterized with literal ints, byte and unicode strings, bools, Enum values, None, other literal types, or type aliases to other literal types",
            "markdown": "'Literal' may be parameterized with literal ints, byte and unicode strings, bools, Enum values, None, other literal types, or type aliases to other literal types"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/fcn.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 199,
                  "startColumn": 31,
                  "charOffset": 9384,
                  "charLength": 15,
                  "snippet": {
                    "text": "\"32\", \"16\", \"8\""
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 197,
                  "startColumn": 1,
                  "charOffset": 9298,
                  "charLength": 156,
                  "snippet": {
                    "text": "\n        super(DCN, self).__init__(n_classes=n_classes)\n        self.variant: Literal[\"32\", \"16\", \"8\"] = variant\n\n        assert type(self.n_classes) is int"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "10f373aedacda46bd19d791b23a15084306dac9785332efc21e0377ade46aa98"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyIncorrectDocstringInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Missing parameter cls in docstring",
            "markdown": "Missing parameter cls in docstring"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 284,
                  "startColumn": 17,
                  "charOffset": 9851,
                  "charLength": 3,
                  "snippet": {
                    "text": "cls"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 282,
                  "startColumn": 1,
                  "charOffset": 9833,
                  "charLength": 170,
                  "snippet": {
                    "text": "\n\ndef tg_to_torch(cls, keys: Optional[Sequence[str]] = None):\n    \"\"\"Ensures wrapped transform can handle both :class:`Tensor` and :mod:`torchgeo` style ``dict`` inputs.\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "a8863a62eb9a787be9eee3e9f90273b30fd1bb9a1d1d418a2bea4280db2766db"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyIncorrectDocstringInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Missing parameter _testing in docstring",
            "markdown": "Missing parameter _testing in docstring"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 1427,
                  "startColumn": 5,
                  "charOffset": 49581,
                  "charLength": 22,
                  "snippet": {
                    "text": "_testing: bool = False"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 1425,
                  "startColumn": 1,
                  "charOffset": 49512,
                  "charLength": 182,
                  "snippet": {
                    "text": "    env_name: str = \"env\",\n    host_num: Union[str, int] = 6006,\n    _testing: bool = False,\n) -> Optional[int]:\n    \"\"\"Runs the :mod:`TensorBoard` logs and hosts on a local webpage."
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "044561ea2624132d2baf02d3c222c552dc00872fcd2703ebe273820cbe6bf4c4"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyProtectedMemberInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Access to a protected member _to_tuple of a class",
            "markdown": "Access to a protected member _to_tuple of a class"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/samplers.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 44,
                  "startColumn": 37,
                  "charOffset": 2008,
                  "charLength": 9,
                  "snippet": {
                    "text": "_to_tuple"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 42,
                  "startColumn": 1,
                  "charOffset": 1866,
                  "charLength": 209,
                  "snippet": {
                    "text": "from torchgeo.datasets.utils import BoundingBox\nfrom torchgeo.samplers import BatchGeoSampler, GeoSampler\nfrom torchgeo.samplers.utils import _to_tuple, get_random_bounding_box\n\nfrom minerva.utils import utils"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "4a7746ca03243bfdebd44d7ba89018864bf89c64507ada5c2b5f822424ee0201"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyProtectedMemberInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Access to a protected member _api of a class",
            "markdown": "Access to a protected member _api of a class"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/core.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 67,
                  "startColumn": 6,
                  "charOffset": 2254,
                  "charLength": 23,
                  "snippet": {
                    "text": "torchvision.models._api"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 65,
                  "startColumn": 1,
                  "charOffset": 2147,
                  "charLength": 194,
                  "snippet": {
                    "text": "from torch.nn.parallel import DataParallel, DistributedDataParallel\nfrom torch.optim import Optimizer\nfrom torchvision.models._api import WeightsEnum\n\nfrom minerva.utils.utils import func_by_str"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "fea7b1a07e3116d1da444c126c8893283768dea53c08e91345382245cac5db32"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyProtectedMemberInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Access to a protected member _api of a class",
            "markdown": "Access to a protected member _api of a class"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/bin/TorchWeightDownloader.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 41,
                  "startColumn": 6,
                  "charOffset": 1764,
                  "charLength": 23,
                  "snippet": {
                    "text": "torchvision.models._api"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 39,
                  "startColumn": 1,
                  "charOffset": 1730,
                  "charLength": 122,
                  "snippet": {
                    "text": "from typing import Optional\n\nfrom torchvision.models._api import WeightsEnum\n\nfrom minerva.models import get_torch_weights"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "238edbc318068ab6a3b46d29d24e68f7daed00ca7ab8825857499c2e3e345b93"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyProtectedMemberInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Access to a protected member _api of a class",
            "markdown": "Access to a protected member _api of a class"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/resnet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 48,
                  "startColumn": 6,
                  "charOffset": 1911,
                  "charLength": 23,
                  "snippet": {
                    "text": "torchvision.models._api"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 46,
                  "startColumn": 1,
                  "charOffset": 1845,
                  "charLength": 179,
                  "snippet": {
                    "text": "from torch import Tensor\nfrom torch.nn.modules import Module\nfrom torchvision.models._api import WeightsEnum\nfrom torchvision.models.resnet import BasicBlock, Bottleneck, conv1x1\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "e554696e6e1f8e923f8f6899a8d34375b3647af2cb2c4b69e2f51e28bc3b7187"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyProtectedMemberInspection",
          "kind": "fail",
          "level": "note",
          "message": {
            "text": "Access to a protected member _device of a class",
            "markdown": "Access to a protected member _device of a class"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 153,
                  "startColumn": 25,
                  "charOffset": 5313,
                  "charLength": 7,
                  "snippet": {
                    "text": "_device"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 151,
                  "startColumn": 1,
                  "charOffset": 5216,
                  "charLength": 153,
                  "snippet": {
                    "text": "from torch.nn import functional as F\nfrom torch.nn.modules import Module\nfrom torch.types import _device\nfrom torchgeo.datasets.utils import BoundingBox\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "b4559d156bce325d3597143c47023ba8bbd4f1318f19273d612cd40cc9be3f18"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WEAK WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'MinervaModel' object is not callable",
            "markdown": "'MinervaModel' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/fcn.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 144,
                  "startColumn": 13,
                  "charOffset": 6339,
                  "charLength": 16,
                  "snippet": {
                    "text": "self.backbone(x)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 142,
                  "startColumn": 1,
                  "charOffset": 6257,
                  "charLength": 127,
                  "snippet": {
                    "text": "                each pixel input 'x' being of that class.\n        \"\"\"\n        z = self.backbone(x)\n        z = self.decoder(z)\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "58f0e3b301407500d016be018ecf9e33ec3a2e298a2348e841f0d65b4ccd7e05"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'DCN' object is not callable",
            "markdown": "'DCN' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/fcn.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 145,
                  "startColumn": 13,
                  "charOffset": 6368,
                  "charLength": 15,
                  "snippet": {
                    "text": "self.decoder(z)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 143,
                  "startColumn": 1,
                  "charOffset": 6315,
                  "charLength": 106,
                  "snippet": {
                    "text": "        \"\"\"\n        z = self.backbone(x)\n        z = self.decoder(z)\n\n        assert isinstance(z, Tensor)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "cefec8ca9325b7d51c0c3a386360597b9b670175c55a453d120f2badbf4b953b"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'MinervaModel' object is not callable",
            "markdown": "'MinervaModel' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/siamese.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 187,
                  "startColumn": 35,
                  "charOffset": 7261,
                  "charLength": 16,
                  "snippet": {
                    "text": "self.backbone(x)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 185,
                  "startColumn": 1,
                  "charOffset": 7167,
                  "charLength": 166,
                  "snippet": {
                    "text": "            embedding vector from the backbone.\n        \"\"\"\n        f: Tensor = torch.flatten(self.backbone(x)[0], start_dim=1)\n        g: Tensor = self.proj_head(f)\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "370be41b1e4117a898f9b7584db26c7dd6fd4227cb6f668245ff03c80b5a6a28"
          },
          "baselineState": "new",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'MinervaModel' object is not callable",
            "markdown": "'MinervaModel' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/siamese.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 385,
                  "startColumn": 50,
                  "charOffset": 14412,
                  "charLength": 16,
                  "snippet": {
                    "text": "self.backbone(x)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 383,
                  "startColumn": 1,
                  "charOffset": 14303,
                  "charLength": 212,
                  "snippet": {
                    "text": "            embedding vector from the backbone.\n        \"\"\"\n        z: Tensor = self.proj_head(torch.flatten(self.backbone(x)[0], start_dim=1))  # type: ignore[attr-defined]\n\n        p: Tensor = self.predictor(z)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "aa5f4e34337ba1ceb988157be04b515db7cdf4f5ec27b7961502d1947a6b1ef6"
          },
          "baselineState": "new",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'ResNet' object is not callable",
            "markdown": "'ResNet' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/resnet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 416,
                  "startColumn": 75,
                  "charOffset": 18571,
                  "charLength": 37,
                  "snippet": {
                    "text": "self.network(\n            x\n        )"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 414,
                  "startColumn": 1,
                  "charOffset": 18418,
                  "charLength": 245,
                  "snippet": {
                    "text": "            network places on the input ``x`` being of each class.\n        \"\"\"\n        z: Union[Tensor, Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]] = self.network(\n            x\n        )\n        if isinstance(z, Tensor):\n            return z"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "d7b48dba49f3d620f2724891e4604956f1a39d6525cc15697ea01fcb8c0bbab9"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'ResNet' object is not callable",
            "markdown": "'ResNet' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/resnet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 508,
                  "startColumn": 75,
                  "charOffset": 22764,
                  "charLength": 37,
                  "snippet": {
                    "text": "self.network(\n            x\n        )"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 506,
                  "startColumn": 1,
                  "charOffset": 22613,
                  "charLength": 243,
                  "snippet": {
                    "text": "            network places on the input `x` being of each class.\n        \"\"\"\n        z: Union[Tensor, Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]] = self.network(\n            x\n        )\n        if isinstance(z, Tensor):\n            return z"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "f1c004d21e871a6138589ede80e63022ef64e28a622fe6874764475ab9a401a0"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'ResNet' object is not callable",
            "markdown": "'ResNet' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/resnet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 604,
                  "startColumn": 75,
                  "charOffset": 27098,
                  "charLength": 37,
                  "snippet": {
                    "text": "self.network(\n            x\n        )"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 602,
                  "startColumn": 1,
                  "charOffset": 26947,
                  "charLength": 243,
                  "snippet": {
                    "text": "            network places on the input `x` being of each class.\n        \"\"\"\n        z: Union[Tensor, Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]] = self.network(\n            x\n        )\n        if isinstance(z, Tensor):\n            return z"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "f2d8171b02d39657477eab6b60d0f9f483f92e3f2924ceee6ba43b331db50d0b"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'ResNet' object is not callable",
            "markdown": "'ResNet' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/resnet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 700,
                  "startColumn": 75,
                  "charOffset": 31437,
                  "charLength": 37,
                  "snippet": {
                    "text": "self.network(\n            x\n        )"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 698,
                  "startColumn": 1,
                  "charOffset": 31286,
                  "charLength": 243,
                  "snippet": {
                    "text": "            network places on the input `x` being of each class.\n        \"\"\"\n        z: Union[Tensor, Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]] = self.network(\n            x\n        )\n        if isinstance(z, Tensor):\n            return z"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "0dc0bd937eac55b53cb66c78492e1e873790b286c4dfa21fb73e85830ab3b241"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'ResNet' object is not callable",
            "markdown": "'ResNet' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/resnet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 796,
                  "startColumn": 75,
                  "charOffset": 35776,
                  "charLength": 37,
                  "snippet": {
                    "text": "self.network(\n            x\n        )"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 794,
                  "startColumn": 1,
                  "charOffset": 35625,
                  "charLength": 243,
                  "snippet": {
                    "text": "            network places on the input `x` being of each class.\n        \"\"\"\n        z: Union[Tensor, Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]] = self.network(\n            x\n        )\n        if isinstance(z, Tensor):\n            return z"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "112a9c895c5ca27057bf2ab4b8972affb63e073b0cfd0aacde97ccf650a44b40"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'DoubleConv' object is not callable",
            "markdown": "'DoubleConv' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 193,
                  "startColumn": 13,
                  "charOffset": 6830,
                  "charLength": 12,
                  "snippet": {
                    "text": "self.conv(x)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 191,
                  "startColumn": 1,
                  "charOffset": 6748,
                  "charLength": 132,
                  "snippet": {
                    "text": "        x = torch.cat([x2, x1], dim=1)  # type: ignore[attr-defined]\n\n        x = self.conv(x)\n\n        assert isinstance(x, Tensor)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "5b16b6d5b3fa568fd14bed6e1cd4b3ac224c6d756e1cb2010602a9d95b9da911"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'DoubleConv' object is not callable",
            "markdown": "'DoubleConv' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 294,
                  "startColumn": 14,
                  "charOffset": 10332,
                  "charLength": 11,
                  "snippet": {
                    "text": "self.inc(x)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 292,
                  "startColumn": 1,
                  "charOffset": 10306,
                  "charLength": 93,
                  "snippet": {
                    "text": "        \"\"\"\n\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "a8d6e978b92c81d48c5d6fd20048ee6017db09e3a7f5e379d60e532175013365"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Down' object is not callable",
            "markdown": "'Down' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 295,
                  "startColumn": 14,
                  "charOffset": 10357,
                  "charLength": 14,
                  "snippet": {
                    "text": "self.down1(x1)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 293,
                  "startColumn": 1,
                  "charOffset": 10318,
                  "charLength": 109,
                  "snippet": {
                    "text": "\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "02028e1cfe7955488a20d3640bf9c71ae861b3295c453cb8ac00a8bbc0e59005"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Down' object is not callable",
            "markdown": "'Down' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 296,
                  "startColumn": 14,
                  "charOffset": 10385,
                  "charLength": 14,
                  "snippet": {
                    "text": "self.down2(x2)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 294,
                  "startColumn": 1,
                  "charOffset": 10319,
                  "charLength": 136,
                  "snippet": {
                    "text": "        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "4b1fd60fd18d3c43248d196b75a3fe7cde086ac42606a12274693760ad447d48"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Down' object is not callable",
            "markdown": "'Down' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 297,
                  "startColumn": 14,
                  "charOffset": 10413,
                  "charLength": 14,
                  "snippet": {
                    "text": "self.down3(x3)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 295,
                  "startColumn": 1,
                  "charOffset": 10344,
                  "charLength": 112,
                  "snippet": {
                    "text": "        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "7a25ae7a205dd8e906762809fd94401865a0ff70e47cf389e2f089b0cf0ee324"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Down' object is not callable",
            "markdown": "'Down' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 298,
                  "startColumn": 14,
                  "charOffset": 10441,
                  "charLength": 14,
                  "snippet": {
                    "text": "self.down4(x4)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 296,
                  "startColumn": 1,
                  "charOffset": 10372,
                  "charLength": 113,
                  "snippet": {
                    "text": "        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n\n        x = self.up1(x5, x4)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "1dfbb066934695f177bd611a2994bbb3def28d979ed491fed6b41babd7ec8198"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Up' object is not callable",
            "markdown": "'Up' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 300,
                  "startColumn": 13,
                  "charOffset": 10469,
                  "charLength": 16,
                  "snippet": {
                    "text": "self.up1(x5, x4)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 298,
                  "startColumn": 1,
                  "charOffset": 10428,
                  "charLength": 113,
                  "snippet": {
                    "text": "        x5 = self.down4(x4)\n\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "d40e4e7800f7ca0291349dbe3b7746e64fbd2e35bf8f63b15e33a06c25ddf8f0"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Up' object is not callable",
            "markdown": "'Up' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 301,
                  "startColumn": 13,
                  "charOffset": 10498,
                  "charLength": 15,
                  "snippet": {
                    "text": "self.up2(x, x3)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 299,
                  "startColumn": 1,
                  "charOffset": 10456,
                  "charLength": 113,
                  "snippet": {
                    "text": "\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "7a32feb8734cb39d9b7fa388cff48065439eb6e18b4cd5f38cc97ba7adcf49cb"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Up' object is not callable",
            "markdown": "'Up' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 302,
                  "startColumn": 13,
                  "charOffset": 10526,
                  "charLength": 15,
                  "snippet": {
                    "text": "self.up3(x, x2)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 300,
                  "startColumn": 1,
                  "charOffset": 10457,
                  "charLength": 113,
                  "snippet": {
                    "text": "        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "21b320479607523a6e6411aa8e4f116dd039eb5e758fc62441a44eb185a44a1a"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Up' object is not callable",
            "markdown": "'Up' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 303,
                  "startColumn": 13,
                  "charOffset": 10554,
                  "charLength": 15,
                  "snippet": {
                    "text": "self.up4(x, x1)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 301,
                  "startColumn": 1,
                  "charOffset": 10486,
                  "charLength": 122,
                  "snippet": {
                    "text": "        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n\n        logits: Tensor = self.outc(x)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "71f422175777027cc87fd37a2bd41864cb73c843f4d161330f385c16e791327d"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'OutConv' object is not callable",
            "markdown": "'OutConv' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 305,
                  "startColumn": 26,
                  "charOffset": 10596,
                  "charLength": 12,
                  "snippet": {
                    "text": "self.outc(x)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 303,
                  "startColumn": 1,
                  "charOffset": 10542,
                  "charLength": 109,
                  "snippet": {
                    "text": "        x = self.up4(x, x1)\n\n        logits: Tensor = self.outc(x)\n\n        assert isinstance(logits, Tensor)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "bfd56faa7db1ec094c1845372a7803b09e9ac091c062f24ed04e8fdb9b1251e1"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'MinervaModel' object is not callable",
            "markdown": "'MinervaModel' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 410,
                  "startColumn": 30,
                  "charOffset": 15485,
                  "charLength": 16,
                  "snippet": {
                    "text": "self.backbone(x)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 408,
                  "startColumn": 1,
                  "charOffset": 15379,
                  "charLength": 182,
                  "snippet": {
                    "text": "        \"\"\"\n        # Output tensors from the residual blocks of the resnet.\n        x4, x3, x2, x1, x0 = self.backbone(x)\n\n        # Concats and upsamples the outputs of the resnet."
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "5f9d7c4cdfb40cc3ef7ad4b7cec3008f86100939dd907a79b5d600d69a1083b9"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Up' object is not callable",
            "markdown": "'Up' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 413,
                  "startColumn": 13,
                  "charOffset": 15574,
                  "charLength": 16,
                  "snippet": {
                    "text": "self.up1(x4, x3)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 411,
                  "startColumn": 1,
                  "charOffset": 15502,
                  "charLength": 144,
                  "snippet": {
                    "text": "\n        # Concats and upsamples the outputs of the resnet.\n        x = self.up1(x4, x3)\n        x = self.up2(x, x2)\n        x = self.up3(x, x1)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "09d31d32fc6a3405fa5703b3b8341feed3d11f0590b8776a62f7b9c296b3e7b0"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Up' object is not callable",
            "markdown": "'Up' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 414,
                  "startColumn": 13,
                  "charOffset": 15603,
                  "charLength": 15,
                  "snippet": {
                    "text": "self.up2(x, x2)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 412,
                  "startColumn": 1,
                  "charOffset": 15503,
                  "charLength": 144,
                  "snippet": {
                    "text": "        # Concats and upsamples the outputs of the resnet.\n        x = self.up1(x4, x3)\n        x = self.up2(x, x2)\n        x = self.up3(x, x1)\n"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "66467aa654ac687b30cd9f7e0d36a7d343c0c5b8cf4a4c3ea0239c040f643c44"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'Up' object is not callable",
            "markdown": "'Up' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 415,
                  "startColumn": 13,
                  "charOffset": 15631,
                  "charLength": 15,
                  "snippet": {
                    "text": "self.up3(x, x1)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 413,
                  "startColumn": 1,
                  "charOffset": 15562,
                  "charLength": 193,
                  "snippet": {
                    "text": "        x = self.up1(x4, x3)\n        x = self.up2(x, x2)\n        x = self.up3(x, x1)\n\n        # Add the upsampled and deconv tensor to the output of the input convolutional layer of the resnet."
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "ad99f41875f000875e45b14fcae76ef29d2bd4562a64e6e1c4a1df6267335a86"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'OutConv' object is not callable",
            "markdown": "'OutConv' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/unet.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 426,
                  "startColumn": 26,
                  "charOffset": 16042,
                  "charLength": 12,
                  "snippet": {
                    "text": "self.outc(x)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 424,
                  "startColumn": 1,
                  "charOffset": 15931,
                  "charLength": 166,
                  "snippet": {
                    "text": "\n        # Reduces the latent channels to the number of classes for the ouput tensor.\n        logits: Tensor = self.outc(x)\n\n        assert isinstance(logits, Tensor)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "de97c11f0a4668b4f7dd9b945dd13052b261d6e15bd071963921750eb860a193"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'MinervaSiamese' object is not callable",
            "markdown": "'MinervaSiamese' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/trainer.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 873,
                  "startColumn": 34,
                  "charOffset": 37589,
                  "charLength": 20,
                  "snippet": {
                    "text": "self.model(val_data)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 871,
                  "startColumn": 1,
                  "charOffset": 37465,
                  "charLength": 190,
                  "snippet": {
                    "text": "                    feature, _ = self.model.forward_single(val_data)\n                else:\n                    feature, _ = self.model(val_data)\n\n                feature_list.append(feature)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "cbdd81a1532fd0d09a410015a9e09a4765f74bffb8d36e15aa58907fafb3048d"
          },
          "baselineState": "new",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyCallingNonCallableInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "'MinervaSiamese' object is not callable",
            "markdown": "'MinervaSiamese' object is not callable"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/trainer.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 901,
                  "startColumn": 34,
                  "charOffset": 38831,
                  "charLength": 21,
                  "snippet": {
                    "text": "self.model(test_data)"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 899,
                  "startColumn": 1,
                  "charOffset": 38706,
                  "charLength": 187,
                  "snippet": {
                    "text": "                    feature, _ = self.model.forward_single(test_data)\n                else:\n                    feature, _ = self.model(test_data)\n\n                total_num += batch_size"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "a0db896efa424249625f2960d251caec10b9bc0bf059627529a770961489ea0e"
          },
          "baselineState": "new",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyRedeclarationInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "Redeclared '__call__' defined above without usage",
            "markdown": "Redeclared '__call__' defined above without usage"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/transforms.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 216,
                  "startColumn": 9,
                  "charOffset": 7335,
                  "charLength": 8,
                  "snippet": {
                    "text": "__call__"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 214,
                  "startColumn": 1,
                  "charOffset": 7294,
                  "charLength": 142,
                  "snippet": {
                    "text": "        ...  # pragma: no cover\n\n    def __call__(\n        self, sample: Union[Tensor, Dict[str, Any]]\n    ) -> Union[Tensor, Dict[str, Any]]:"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "60dbbda4bec863b25c6d84462748a46071f7f18ab2e927b465e5a33493b2f910"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyRedeclarationInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "Redeclared 'step' defined above without usage",
            "markdown": "Redeclared 'step' defined above without usage"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/models/core.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 152,
                  "startColumn": 9,
                  "charOffset": 5648,
                  "charLength": 4,
                  "snippet": {
                    "text": "step"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 150,
                  "startColumn": 1,
                  "charOffset": 5607,
                  "charLength": 79,
                  "snippet": {
                    "text": "        ...  # pragma: no cover\n\n    def step(\n        self,\n        x: Tensor,"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "0e0feb091e9d13fda41a273b5e62a7e53ad58976f604bbfced59ee19eeb2b14d"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyRedeclarationInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "Redeclared '__call__' defined above without usage",
            "markdown": "Redeclared '__call__' defined above without usage"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 318,
                  "startColumn": 13,
                  "charOffset": 11039,
                  "charLength": 8,
                  "snippet": {
                    "text": "__call__"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 316,
                  "startColumn": 1,
                  "charOffset": 10990,
                  "charLength": 202,
                  "snippet": {
                    "text": "            ...  # pragma: no cover\n\n        def __call__(self, batch: Union[Dict[str, Any], Tensor]) -> Dict[str, Any]:\n            if isinstance(batch, Tensor):\n                return self.wrap(batch)"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "ef4e21105cf58fb82c1bc0e747c450fd59d703bd21796f5b72903f97385be1d2"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyRedeclarationInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "Redeclared 'transform_coordinates' defined above without usage",
            "markdown": "Redeclared 'transform_coordinates' defined above without usage"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 532,
                  "startColumn": 5,
                  "charOffset": 17489,
                  "charLength": 21,
                  "snippet": {
                    "text": "transform_coordinates"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 530,
                  "startColumn": 1,
                  "charOffset": 17483,
                  "charLength": 104,
                  "snippet": {
                    "text": "\n\ndef transform_coordinates(\n    x: Union[Sequence[float], float],\n    y: Union[Sequence[float], float],"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "56601b76566c4d35a6255add90afd08b8e145d4d6b9f244ab70b0caf47c94867"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        },
        {
          "ruleId": "PyRedeclarationInspection",
          "kind": "fail",
          "level": "warning",
          "message": {
            "text": "Redeclared 'mask_transform' defined above without usage",
            "markdown": "Redeclared 'mask_transform' defined above without usage"
          },
          "locations": [
            {
              "physicalLocation": {
                "artifactLocation": {
                  "uri": "minerva/utils/utils.py",
                  "uriBaseId": "SRCROOT"
                },
                "region": {
                  "startLine": 921,
                  "startColumn": 5,
                  "charOffset": 31399,
                  "charLength": 14,
                  "snippet": {
                    "text": "mask_transform"
                  },
                  "sourceLanguage": "Python"
                },
                "contextRegion": {
                  "startLine": 919,
                  "startColumn": 1,
                  "charOffset": 31393,
                  "charLength": 98,
                  "snippet": {
                    "text": "\n\ndef mask_transform(\n    array: Union[NDArray[Any, Int], LongTensor],\n    matrix: Dict[int, int],"
                  }
                }
              },
              "logicalLocations": [
                {
                  "fullyQualifiedName": "project",
                  "kind": "module"
                }
              ]
            }
          ],
          "partialFingerprints": {
            "equalIndicator/v1": "f160794e1f6a0ef99efd253058656a0ab90417e66ad4b700d4051f5759d7fd08"
          },
          "baselineState": "unchanged",
          "properties": {
            "ideaSeverity": "WARNING",
            "tags": [
              "Python"
            ]
          }
        }
      ],
      "automationDetails": {
        "id": "project/qodana/2023-02-16",
        "guid": "a730eafd-3c3f-4b2e-ba0c-ac38471f5266",
        "properties": {
          "jobUrl": ""
        }
      },
      "newlineSequences": [
        "\r\n",
        "\n"
      ],
      "properties": {
        "qodana.sanity.results": [
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "docs/conf.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 2067,
                    "snippet": {
                      "text": "# Configuration file for the Sphinx documentation builder.\n#\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\n\nsys.path.insert(0, os.path.abspath(\"../minerva/\"))\n\n\n# -- Project information -----------------------------------------------------\n\nproject = \"Minerva\"\ncopyright = \"2023, Harry Baker\"\nauthor = \"Harry Baker\"\n\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\"sphinx.ext.napoleon\", \"sphinx.ext.autodoc\", \"myst_parser\"]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\"]\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\nadd_module_names = False\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \"sphinx_rtd_theme\"\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"source/_static\"]\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 2067,
                    "snippet": {
                      "text": "# Configuration file for the Sphinx documentation builder.\n#\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\n\nsys.path.insert(0, os.path.abspath(\"../minerva/\"))\n\n\n# -- Project information -----------------------------------------------------\n\nproject = \"Minerva\"\ncopyright = \"2023, Harry Baker\"\nauthor = \"Harry Baker\"\n\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\"sphinx.ext.napoleon\", \"sphinx.ext.autodoc\", \"myst_parser\"]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\"]\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\nadd_module_names = False\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \"sphinx_rtd_theme\"\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"source/_static\"]\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "7b43fe3dc6d10cfa1466082112b7c96d2f64033c44fd67e10b9cfb289acd00c2"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/Torch_to_ONNX.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 2994,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Converts :mod:`torch` model weights to ``ONNX`` format.\"\"\"\n\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\n\nfrom minerva.trainer import Trainer\nfrom minerva.utils import CONFIG, runner, universal_path\n\n\n# =====================================================================================================================\n#                                                      MAIN\n# =====================================================================================================================\ndef main(gpu: int, args) -> None:\n\n    trainer = Trainer(\n        gpu=gpu, rank=args.rank, world_size=args.world_size, verbose=False, **CONFIG\n    )\n\n    weights_path = universal_path(CONFIG[\"dir\"][\"cache\"]) / CONFIG[\"pre_train_name\"]\n\n    trainer.save_model(fn=weights_path, format=\"onnx\")\n\n    print(f\"Model saved to --> {weights_path}.onnx\")\n\n    if gpu == 0:\n        trainer.close()\n\n\nif __name__ == \"__main__\":\n    # ---+ CLI +--------------------------------------------------------------+\n    parser = argparse.ArgumentParser(parents=[runner.GENERIC_PARSER], add_help=False)\n\n    # ------------ ADD EXTRA ARGS FOR THE PARSER HERE ------------------------+\n\n    # Export args from CLI.\n    cli_args = parser.parse_args()\n\n    # Configure the arguments and environment variables.\n    runner.config_args(cli_args)\n\n    # Run the specified main with distributed computing and the arguments provided.\n    runner.distributed_run(main, cli_args)\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 2994,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Converts :mod:`torch` model weights to ``ONNX`` format.\"\"\"\n\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\n\nfrom minerva.trainer import Trainer\nfrom minerva.utils import CONFIG, runner, universal_path\n\n\n# =====================================================================================================================\n#                                                      MAIN\n# =====================================================================================================================\ndef main(gpu: int, args) -> None:\n\n    trainer = Trainer(\n        gpu=gpu, rank=args.rank, world_size=args.world_size, verbose=False, **CONFIG\n    )\n\n    weights_path = universal_path(CONFIG[\"dir\"][\"cache\"]) / CONFIG[\"pre_train_name\"]\n\n    trainer.save_model(fn=weights_path, format=\"onnx\")\n\n    print(f\"Model saved to --> {weights_path}.onnx\")\n\n    if gpu == 0:\n        trainer.close()\n\n\nif __name__ == \"__main__\":\n    # ---+ CLI +--------------------------------------------------------------+\n    parser = argparse.ArgumentParser(parents=[runner.GENERIC_PARSER], add_help=False)\n\n    # ------------ ADD EXTRA ARGS FOR THE PARSER HERE ------------------------+\n\n    # Export args from CLI.\n    cli_args = parser.parse_args()\n\n    # Configure the arguments and environment variables.\n    runner.config_args(cli_args)\n\n    # Run the specified main with distributed computing and the arguments provided.\n    runner.distributed_run(main, cli_args)\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "768086fa81a69ff895549d8711b32dbd949e18b9a025194849a54e91bca1efde"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/MinervaExp.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 3483,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# PYTHON_ARGCOMPLETE_OK\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Script to execute the creation, fitting and testing of a computer vision neural network model.\n\nDesigned for use in SLURM clusters and with distributed computing support.\n\nSome code derived from Barlow Twins implementation of distributed computing:\nhttps://github.com/facebookresearch/barlowtwins\n\"\"\"\n\n# TODO: Add ability to conduct hyper-parameter iterative variation experimentation.\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\n\nimport argcomplete\n\nfrom minerva.trainer import Trainer\nfrom minerva.utils import CONFIG, runner\n\n\n# =====================================================================================================================\n#                                                      MAIN\n# =====================================================================================================================\ndef main(gpu: int, args) -> None:\n    trainer = Trainer(\n        gpu=gpu,\n        rank=args.rank,\n        world_size=args.world_size,\n        wandb_run=args.wandb_run,\n        **CONFIG\n    )\n\n    if not CONFIG.get(\"eval\", False):\n        trainer.fit()\n\n    if CONFIG.get(\"pre_train\", False) and gpu == 0:\n        trainer.save_backbone()\n        trainer.close()\n\n    if not CONFIG.get(\"pre_train\", False):\n        trainer.test()\n\n\nif __name__ == \"__main__\":\n    # ---+ CLI +--------------------------------------------------------------+\n    parser = argparse.ArgumentParser(parents=[runner.GENERIC_PARSER], add_help=False)\n    argcomplete.autocomplete(parser)\n    # ------------ ADD EXTRA ARGS FOR THE PARSER HERE ------------------------+\n\n    # Export args from CLI.\n    cli_args = parser.parse_args()\n\n    with runner.WandbConnectionManager():\n        # Configure the arguments and environment variables.\n        runner.config_args(cli_args)\n\n        # Run the specified main with distributed computing and the arguments provided.\n        runner.distributed_run(main, cli_args)\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 3483,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# PYTHON_ARGCOMPLETE_OK\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Script to execute the creation, fitting and testing of a computer vision neural network model.\n\nDesigned for use in SLURM clusters and with distributed computing support.\n\nSome code derived from Barlow Twins implementation of distributed computing:\nhttps://github.com/facebookresearch/barlowtwins\n\"\"\"\n\n# TODO: Add ability to conduct hyper-parameter iterative variation experimentation.\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\n\nimport argcomplete\n\nfrom minerva.trainer import Trainer\nfrom minerva.utils import CONFIG, runner\n\n\n# =====================================================================================================================\n#                                                      MAIN\n# =====================================================================================================================\ndef main(gpu: int, args) -> None:\n    trainer = Trainer(\n        gpu=gpu,\n        rank=args.rank,\n        world_size=args.world_size,\n        wandb_run=args.wandb_run,\n        **CONFIG\n    )\n\n    if not CONFIG.get(\"eval\", False):\n        trainer.fit()\n\n    if CONFIG.get(\"pre_train\", False) and gpu == 0:\n        trainer.save_backbone()\n        trainer.close()\n\n    if not CONFIG.get(\"pre_train\", False):\n        trainer.test()\n\n\nif __name__ == \"__main__\":\n    # ---+ CLI +--------------------------------------------------------------+\n    parser = argparse.ArgumentParser(parents=[runner.GENERIC_PARSER], add_help=False)\n    argcomplete.autocomplete(parser)\n    # ------------ ADD EXTRA ARGS FOR THE PARSER HERE ------------------------+\n\n    # Export args from CLI.\n    cli_args = parser.parse_args()\n\n    with runner.WandbConnectionManager():\n        # Configure the arguments and environment variables.\n        runner.config_args(cli_args)\n\n        # Run the specified main with distributed computing and the arguments provided.\n        runner.distributed_run(main, cli_args)\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "f0f94b562342f1cb4c30b953c6920033bce4d17d2289d2040fd9ffcbd1bf96a5"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/modelio.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 5620,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Module to handle various IO from `dataloaders` and to models.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"sup_tg\",\n    \"ssl_pair_tg\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nfrom typing import Any, Dict, Sequence, Tuple, Union\n\nimport numpy as np\nimport torch\nfrom torch import Tensor\nfrom torchgeo.datasets.utils import BoundingBox\n\nfrom minerva.models import MinervaModel\n\n\n# =====================================================================================================================\n#                                                     METHODS\n# =====================================================================================================================\ndef sup_tg(\n    batch: Dict[Any, Any],\n    model: MinervaModel,\n    device: torch.device,  # type: ignore[name-defined]\n    mode: str,\n    **kwargs,\n) -> Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]], Tensor, Sequence[BoundingBox]]:\n    \"\"\"Provides IO functionality for a supervised model using `torchgeo` datasets.\n\n    Args:\n        batch (Dict[Any, Any]): Batch of data in a dict. Must have 'image', 'mask' and 'bbox' keys.\n        model (MinervaModel): Model being fitted.\n        device (torch.device): `torch` device object to send data to (e.g. CUDA device).\n        mode (str): Mode of model fitting to use.\n\n    Returns:\n        Tuple[Tensor, Tensor, Tensor, Sequence[BoundingBox]]: The `loss`, the model output `z`, the `y` supplied\n            and the bounding boxes of the input images supplied.\n    \"\"\"\n    # Extracts the x and y batches from the dict.\n    images: Tensor = batch[\"image\"]\n    masks: Tensor = batch[\"mask\"]\n\n    # Re-arranges the x and y batches.\n    x_batch: Tensor = images.to(torch.float)  # type: ignore[attr-defined]\n    y_batch: Tensor\n\n    # Squeeze out axis 1 if only 1 element wide.\n    if masks.shape[1] == 1:\n        masks = np.squeeze(masks.detach().cpu().numpy(), axis=1)\n\n    if isinstance(masks, Tensor):\n        masks = masks.detach().cpu().numpy()\n    y_batch = torch.tensor(masks, dtype=torch.long)  # type: ignore[attr-defined]\n\n    # Transfer to GPU.\n    x: Tensor = x_batch.to(device)\n    y: Tensor = y_batch.to(device)\n\n    # Runs a training epoch.\n    if mode == \"train\":\n        loss, z = model.step(x, y, train=True)\n\n    # Runs a validation or test epoch.\n    else:\n        loss, z = model.step(x, y, train=False)\n\n    bbox: Sequence[BoundingBox] = batch[\"bbox\"]\n    assert isinstance(bbox, Sequence)\n    return loss, z, y, bbox\n\n\ndef ssl_pair_tg(\n    batch: Tuple[Dict[str, Any], Dict[str, Any]],\n    model: MinervaModel,\n    device: torch.device,  # type: ignore[name-defined]\n    mode: str,\n    **kwargs,\n) -> Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]], None, Sequence[BoundingBox]]:\n    \"\"\"Provides IO functionality for a self-supervised Siamese model using :mod:`torchgeo` datasets.\n\n    Args:\n        batch (Tuple[Dict[str, Any], Dict[str, Any]]): Pair of batches of data in :class:`dicts`.\n            Must have ``\"image\"`` and ``\"bbox\"`` keys.\n        model (MinervaModel): Model being fitted.\n        device (torch.device): :mod:`torch` device object to send data to (e.g. ``CUDA`` device).\n        mode (str): Mode of model fitting to use.\n\n    Returns:\n        Tuple[Tensor, Tensor, Tensor, Sequence[BoundingBox]]: The ``loss``, the model output ``z``,\n        the ``y`` supplied and the bounding boxes of the original input images supplied.\n    \"\"\"\n    # Extracts the x_i batch from the dict.\n    x_i_batch: Tensor = batch[0][\"image\"]\n    x_j_batch: Tensor = batch[1][\"image\"]\n\n    # Ensures images are floats.\n    x_i_batch = x_i_batch.to(torch.float)  # type: ignore[attr-defined]\n    x_j_batch = x_j_batch.to(torch.float)  # type: ignore[attr-defined]\n\n    # Stacks each side of the pair batches together.\n    x_batch = torch.stack([x_i_batch, x_j_batch])\n\n    # Transfer to GPU.\n    x = x_batch.to(device, non_blocking=True)\n\n    # Runs a training epoch.\n    if mode == \"train\":\n        loss, z = model.step(x, train=True)\n\n    # Runs a validation epoch.\n    else:\n        loss, z = model.step(x, train=False)\n\n    return loss, z, None, batch[0][\"bbox\"] + batch[1][\"bbox\"]\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 5620,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Module to handle various IO from `dataloaders` and to models.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"sup_tg\",\n    \"ssl_pair_tg\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nfrom typing import Any, Dict, Sequence, Tuple, Union\n\nimport numpy as np\nimport torch\nfrom torch import Tensor\nfrom torchgeo.datasets.utils import BoundingBox\n\nfrom minerva.models import MinervaModel\n\n\n# =====================================================================================================================\n#                                                     METHODS\n# =====================================================================================================================\ndef sup_tg(\n    batch: Dict[Any, Any],\n    model: MinervaModel,\n    device: torch.device,  # type: ignore[name-defined]\n    mode: str,\n    **kwargs,\n) -> Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]], Tensor, Sequence[BoundingBox]]:\n    \"\"\"Provides IO functionality for a supervised model using `torchgeo` datasets.\n\n    Args:\n        batch (Dict[Any, Any]): Batch of data in a dict. Must have 'image', 'mask' and 'bbox' keys.\n        model (MinervaModel): Model being fitted.\n        device (torch.device): `torch` device object to send data to (e.g. CUDA device).\n        mode (str): Mode of model fitting to use.\n\n    Returns:\n        Tuple[Tensor, Tensor, Tensor, Sequence[BoundingBox]]: The `loss`, the model output `z`, the `y` supplied\n            and the bounding boxes of the input images supplied.\n    \"\"\"\n    # Extracts the x and y batches from the dict.\n    images: Tensor = batch[\"image\"]\n    masks: Tensor = batch[\"mask\"]\n\n    # Re-arranges the x and y batches.\n    x_batch: Tensor = images.to(torch.float)  # type: ignore[attr-defined]\n    y_batch: Tensor\n\n    # Squeeze out axis 1 if only 1 element wide.\n    if masks.shape[1] == 1:\n        masks = np.squeeze(masks.detach().cpu().numpy(), axis=1)\n\n    if isinstance(masks, Tensor):\n        masks = masks.detach().cpu().numpy()\n    y_batch = torch.tensor(masks, dtype=torch.long)  # type: ignore[attr-defined]\n\n    # Transfer to GPU.\n    x: Tensor = x_batch.to(device)\n    y: Tensor = y_batch.to(device)\n\n    # Runs a training epoch.\n    if mode == \"train\":\n        loss, z = model.step(x, y, train=True)\n\n    # Runs a validation or test epoch.\n    else:\n        loss, z = model.step(x, y, train=False)\n\n    bbox: Sequence[BoundingBox] = batch[\"bbox\"]\n    assert isinstance(bbox, Sequence)\n    return loss, z, y, bbox\n\n\ndef ssl_pair_tg(\n    batch: Tuple[Dict[str, Any], Dict[str, Any]],\n    model: MinervaModel,\n    device: torch.device,  # type: ignore[name-defined]\n    mode: str,\n    **kwargs,\n) -> Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]], None, Sequence[BoundingBox]]:\n    \"\"\"Provides IO functionality for a self-supervised Siamese model using :mod:`torchgeo` datasets.\n\n    Args:\n        batch (Tuple[Dict[str, Any], Dict[str, Any]]): Pair of batches of data in :class:`dicts`.\n            Must have ``\"image\"`` and ``\"bbox\"`` keys.\n        model (MinervaModel): Model being fitted.\n        device (torch.device): :mod:`torch` device object to send data to (e.g. ``CUDA`` device).\n        mode (str): Mode of model fitting to use.\n\n    Returns:\n        Tuple[Tensor, Tensor, Tensor, Sequence[BoundingBox]]: The ``loss``, the model output ``z``,\n        the ``y`` supplied and the bounding boxes of the original input images supplied.\n    \"\"\"\n    # Extracts the x_i batch from the dict.\n    x_i_batch: Tensor = batch[0][\"image\"]\n    x_j_batch: Tensor = batch[1][\"image\"]\n\n    # Ensures images are floats.\n    x_i_batch = x_i_batch.to(torch.float)  # type: ignore[attr-defined]\n    x_j_batch = x_j_batch.to(torch.float)  # type: ignore[attr-defined]\n\n    # Stacks each side of the pair batches together.\n    x_batch = torch.stack([x_i_batch, x_j_batch])\n\n    # Transfer to GPU.\n    x = x_batch.to(device, non_blocking=True)\n\n    # Runs a training epoch.\n    if mode == \"train\":\n        loss, z = model.step(x, train=True)\n\n    # Runs a validation epoch.\n    else:\n        loss, z = model.step(x, train=False)\n\n    return loss, z, None, batch[0][\"bbox\"] + batch[1][\"bbox\"]\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "d3e98a0f2cca5cff454fb60f3340dd12666a3117f01a60a19b462f4d8ea82420"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/utils/__init__.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 3530,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Utility functionality, visualisation and configuration for :mod:`minerva`.\n\nAttributes:\n    CONFIG_NAME (str): Name of the config to be used in the experiment.\n    CONFIG_PATH (str): Path to the config.\n    MASTER_PARSER (ArgumentParser): Argparser for the CLI for the config loading.\n    CONFIG (Dict[str, Any]): The master config loaded by :mod:`config_load`.\n    AUX_CONFIGS (Dict[str, Any]): Dictionary containing the auxilary configs loaded by :mod:`config_load`.\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"universal_path\",\n    \"CONFIG_NAME\",\n    \"CONFIG_PATH\",\n    \"MASTER_PARSER\",\n    \"CONFIG\",\n    \"AUX_CONFIGS\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\nimport os\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom minerva.utils.config_load import check_paths, load_configs\nfrom minerva.utils.config_load import universal_path as universal_path  # noqa: F401\n\n# =====================================================================================================================\n#                                                     GLOBALS\n# =====================================================================================================================\n# Objects to hold the config name and path.\nCONFIG_NAME: Optional[str]\nCONFIG_PATH: Optional[Path]\n\nMASTER_PARSER = argparse.ArgumentParser(add_help=False)\nMASTER_PARSER.add_argument(\n    \"-c\",\n    \"--config\",\n    type=str,\n    help=\"Path to the config file defining experiment\",\n)\nMASTER_PARSER.add_argument(\n    \"--use-default-conf-dir\",\n    dest=\"use_default_conf_dir\",\n    action=\"store_true\",\n    help=\"Set config path to default\",\n)\n_args, _ = MASTER_PARSER.parse_known_args()\n\n# Store the current working directory (i.e where script is being run from).\n_cwd = os.getcwd()\n\n_path, CONFIG_NAME, CONFIG_PATH = check_paths(_args.config, _args.use_default_conf_dir)\n\n# Loads the configs from file using paths found in sys.args.\nCONFIG, AUX_CONFIGS = load_configs(_path)\n\n# Change the working directory back to script location.\nos.chdir(_cwd)\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 3530,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Utility functionality, visualisation and configuration for :mod:`minerva`.\n\nAttributes:\n    CONFIG_NAME (str): Name of the config to be used in the experiment.\n    CONFIG_PATH (str): Path to the config.\n    MASTER_PARSER (ArgumentParser): Argparser for the CLI for the config loading.\n    CONFIG (Dict[str, Any]): The master config loaded by :mod:`config_load`.\n    AUX_CONFIGS (Dict[str, Any]): Dictionary containing the auxilary configs loaded by :mod:`config_load`.\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"universal_path\",\n    \"CONFIG_NAME\",\n    \"CONFIG_PATH\",\n    \"MASTER_PARSER\",\n    \"CONFIG\",\n    \"AUX_CONFIGS\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\nimport os\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom minerva.utils.config_load import check_paths, load_configs\nfrom minerva.utils.config_load import universal_path as universal_path  # noqa: F401\n\n# =====================================================================================================================\n#                                                     GLOBALS\n# =====================================================================================================================\n# Objects to hold the config name and path.\nCONFIG_NAME: Optional[str]\nCONFIG_PATH: Optional[Path]\n\nMASTER_PARSER = argparse.ArgumentParser(add_help=False)\nMASTER_PARSER.add_argument(\n    \"-c\",\n    \"--config\",\n    type=str,\n    help=\"Path to the config file defining experiment\",\n)\nMASTER_PARSER.add_argument(\n    \"--use-default-conf-dir\",\n    dest=\"use_default_conf_dir\",\n    action=\"store_true\",\n    help=\"Set config path to default\",\n)\n_args, _ = MASTER_PARSER.parse_known_args()\n\n# Store the current working directory (i.e where script is being run from).\n_cwd = os.getcwd()\n\n_path, CONFIG_NAME, CONFIG_PATH = check_paths(_args.config, _args.use_default_conf_dir)\n\n# Loads the configs from file using paths found in sys.args.\nCONFIG, AUX_CONFIGS = load_configs(_path)\n\n# Change the working directory back to script location.\nos.chdir(_cwd)\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "e67b62780bb6759ccb6f94d4addbb4cf6801dc6c15cce0bb9157a7c494ce5d5d"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/samplers.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 11036,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Module containing custom samplers for :mod:`torchgeo` datasets.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"RandomPairGeoSampler\",\n    \"RandomPairBatchGeoSampler\",\n    \"get_greater_bbox\",\n    \"get_pair_bboxes\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport random\nfrom typing import Iterator, List, Optional, Sequence, Tuple, Union\n\nfrom torchgeo.datasets import GeoDataset\nfrom torchgeo.datasets.utils import BoundingBox\nfrom torchgeo.samplers import BatchGeoSampler, GeoSampler\nfrom torchgeo.samplers.utils import _to_tuple, get_random_bounding_box\n\nfrom minerva.utils import utils\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass RandomPairGeoSampler(GeoSampler):\n    \"\"\"Samples geo-close pairs of elements from a region of interest randomly.\n\n    An extension to :class:`RandomGeoSampler` that supports paired sampling (i.e for GeoCLR).\n    \"\"\"\n\n    def __init__(\n        self,\n        dataset: GeoDataset,\n        size: Union[Tuple[float, float], float],\n        length: int,\n        roi: Optional[BoundingBox] = None,\n        max_r: float = 256.0,\n    ) -> None:\n        \"\"\"Initialize a new Sampler instance.\n\n        The ``size`` argument can either be:\n\n        * a single ``float`` - in which case the same value is used for the height and\n          width dimension\n        * a ``tuple`` of two floats - in which case, the first *float* is used for the\n          height dimension, and the second *float* for the width dimension\n\n        Args:\n            dataset (GeoDataset): Dataset to index from.\n            size (Tuple[float, float] | float): Dimensions of each :term:`patch` in units of CRS.\n            length (int): number of random samples to draw per epoch.\n            roi (BoundingBox): Optional; Region of interest to sample from (``minx``, ``maxx``, ``miny``, ``maxy``,\n                ``mint``, ``maxt``). (defaults to the bounds of ``dataset.index``).\n            max_r (float): Optional; Maximum geo-spatial distance (from centre to centre)\n                to sample matching sample from.\n        \"\"\"\n        super().__init__(dataset, roi)\n        self.size = _to_tuple(size)\n        self.length = length\n        self.max_r = max_r\n        self.hits = []\n        for hit in self.index.intersection(tuple(self.roi), objects=True):\n            bounds = BoundingBox(*hit.bounds)  # type: ignore\n            if (\n                bounds.maxx - bounds.minx > self.size[1]\n                and bounds.maxy - bounds.miny > self.size[0]\n            ):\n                self.hits.append(hit)\n\n    def __iter__(self) -> Iterator[Tuple[BoundingBox, BoundingBox]]:  # type: ignore[override]\n        \"\"\"Return a pair of BoundingBox indices of a dataset that are geospatially close.\n\n        Returns:\n            Tuple[BoundingBox, BoundingBox]: Tuple of bounding boxes to index a dataset.\n        \"\"\"\n        for _ in range(len(self)):\n            # Choose a random tile.\n            hit = random.choice(self.hits)\n            bounds = BoundingBox(*hit.bounds)\n\n            bbox_a, bbox_b = get_pair_bboxes(bounds, self.size, self.res, self.max_r)\n\n            yield bbox_a, bbox_b\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of samples in a single epoch.\n\n        Returns:\n            int: Length of the epoch.\n        \"\"\"\n        return self.length\n\n\nclass RandomPairBatchGeoSampler(BatchGeoSampler):\n    \"\"\"Samples batches of pairs of elements from a region of interest randomly.\n\n    This is particularly useful during training when you want to maximize the size of\n    the dataset and return as many random :term:`patches` as possible.\n\n    An extension to :class:`RandomBatchGeoSampler` that supports paired sampling (i.e. for GeoCLR)\n    and ability to samples from multiple tiles per batch to increase variance of batch.\n    \"\"\"\n\n    def __init__(\n        self,\n        dataset: GeoDataset,\n        size: Union[Tuple[float, float], float],\n        batch_size: int,\n        length: int,\n        roi: Optional[BoundingBox] = None,\n        max_r: float = 256.0,\n        tiles_per_batch: int = 4,\n    ) -> None:\n        \"\"\"Initialize a new Sampler instance.\n\n        The ``size`` argument can either be:\n\n        * a single ``float`` - in which case the same value is used for the height and\n          width dimension\n        * a ``tuple`` of two floats - in which case, the first *float* is used for the\n          height dimension, and the second *float* for the width dimension\n\n        Args:\n            dataset (GeoDataset): Dataset to index from.\n            size (Union[Tuple[float, float], float]): Dimensions of each :term:`patch` in units of CRS.\n            batch_size (int): Number of samples per batch.\n            length (int): Number of samples per epoch.\n            roi (BoundingBox): Optional; Region of interest to sample from (``minx``, ``maxx``, ``miny``, ``maxy``,\n                ``mint``, ``maxt``). (defaults to the bounds of ``dataset.index``)\n            max_r (float): Optional; Maximum geo-spatial distance (from centre to centre)\n                to sample matching sample from.\n            tiles_per_batch (int): Optional; Number of tiles to sample from per batch.\n                Must be a multiple of ``batch_size``.\n\n        Raises:\n            ValueError: If ``tiles_per_batch`` is not a multiple of ``batch_size``.\n        \"\"\"\n        super().__init__(dataset, roi)\n        self.size = _to_tuple(size)\n        self.batch_size = batch_size\n        self.length = length\n        self.max_r = max_r\n        self.hits = list(self.index.intersection(tuple(self.roi), objects=True))\n\n        self.tiles_per_batch = tiles_per_batch\n\n        if self.batch_size % tiles_per_batch == 0:\n            self.sam_per_tile = self.batch_size // tiles_per_batch\n        else:\n            raise ValueError(f\"{tiles_per_batch=} is not a multiple of {batch_size=}\")\n\n    def __iter__(self) -> Iterator[List[Tuple[BoundingBox, BoundingBox]]]:  # type: ignore[override]\n        \"\"\"Return the indices of a dataset.\n\n        Returns:\n            batch of (minx, maxx, miny, maxy, mint, maxt) coordinates to index a dataset\n        \"\"\"\n        for _ in range(len(self)):\n            batch = []\n            for _ in range(self.tiles_per_batch):\n                # Choose a random tile\n                hit = random.choice(self.hits)\n                bounds = BoundingBox(*hit.bounds)  # type: ignore\n\n                # Choose random indices within that tile\n                for _ in range(self.sam_per_tile):\n                    bbox_a, bbox_b = get_pair_bboxes(\n                        bounds, self.size, self.res, self.max_r\n                    )\n                    batch.append((bbox_a, bbox_b))\n\n            yield batch\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of batches in a single epoch.\n\n        Returns:\n            int: Number of batches in an epoch\n        \"\"\"\n        return self.length // self.batch_size\n\n\ndef get_greater_bbox(\n    bbox: BoundingBox, r: float, size: Union[float, int, Sequence[float]]\n) -> BoundingBox:\n    \"\"\"Return a bounding box at ``max_r`` distance around the first box.\n\n    Args:\n        bbox (BoundingBox): Bounding box of the original sample.\n        r (float): Distance in pixels to extend the original bounding box by\n            to get a new greater bounds to sample from.\n        size (float | Sequence[float]): The (``x``, ``y``) size of the :term:`patch` that ``bbox``\n            represents in pixels. Will only use size[0] if a :class:`Sequence`.\n\n    Returns:\n        BoundingBox: Greater bounds around original bounding box to sample from.\n    \"\"\"\n    x: float\n    if isinstance(size, Sequence):\n        assert isinstance(size, Sequence)\n        x = float(size[0])\n    else:\n        assert isinstance(size, (float, int))\n        x = float(size)\n\n    # Calculates the geospatial distance to add to the existing bounding box to get\n    # the box to sample the other side of the pair from.\n    r_in_crs = r * abs(bbox.maxx - bbox.minx) / float(x)\n\n    return BoundingBox(\n        bbox.minx - r_in_crs,\n        bbox.maxx + r_in_crs,\n        bbox.miny - r_in_crs,\n        bbox.maxy + r_in_crs,\n        bbox.mint,\n        bbox.maxt,\n    )\n\n\ndef get_pair_bboxes(\n    bounds: BoundingBox,\n    size: Union[Tuple[float, float], float],\n    res: float,\n    max_r: float,\n) -> Tuple[BoundingBox, BoundingBox]:\n    \"\"\"Samples a pair of bounding boxes geo-spatially close to each other.\n\n    Args:\n        bounds (BoundingBox): Maximum bounds of the :term:`tile` to sample pair from.\n        size (Union[Tuple[float, float], float]): Size of each :term:`patch`.\n        res (float): Resolution to sample :term:`patch` at.\n        max_r (float): Padding around original :term:`patch` to sample new :term:`patch` from.\n\n    Returns:\n        Tuple[BoundingBox, BoundingBox]: Pair of bounding boxes to sample pair of patches from dataset.\n    \"\"\"\n    # Choose a random index within that tile.\n    bbox_a = get_random_bounding_box(bounds, size, res)\n\n    max_bounds = get_greater_bbox(bbox_a, max_r, size)\n\n    # Check that the new bbox cannot exceed the bounds of the tile.\n    max_bounds = utils.check_within_bounds(max_bounds, bounds)\n\n    # Randomly sample another box at a max distance of max_r from box_a.\n    bbox_b = get_random_bounding_box(max_bounds, size, res)\n\n    return bbox_a, bbox_b\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 11036,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Module containing custom samplers for :mod:`torchgeo` datasets.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"RandomPairGeoSampler\",\n    \"RandomPairBatchGeoSampler\",\n    \"get_greater_bbox\",\n    \"get_pair_bboxes\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport random\nfrom typing import Iterator, List, Optional, Sequence, Tuple, Union\n\nfrom torchgeo.datasets import GeoDataset\nfrom torchgeo.datasets.utils import BoundingBox\nfrom torchgeo.samplers import BatchGeoSampler, GeoSampler\nfrom torchgeo.samplers.utils import _to_tuple, get_random_bounding_box\n\nfrom minerva.utils import utils\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass RandomPairGeoSampler(GeoSampler):\n    \"\"\"Samples geo-close pairs of elements from a region of interest randomly.\n\n    An extension to :class:`RandomGeoSampler` that supports paired sampling (i.e for GeoCLR).\n    \"\"\"\n\n    def __init__(\n        self,\n        dataset: GeoDataset,\n        size: Union[Tuple[float, float], float],\n        length: int,\n        roi: Optional[BoundingBox] = None,\n        max_r: float = 256.0,\n    ) -> None:\n        \"\"\"Initialize a new Sampler instance.\n\n        The ``size`` argument can either be:\n\n        * a single ``float`` - in which case the same value is used for the height and\n          width dimension\n        * a ``tuple`` of two floats - in which case, the first *float* is used for the\n          height dimension, and the second *float* for the width dimension\n\n        Args:\n            dataset (GeoDataset): Dataset to index from.\n            size (Tuple[float, float] | float): Dimensions of each :term:`patch` in units of CRS.\n            length (int): number of random samples to draw per epoch.\n            roi (BoundingBox): Optional; Region of interest to sample from (``minx``, ``maxx``, ``miny``, ``maxy``,\n                ``mint``, ``maxt``). (defaults to the bounds of ``dataset.index``).\n            max_r (float): Optional; Maximum geo-spatial distance (from centre to centre)\n                to sample matching sample from.\n        \"\"\"\n        super().__init__(dataset, roi)\n        self.size = _to_tuple(size)\n        self.length = length\n        self.max_r = max_r\n        self.hits = []\n        for hit in self.index.intersection(tuple(self.roi), objects=True):\n            bounds = BoundingBox(*hit.bounds)  # type: ignore\n            if (\n                bounds.maxx - bounds.minx > self.size[1]\n                and bounds.maxy - bounds.miny > self.size[0]\n            ):\n                self.hits.append(hit)\n\n    def __iter__(self) -> Iterator[Tuple[BoundingBox, BoundingBox]]:  # type: ignore[override]\n        \"\"\"Return a pair of BoundingBox indices of a dataset that are geospatially close.\n\n        Returns:\n            Tuple[BoundingBox, BoundingBox]: Tuple of bounding boxes to index a dataset.\n        \"\"\"\n        for _ in range(len(self)):\n            # Choose a random tile.\n            hit = random.choice(self.hits)\n            bounds = BoundingBox(*hit.bounds)\n\n            bbox_a, bbox_b = get_pair_bboxes(bounds, self.size, self.res, self.max_r)\n\n            yield bbox_a, bbox_b\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of samples in a single epoch.\n\n        Returns:\n            int: Length of the epoch.\n        \"\"\"\n        return self.length\n\n\nclass RandomPairBatchGeoSampler(BatchGeoSampler):\n    \"\"\"Samples batches of pairs of elements from a region of interest randomly.\n\n    This is particularly useful during training when you want to maximize the size of\n    the dataset and return as many random :term:`patches` as possible.\n\n    An extension to :class:`RandomBatchGeoSampler` that supports paired sampling (i.e. for GeoCLR)\n    and ability to samples from multiple tiles per batch to increase variance of batch.\n    \"\"\"\n\n    def __init__(\n        self,\n        dataset: GeoDataset,\n        size: Union[Tuple[float, float], float],\n        batch_size: int,\n        length: int,\n        roi: Optional[BoundingBox] = None,\n        max_r: float = 256.0,\n        tiles_per_batch: int = 4,\n    ) -> None:\n        \"\"\"Initialize a new Sampler instance.\n\n        The ``size`` argument can either be:\n\n        * a single ``float`` - in which case the same value is used for the height and\n          width dimension\n        * a ``tuple`` of two floats - in which case, the first *float* is used for the\n          height dimension, and the second *float* for the width dimension\n\n        Args:\n            dataset (GeoDataset): Dataset to index from.\n            size (Union[Tuple[float, float], float]): Dimensions of each :term:`patch` in units of CRS.\n            batch_size (int): Number of samples per batch.\n            length (int): Number of samples per epoch.\n            roi (BoundingBox): Optional; Region of interest to sample from (``minx``, ``maxx``, ``miny``, ``maxy``,\n                ``mint``, ``maxt``). (defaults to the bounds of ``dataset.index``)\n            max_r (float): Optional; Maximum geo-spatial distance (from centre to centre)\n                to sample matching sample from.\n            tiles_per_batch (int): Optional; Number of tiles to sample from per batch.\n                Must be a multiple of ``batch_size``.\n\n        Raises:\n            ValueError: If ``tiles_per_batch`` is not a multiple of ``batch_size``.\n        \"\"\"\n        super().__init__(dataset, roi)\n        self.size = _to_tuple(size)\n        self.batch_size = batch_size\n        self.length = length\n        self.max_r = max_r\n        self.hits = list(self.index.intersection(tuple(self.roi), objects=True))\n\n        self.tiles_per_batch = tiles_per_batch\n\n        if self.batch_size % tiles_per_batch == 0:\n            self.sam_per_tile = self.batch_size // tiles_per_batch\n        else:\n            raise ValueError(f\"{tiles_per_batch=} is not a multiple of {batch_size=}\")\n\n    def __iter__(self) -> Iterator[List[Tuple[BoundingBox, BoundingBox]]]:  # type: ignore[override]\n        \"\"\"Return the indices of a dataset.\n\n        Returns:\n            batch of (minx, maxx, miny, maxy, mint, maxt) coordinates to index a dataset\n        \"\"\"\n        for _ in range(len(self)):\n            batch = []\n            for _ in range(self.tiles_per_batch):\n                # Choose a random tile\n                hit = random.choice(self.hits)\n                bounds = BoundingBox(*hit.bounds)  # type: ignore\n\n                # Choose random indices within that tile\n                for _ in range(self.sam_per_tile):\n                    bbox_a, bbox_b = get_pair_bboxes(\n                        bounds, self.size, self.res, self.max_r\n                    )\n                    batch.append((bbox_a, bbox_b))\n\n            yield batch\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of batches in a single epoch.\n\n        Returns:\n            int: Number of batches in an epoch\n        \"\"\"\n        return self.length // self.batch_size\n\n\ndef get_greater_bbox(\n    bbox: BoundingBox, r: float, size: Union[float, int, Sequence[float]]\n) -> BoundingBox:\n    \"\"\"Return a bounding box at ``max_r`` distance around the first box.\n\n    Args:\n        bbox (BoundingBox): Bounding box of the original sample.\n        r (float): Distance in pixels to extend the original bounding box by\n            to get a new greater bounds to sample from.\n        size (float | Sequence[float]): The (``x``, ``y``) size of the :term:`patch` that ``bbox``\n            represents in pixels. Will only use size[0] if a :class:`Sequence`.\n\n    Returns:\n        BoundingBox: Greater bounds around original bounding box to sample from.\n    \"\"\"\n    x: float\n    if isinstance(size, Sequence):\n        assert isinstance(size, Sequence)\n        x = float(size[0])\n    else:\n        assert isinstance(size, (float, int))\n        x = float(size)\n\n    # Calculates the geospatial distance to add to the existing bounding box to get\n    # the box to sample the other side of the pair from.\n    r_in_crs = r * abs(bbox.maxx - bbox.minx) / float(x)\n\n    return BoundingBox(\n        bbox.minx - r_in_crs,\n        bbox.maxx + r_in_crs,\n        bbox.miny - r_in_crs,\n        bbox.maxy + r_in_crs,\n        bbox.mint,\n        bbox.maxt,\n    )\n\n\ndef get_pair_bboxes(\n    bounds: BoundingBox,\n    size: Union[Tuple[float, float], float],\n    res: float,\n    max_r: float,\n) -> Tuple[BoundingBox, BoundingBox]:\n    \"\"\"Samples a pair of bounding boxes geo-spatially close to each other.\n\n    Args:\n        bounds (BoundingBox): Maximum bounds of the :term:`tile` to sample pair from.\n        size (Union[Tuple[float, float], float]): Size of each :term:`patch`.\n        res (float): Resolution to sample :term:`patch` at.\n        max_r (float): Padding around original :term:`patch` to sample new :term:`patch` from.\n\n    Returns:\n        Tuple[BoundingBox, BoundingBox]: Pair of bounding boxes to sample pair of patches from dataset.\n    \"\"\"\n    # Choose a random index within that tile.\n    bbox_a = get_random_bounding_box(bounds, size, res)\n\n    max_bounds = get_greater_bbox(bbox_a, max_r, size)\n\n    # Check that the new bbox cannot exceed the bounds of the tile.\n    max_bounds = utils.check_within_bounds(max_bounds, bounds)\n\n    # Randomly sample another box at a max distance of max_r from box_a.\n    bbox_b = get_random_bounding_box(max_bounds, size, res)\n\n    return bbox_a, bbox_b\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "402a5708f5fd1ec8b495ec45cba8ce0760aafaf160d29178f58b207480ee8ec0"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/utils/runner.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 16542,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Module to handle generic functionality for running :mod:`minerva` scripts.\n\nAttributes:\n    GENERIC_PARSER (ArgumentParser): A standard argparser with arguments for use in :mod:`minerva`.\n        Can be used as the basis for a user defined extended argparser.\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"GENERIC_PARSER\",\n    \"config_env_vars\",\n    \"config_args\",\n    \"distributed_run\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\nimport os\nimport signal\nimport subprocess\nfrom argparse import Namespace\nfrom typing import Any, Callable, Optional, Union\n\nimport requests\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nfrom wandb.sdk.lib import RunDisabled\nfrom wandb.sdk.wandb_run import Run\n\nimport wandb\nfrom minerva.utils import CONFIG, MASTER_PARSER, utils\n\n# =====================================================================================================================\n#                                                     GLOBALS\n# =====================================================================================================================\n# ---+ CLI +--------------------------------------------------------------+\nGENERIC_PARSER = argparse.ArgumentParser(parents=[MASTER_PARSER])\n\nGENERIC_PARSER.add_argument(\n    \"--seed\",\n    dest=\"seed\",\n    type=int,\n    default=42,\n    help=\"Set seed number\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--model-name\",\n    dest=\"model_name\",\n    type=str,\n    help=\"Name of model.\"\n    + \" Sub-string before hyphen is taken as model class name.\"\n    + \" Sub-string past hyphen can be used to differeniate between versions.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--model-type\",\n    dest=\"model_type\",\n    type=str,\n    help=\"Type of model. Should be 'segmentation', 'scene_classifier', 'siamese' or 'mlp'\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--pre-train\",\n    dest=\"pre_train\",\n    action=\"store_true\",\n    help=\"Sets experiment type to pre-train. Will save model to cache at end of training.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--fine-tune\",\n    dest=\"fine_tune\",\n    action=\"store_true\",\n    help=\"Sets experiment type to fine-tune. Will load pre-trained backbone from file.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--eval\",\n    dest=\"eval\",\n    action=\"store_true\",\n    help=\"Sets experiment type to pre-train. Will save model to cache at end of training.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--balance\",\n    dest=\"balance\",\n    action=\"store_true\",\n    help=\"Activates class balancing.\"\n    + \" Depending on `model_type`, this will either be via sampling or weighting of the loss function.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--class-elim\",\n    dest=\"elim\",\n    action=\"store_true\",\n    help=\"Eliminates classes that are specified in config but not present in the data.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--sample-pairs\",\n    dest=\"sample_pairs\",\n    action=\"store_true\",\n    help=\"Use paired sampling. E.g. For Siamese models.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--save-model\",\n    dest=\"save_model\",\n    type=str,\n    default=False,\n    help=\"Whether to save the model at end of testing. Must be 'true', 'false' or 'auto'.\"\n    + \" Setting 'auto' will automatically save the model to file.\"\n    + \" 'true' will ask the user whether to or not at runtime.\"\n    + \" 'false' will not save the model and will not ask the user at runtime.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--run-tensorboard\",\n    dest=\"run_tensorboard\",\n    type=str,\n    default=False,\n    help=\"Whether to run the Tensorboard logs at end of testing. Must be 'true', 'false' or 'auto'.\"\n    + \" Setting 'auto' will automatically locate and run the logs on a local browser.\"\n    + \" 'true' will ask the user whether to or not at runtime.\"\n    + \" 'false' will not save the model and will not ask the user at runtime.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--save-plots-no\",\n    dest=\"save\",\n    action=\"store_false\",\n    help=\"Plots created will not be saved to file.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--show-plots\",\n    dest=\"show\",\n    action=\"store_true\",\n    help=\"Show plots created in a window.\"\n    + \" Warning: Do not use with a terminal-less operation, e.g. SLURM.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--print-dist\",\n    dest=\"p_dist\",\n    action=\"store_true\",\n    help=\"Print the distribution of classes within the data to `stdout`.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--plot-last-epoch\",\n    dest=\"plot_last_epoch\",\n    action=\"store_true\",\n    help=\"Plot the results from the final validation epoch.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--wandb-log\",\n    dest=\"wandb_log\",\n    action=\"store_true\",\n    help=\"Activate Weights and Biases logging.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--project_name\",\n    dest=\"project\",\n    type=str,\n    help=\"Name of the Weights and Biases project this experiment belongs to.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--wandb-entity\",\n    dest=\"entity\",\n    type=str,\n    help=\"The Weights and Biases entity to send runs to.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--wandb-dir\",\n    dest=\"wandb_dir\",\n    type=str,\n    default=\"./wandb\",\n    help=\"Where to store the Weights and Biases logs locally.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--wandb-log-all\",\n    dest=\"log_all\",\n    action=\"store_true\",\n    help=\"Will log each process on Weights and Biases. Otherwise, logging will be performed from the master process.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--knn-k\",\n    dest=\"knn_k\",\n    type=int,\n    default=200,\n    help=\"Top k most similar images used to predict the image for KNN validation.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--val-freq\",\n    dest=\"val_freq\",\n    type=int,\n    default=5,\n    help=\"Frequency at which to conduct a validation epoch with KNN compared to training epochs for SSL or Siamese models.\",\n)\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass WandbConnectionManager:\n    \"\"\"Checks for a connection to :mod:`wandb`. If not, sets :mod:`wandb` to offline during context.\"\"\"\n\n    def __init__(self) -> None:\n        try:\n            requests.head(\"http://www.wandb.ai/\", timeout=0.1)\n            self._on = True\n        except requests.ConnectionError:\n            self._on = False\n\n    def __enter__(self) -> None:\n        if self._on:\n            os.environ[\"WANDB_MODE\"] = \"online\"\n        else:\n            os.environ[\"WANDB_MODE\"] = \"offline\"\n\n    def __exit__(self, exc_type, exc_value, exc_traceback) -> None:\n        os.environ[\"WANDB_MODE\"] = \"online\"\n\n\n# =====================================================================================================================\n#                                                     METHODS\n# =====================================================================================================================\ndef _handle_sigusr1(signum, frame) -> None:  # pragma: no cover\n    subprocess.Popen(  # nosec B602\n        f'scontrol requeue {os.getenv(\"SLURM_JOB_ID\")}',\n        shell=True,\n    )\n    exit()\n\n\ndef _handle_sigterm(signum, frame) -> None:  # pragma: no cover\n    pass\n\n\ndef setup_wandb_run(gpu: int, args: Namespace) -> Optional[Union[Run, RunDisabled]]:\n    \"\"\"Sets up a :mod:`wandb` logger for either every process, the master process or not if not logging.\n\n    .. note::\n        ``args`` must contain these keys:\n            * ``wandb_log`` (bool): Activate :mod:`wandb` logging.\n            * ``log_all`` (bool): :mod:`wandb` logging on every process if ``True``.\n                Only log on the master process if ``False``.\n            * ``entity`` (str): :mod:`wandb` entity where to send runs to.\n            * ``project`` (str): Name of the :mod:`wandb` project this experiment belongs to.\n            * ``world_size`` (int): Total number of processes across the experiment.\n\n    Args:\n        gpu (int): Local process (GPU) number.\n        args (Namespace): CLI arguments from :mod:`argparse`.\n\n    Returns:\n        Optional[Union[Run, RunDisabled]]: The :mod:`wandb` run object for this process\n            or ``None`` if ``log_all=False`` and ``rank!=0``.\n    \"\"\"\n    run: Optional[Union[Run, RunDisabled]] = None\n    if CONFIG.get(\"wandb_log\", False) or CONFIG.get(\"project\", None):\n        try:\n            if CONFIG.get(\"log_all\", False) and args.world_size > 1:\n                run = wandb.init(\n                    entity=CONFIG.get(\"entity\", None),\n                    project=CONFIG.get(\"project\", None),\n                    group=CONFIG.get(\"group\", \"DDP\"),\n                    dir=CONFIG.get(\"wandb_dir\", None),\n                    name=args.jobid,\n                )\n            else:\n                if gpu == 0:\n                    run = wandb.init(\n                        entity=CONFIG.get(\"entity\", None),\n                        project=CONFIG.get(\"project\", None),\n                        dir=CONFIG.get(\"wandb_dir\", None),\n                        name=args.jobid,\n                    )\n            CONFIG[\"wandb_log\"] = True\n        except wandb.UsageError:  # type: ignore[attr-defined]\n            print(\n                \"wandb API Key has not been inited.\",\n                \"\\nEither call wandb.login(key=[your_api_key]) or use `wandb login` in the shell.\",\n                \"\\nOr if not using wandb, safely ignore this message.\",\n            )\n    else:\n        print(\"Weights and Biases logging OFF\")\n\n    return run\n\n\ndef config_env_vars(args: Namespace) -> Namespace:\n    \"\"\"Finds SLURM environment variables (if they exist) and configures args accordingly.\n\n    If SLURM variables are found in the environment variables, the arguments are configured for a SLURM job:\n\n    * ``args.rank`` is set to the ``SLURM_NODEID * args.ngpus_per_node``.\n    * ``args.world_size`` is set to ``SLURM_NNODES * args.ngpus_per_node``.\n    * ``args.dist_url`` is set to ``tcp://{host_name}:58472``\n\n    If SLURM variables are not detected, the arguments are configured for a single-node job:\n\n    * ``args.rank=0``.\n    * ``args.world_size=args.ngpus_per_node``.\n    * ``args.dist_url = \"tcp://localhost:58472\"``.\n\n    Args:\n        args (Namespace): Arguments from the CLI ``parser`` from :mod:`argparse`.\n\n    Returns:\n        Namespace: Inputted arguments with the addition of ``rank``, ``dist_url`` and ``world_sized`` attributes.\n    \"\"\"\n    if \"SLURM_JOB_ID\" in os.environ:\n        # Single-node and multi-node distributed training on SLURM cluster.\n        # Requeue job on SLURM preemption.\n        signal.signal(signal.SIGUSR1, _handle_sigusr1)\n        signal.signal(signal.SIGTERM, _handle_sigterm)\n\n        # Get SLURM variables.\n        slurm_job_nodelist: Optional[str] = os.getenv(\"SLURM_JOB_NODELIST\")\n        slurm_nodeid: Optional[str] = os.getenv(\"SLURM_NODEID\")\n        slurm_nnodes: Optional[str] = os.getenv(\"SLURM_NNODES\")\n        slurm_jobid: Optional[str] = os.getenv(\"SLURM_JOB_ID\")\n\n        # Check that SLURM variables have been found.\n        assert slurm_job_nodelist is not None\n        assert slurm_nodeid is not None\n        assert slurm_nnodes is not None\n        assert slurm_jobid is not None\n\n        # Find a common host name on all nodes.\n        # Assume scontrol returns hosts in the same order on all nodes.\n        cmd = \"scontrol show hostnames \" + slurm_job_nodelist\n        stdout = subprocess.check_output(cmd.split())\n        host_name = stdout.decode().splitlines()[0]\n        args.rank = int(slurm_nodeid) * args.ngpus_per_node\n        args.world_size = int(slurm_nnodes) * args.ngpus_per_node\n        args.dist_url = f\"tcp://{host_name}:58472\"\n        args.jobid = slurm_jobid\n\n    else:\n        # Single-node distributed training.\n        args.rank = 0\n        args.dist_url = \"tcp://localhost:58472\"\n        args.world_size = args.ngpus_per_node\n        args.jobid = None\n\n    return args\n\n\ndef config_args(args: Namespace) -> Namespace:\n    \"\"\"Prepare the arguments generated from the :mod:`argparser` CLI for the job run.\n\n    * Finds and sets ``args.ngpus_per_node``;\n    * updates the ``CONFIG`` with new arguments from the CLI;\n    * sets the seeds from the seed found in ``CONFIG`` or from CLI;\n    * uses :func:`config_env_vars` to determine the correct arguments for distributed computing jobs e.g. SLURM.\n\n    Args:\n        args (Namespace): Arguments from the CLI ``parser`` from :mod:`argparse`.\n\n    Returns:\n        Namespace: Inputted arguments with the addition of ``rank``, ``dist_url`` and ``world_sized`` attributes.\n    \"\"\"\n    args.ngpus_per_node = torch.cuda.device_count()\n\n    # Convert CLI arguments to dict.\n    args_dict = vars(args)\n\n    # Find which CLI arguments are not in the config.\n    new_args = {key: args_dict[key] for key in args_dict if key not in CONFIG}\n\n    # Updates the config with new arguments from the CLI.\n    CONFIG.update(new_args)\n\n    # Get seed from config.\n    seed = CONFIG.get(\"seed\", 42)\n\n    # Set torch, numpy and inbuilt seeds for reproducibility.\n    utils.set_seeds(seed)\n\n    return config_env_vars(args)\n\n\ndef _run_preamble(\n    gpu: int, run: Callable[[int, Namespace], Any], args: Namespace\n) -> None:\n    # Calculates the global rank of this process.\n    args.rank += gpu\n\n    # Setups the `wandb` run for this process.\n    args.wandb_run = setup_wandb_run(gpu, args)\n\n    if args.world_size > 1:\n        dist.init_process_group(  # type: ignore[attr-defined]\n            backend=\"gloo\",\n            init_method=args.dist_url,\n            world_size=args.world_size,\n            rank=args.rank,\n        )\n        print(f\"INITIALISED PROCESS ON {args.rank}\")\n\n    if torch.cuda.is_available():\n        torch.cuda.set_device(gpu)\n        torch.backends.cudnn.benchmark = True  # type: ignore\n\n    # Start this this process run.\n    run(gpu, args)\n\n\ndef distributed_run(run: Callable[[int, Namespace], Any], args: Namespace) -> None:\n    \"\"\"Runs the supplied function and arguments with distributed computing according to arguments.\n\n    :func:`run_preamble` adds some additional commands to initialise the process group for each run\n    and allocating the GPU device number to use before running the supplied function.\n\n    Note:\n        ``args`` must contain the attributes ``rank``, ``world_size`` and ``dist_url``. These can be\n        configured using :func:`config_env_vars` or :func:`config_args`.\n\n    Args:\n        run (Callable[[int, Namespace], Any]): Function to run with distributed computing.\n        args (Namespace): Arguments for the run and to specify the variables for distributed computing.\n    \"\"\"\n    if args.world_size <= 1:\n        # Setups up the `wandb` run.\n        args.wandb_run = setup_wandb_run(0, args)\n\n        # Run the experiment.\n        run(0, args)\n\n    else:\n        try:\n            mp.spawn(_run_preamble, (run, args), args.ngpus_per_node)  # type: ignore[attr-defined]\n        except KeyboardInterrupt:\n            dist.destroy_process_group()  # type: ignore[attr-defined]\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 16542,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Module to handle generic functionality for running :mod:`minerva` scripts.\n\nAttributes:\n    GENERIC_PARSER (ArgumentParser): A standard argparser with arguments for use in :mod:`minerva`.\n        Can be used as the basis for a user defined extended argparser.\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"GENERIC_PARSER\",\n    \"config_env_vars\",\n    \"config_args\",\n    \"distributed_run\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\nimport os\nimport signal\nimport subprocess\nfrom argparse import Namespace\nfrom typing import Any, Callable, Optional, Union\n\nimport requests\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nfrom wandb.sdk.lib import RunDisabled\nfrom wandb.sdk.wandb_run import Run\n\nimport wandb\nfrom minerva.utils import CONFIG, MASTER_PARSER, utils\n\n# =====================================================================================================================\n#                                                     GLOBALS\n# =====================================================================================================================\n# ---+ CLI +--------------------------------------------------------------+\nGENERIC_PARSER = argparse.ArgumentParser(parents=[MASTER_PARSER])\n\nGENERIC_PARSER.add_argument(\n    \"--seed\",\n    dest=\"seed\",\n    type=int,\n    default=42,\n    help=\"Set seed number\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--model-name\",\n    dest=\"model_name\",\n    type=str,\n    help=\"Name of model.\"\n    + \" Sub-string before hyphen is taken as model class name.\"\n    + \" Sub-string past hyphen can be used to differeniate between versions.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--model-type\",\n    dest=\"model_type\",\n    type=str,\n    help=\"Type of model. Should be 'segmentation', 'scene_classifier', 'siamese' or 'mlp'\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--pre-train\",\n    dest=\"pre_train\",\n    action=\"store_true\",\n    help=\"Sets experiment type to pre-train. Will save model to cache at end of training.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--fine-tune\",\n    dest=\"fine_tune\",\n    action=\"store_true\",\n    help=\"Sets experiment type to fine-tune. Will load pre-trained backbone from file.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--eval\",\n    dest=\"eval\",\n    action=\"store_true\",\n    help=\"Sets experiment type to pre-train. Will save model to cache at end of training.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--balance\",\n    dest=\"balance\",\n    action=\"store_true\",\n    help=\"Activates class balancing.\"\n    + \" Depending on `model_type`, this will either be via sampling or weighting of the loss function.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--class-elim\",\n    dest=\"elim\",\n    action=\"store_true\",\n    help=\"Eliminates classes that are specified in config but not present in the data.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--sample-pairs\",\n    dest=\"sample_pairs\",\n    action=\"store_true\",\n    help=\"Use paired sampling. E.g. For Siamese models.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--save-model\",\n    dest=\"save_model\",\n    type=str,\n    default=False,\n    help=\"Whether to save the model at end of testing. Must be 'true', 'false' or 'auto'.\"\n    + \" Setting 'auto' will automatically save the model to file.\"\n    + \" 'true' will ask the user whether to or not at runtime.\"\n    + \" 'false' will not save the model and will not ask the user at runtime.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--run-tensorboard\",\n    dest=\"run_tensorboard\",\n    type=str,\n    default=False,\n    help=\"Whether to run the Tensorboard logs at end of testing. Must be 'true', 'false' or 'auto'.\"\n    + \" Setting 'auto' will automatically locate and run the logs on a local browser.\"\n    + \" 'true' will ask the user whether to or not at runtime.\"\n    + \" 'false' will not save the model and will not ask the user at runtime.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--save-plots-no\",\n    dest=\"save\",\n    action=\"store_false\",\n    help=\"Plots created will not be saved to file.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--show-plots\",\n    dest=\"show\",\n    action=\"store_true\",\n    help=\"Show plots created in a window.\"\n    + \" Warning: Do not use with a terminal-less operation, e.g. SLURM.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--print-dist\",\n    dest=\"p_dist\",\n    action=\"store_true\",\n    help=\"Print the distribution of classes within the data to `stdout`.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--plot-last-epoch\",\n    dest=\"plot_last_epoch\",\n    action=\"store_true\",\n    help=\"Plot the results from the final validation epoch.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--wandb-log\",\n    dest=\"wandb_log\",\n    action=\"store_true\",\n    help=\"Activate Weights and Biases logging.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--project_name\",\n    dest=\"project\",\n    type=str,\n    help=\"Name of the Weights and Biases project this experiment belongs to.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--wandb-entity\",\n    dest=\"entity\",\n    type=str,\n    help=\"The Weights and Biases entity to send runs to.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--wandb-dir\",\n    dest=\"wandb_dir\",\n    type=str,\n    default=\"./wandb\",\n    help=\"Where to store the Weights and Biases logs locally.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--wandb-log-all\",\n    dest=\"log_all\",\n    action=\"store_true\",\n    help=\"Will log each process on Weights and Biases. Otherwise, logging will be performed from the master process.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--knn-k\",\n    dest=\"knn_k\",\n    type=int,\n    default=200,\n    help=\"Top k most similar images used to predict the image for KNN validation.\",\n)\n\nGENERIC_PARSER.add_argument(\n    \"--val-freq\",\n    dest=\"val_freq\",\n    type=int,\n    default=5,\n    help=\"Frequency at which to conduct a validation epoch with KNN compared to training epochs for SSL or Siamese models.\",\n)\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass WandbConnectionManager:\n    \"\"\"Checks for a connection to :mod:`wandb`. If not, sets :mod:`wandb` to offline during context.\"\"\"\n\n    def __init__(self) -> None:\n        try:\n            requests.head(\"http://www.wandb.ai/\", timeout=0.1)\n            self._on = True\n        except requests.ConnectionError:\n            self._on = False\n\n    def __enter__(self) -> None:\n        if self._on:\n            os.environ[\"WANDB_MODE\"] = \"online\"\n        else:\n            os.environ[\"WANDB_MODE\"] = \"offline\"\n\n    def __exit__(self, exc_type, exc_value, exc_traceback) -> None:\n        os.environ[\"WANDB_MODE\"] = \"online\"\n\n\n# =====================================================================================================================\n#                                                     METHODS\n# =====================================================================================================================\ndef _handle_sigusr1(signum, frame) -> None:  # pragma: no cover\n    subprocess.Popen(  # nosec B602\n        f'scontrol requeue {os.getenv(\"SLURM_JOB_ID\")}',\n        shell=True,\n    )\n    exit()\n\n\ndef _handle_sigterm(signum, frame) -> None:  # pragma: no cover\n    pass\n\n\ndef setup_wandb_run(gpu: int, args: Namespace) -> Optional[Union[Run, RunDisabled]]:\n    \"\"\"Sets up a :mod:`wandb` logger for either every process, the master process or not if not logging.\n\n    .. note::\n        ``args`` must contain these keys:\n            * ``wandb_log`` (bool): Activate :mod:`wandb` logging.\n            * ``log_all`` (bool): :mod:`wandb` logging on every process if ``True``.\n                Only log on the master process if ``False``.\n            * ``entity`` (str): :mod:`wandb` entity where to send runs to.\n            * ``project`` (str): Name of the :mod:`wandb` project this experiment belongs to.\n            * ``world_size`` (int): Total number of processes across the experiment.\n\n    Args:\n        gpu (int): Local process (GPU) number.\n        args (Namespace): CLI arguments from :mod:`argparse`.\n\n    Returns:\n        Optional[Union[Run, RunDisabled]]: The :mod:`wandb` run object for this process\n            or ``None`` if ``log_all=False`` and ``rank!=0``.\n    \"\"\"\n    run: Optional[Union[Run, RunDisabled]] = None\n    if CONFIG.get(\"wandb_log\", False) or CONFIG.get(\"project\", None):\n        try:\n            if CONFIG.get(\"log_all\", False) and args.world_size > 1:\n                run = wandb.init(\n                    entity=CONFIG.get(\"entity\", None),\n                    project=CONFIG.get(\"project\", None),\n                    group=CONFIG.get(\"group\", \"DDP\"),\n                    dir=CONFIG.get(\"wandb_dir\", None),\n                    name=args.jobid,\n                )\n            else:\n                if gpu == 0:\n                    run = wandb.init(\n                        entity=CONFIG.get(\"entity\", None),\n                        project=CONFIG.get(\"project\", None),\n                        dir=CONFIG.get(\"wandb_dir\", None),\n                        name=args.jobid,\n                    )\n            CONFIG[\"wandb_log\"] = True\n        except wandb.UsageError:  # type: ignore[attr-defined]\n            print(\n                \"wandb API Key has not been inited.\",\n                \"\\nEither call wandb.login(key=[your_api_key]) or use `wandb login` in the shell.\",\n                \"\\nOr if not using wandb, safely ignore this message.\",\n            )\n    else:\n        print(\"Weights and Biases logging OFF\")\n\n    return run\n\n\ndef config_env_vars(args: Namespace) -> Namespace:\n    \"\"\"Finds SLURM environment variables (if they exist) and configures args accordingly.\n\n    If SLURM variables are found in the environment variables, the arguments are configured for a SLURM job:\n\n    * ``args.rank`` is set to the ``SLURM_NODEID * args.ngpus_per_node``.\n    * ``args.world_size`` is set to ``SLURM_NNODES * args.ngpus_per_node``.\n    * ``args.dist_url`` is set to ``tcp://{host_name}:58472``\n\n    If SLURM variables are not detected, the arguments are configured for a single-node job:\n\n    * ``args.rank=0``.\n    * ``args.world_size=args.ngpus_per_node``.\n    * ``args.dist_url = \"tcp://localhost:58472\"``.\n\n    Args:\n        args (Namespace): Arguments from the CLI ``parser`` from :mod:`argparse`.\n\n    Returns:\n        Namespace: Inputted arguments with the addition of ``rank``, ``dist_url`` and ``world_sized`` attributes.\n    \"\"\"\n    if \"SLURM_JOB_ID\" in os.environ:\n        # Single-node and multi-node distributed training on SLURM cluster.\n        # Requeue job on SLURM preemption.\n        signal.signal(signal.SIGUSR1, _handle_sigusr1)\n        signal.signal(signal.SIGTERM, _handle_sigterm)\n\n        # Get SLURM variables.\n        slurm_job_nodelist: Optional[str] = os.getenv(\"SLURM_JOB_NODELIST\")\n        slurm_nodeid: Optional[str] = os.getenv(\"SLURM_NODEID\")\n        slurm_nnodes: Optional[str] = os.getenv(\"SLURM_NNODES\")\n        slurm_jobid: Optional[str] = os.getenv(\"SLURM_JOB_ID\")\n\n        # Check that SLURM variables have been found.\n        assert slurm_job_nodelist is not None\n        assert slurm_nodeid is not None\n        assert slurm_nnodes is not None\n        assert slurm_jobid is not None\n\n        # Find a common host name on all nodes.\n        # Assume scontrol returns hosts in the same order on all nodes.\n        cmd = \"scontrol show hostnames \" + slurm_job_nodelist\n        stdout = subprocess.check_output(cmd.split())\n        host_name = stdout.decode().splitlines()[0]\n        args.rank = int(slurm_nodeid) * args.ngpus_per_node\n        args.world_size = int(slurm_nnodes) * args.ngpus_per_node\n        args.dist_url = f\"tcp://{host_name}:58472\"\n        args.jobid = slurm_jobid\n\n    else:\n        # Single-node distributed training.\n        args.rank = 0\n        args.dist_url = \"tcp://localhost:58472\"\n        args.world_size = args.ngpus_per_node\n        args.jobid = None\n\n    return args\n\n\ndef config_args(args: Namespace) -> Namespace:\n    \"\"\"Prepare the arguments generated from the :mod:`argparser` CLI for the job run.\n\n    * Finds and sets ``args.ngpus_per_node``;\n    * updates the ``CONFIG`` with new arguments from the CLI;\n    * sets the seeds from the seed found in ``CONFIG`` or from CLI;\n    * uses :func:`config_env_vars` to determine the correct arguments for distributed computing jobs e.g. SLURM.\n\n    Args:\n        args (Namespace): Arguments from the CLI ``parser`` from :mod:`argparse`.\n\n    Returns:\n        Namespace: Inputted arguments with the addition of ``rank``, ``dist_url`` and ``world_sized`` attributes.\n    \"\"\"\n    args.ngpus_per_node = torch.cuda.device_count()\n\n    # Convert CLI arguments to dict.\n    args_dict = vars(args)\n\n    # Find which CLI arguments are not in the config.\n    new_args = {key: args_dict[key] for key in args_dict if key not in CONFIG}\n\n    # Updates the config with new arguments from the CLI.\n    CONFIG.update(new_args)\n\n    # Get seed from config.\n    seed = CONFIG.get(\"seed\", 42)\n\n    # Set torch, numpy and inbuilt seeds for reproducibility.\n    utils.set_seeds(seed)\n\n    return config_env_vars(args)\n\n\ndef _run_preamble(\n    gpu: int, run: Callable[[int, Namespace], Any], args: Namespace\n) -> None:\n    # Calculates the global rank of this process.\n    args.rank += gpu\n\n    # Setups the `wandb` run for this process.\n    args.wandb_run = setup_wandb_run(gpu, args)\n\n    if args.world_size > 1:\n        dist.init_process_group(  # type: ignore[attr-defined]\n            backend=\"gloo\",\n            init_method=args.dist_url,\n            world_size=args.world_size,\n            rank=args.rank,\n        )\n        print(f\"INITIALISED PROCESS ON {args.rank}\")\n\n    if torch.cuda.is_available():\n        torch.cuda.set_device(gpu)\n        torch.backends.cudnn.benchmark = True  # type: ignore\n\n    # Start this this process run.\n    run(gpu, args)\n\n\ndef distributed_run(run: Callable[[int, Namespace], Any], args: Namespace) -> None:\n    \"\"\"Runs the supplied function and arguments with distributed computing according to arguments.\n\n    :func:`run_preamble` adds some additional commands to initialise the process group for each run\n    and allocating the GPU device number to use before running the supplied function.\n\n    Note:\n        ``args`` must contain the attributes ``rank``, ``world_size`` and ``dist_url``. These can be\n        configured using :func:`config_env_vars` or :func:`config_args`.\n\n    Args:\n        run (Callable[[int, Namespace], Any]): Function to run with distributed computing.\n        args (Namespace): Arguments for the run and to specify the variables for distributed computing.\n    \"\"\"\n    if args.world_size <= 1:\n        # Setups up the `wandb` run.\n        args.wandb_run = setup_wandb_run(0, args)\n\n        # Run the experiment.\n        run(0, args)\n\n    else:\n        try:\n            mp.spawn(_run_preamble, (run, args), args.ngpus_per_node)  # type: ignore[attr-defined]\n        except KeyboardInterrupt:\n            dist.destroy_process_group()  # type: ignore[attr-defined]\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "1bafe06710fb33f161ae45500dc2f29729d5302505aac2f9e4b422be08bcddd7"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/transforms.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 8802,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Module containing custom transforms to be used with :mod:`torchvision.transforms`.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"ClassTransform\",\n    \"PairCreate\",\n    \"Normalise\",\n    \"DetachedColorJitter\",\n    \"MinervaCompose\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nfrom typing import Any, Callable, Dict, Optional, Sequence, Tuple, Union, overload\n\nimport torch\nfrom torch import LongTensor, Tensor\nfrom torchvision.transforms import ColorJitter\nfrom torchvision.transforms import functional_tensor as ft\n\nfrom minerva.utils.utils import mask_transform\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass ClassTransform:\n    \"\"\"Transform to be applied to a mask to convert from one labelling schema to another.\n\n    Attributes:\n        transform (Dict[int, int]): Mapping from one labelling schema to another.\n\n    Args:\n        transform (Dict[int, int]): Mapping from one labelling schema to another.\n    \"\"\"\n\n    def __init__(self, transform: Dict[int, int]) -> None:\n        self.transform = transform\n\n    def __call__(self, mask: LongTensor) -> LongTensor:\n        \"\"\"Transforms the given mask from the original label schema to the new.\n\n        Args:\n            mask (LongTensor): Mask in the original label schema.\n\n        Returns:\n            LongTensor: Mask transformed into new label schema.\n        \"\"\"\n        transformed: LongTensor = mask_transform(mask, self.transform)\n        return transformed\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}(transform={self.transform})\"\n\n\nclass PairCreate:\n    \"\"\"Transform that takes a sample and returns a pair of the same sample.\"\"\"\n\n    def __init__(self) -> None:\n        pass\n\n    def __call__(self, sample: Any) -> Tuple[Any, Any]:\n        \"\"\"Takes a sample and returns it and a copy as a tuple pair.\n\n        Args:\n            sample (Any): Sample to duplicate.\n\n        Returns:\n            Tuple[Any, Any]: Tuple of two copies of the sample.\n        \"\"\"\n        return sample, sample\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}()\"\n\n\nclass Normalise:\n    \"\"\"Transform that normalises an image tensor based on the bit size.\n\n    Attributes:\n        norm_value (int): Value to normalise image with.\n\n    Args:\n        norm_value (int): Value to normalise image with.\n    \"\"\"\n\n    def __init__(self, norm_value: int) -> None:\n        self.norm_value = norm_value\n\n    def __call__(self, img: Tensor) -> Tensor:\n        \"\"\"Normalises inputted image using ``norm_value``.\n\n        Args:\n            img (Tensor): Image tensor to be normalised. Should have a bit size that relates to ``norm_value``.\n\n        Returns:\n            Tensor: Input image tensor normalised by ``norm_value``.\n        \"\"\"\n        return img / self.norm_value\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}(norm_value={self.norm_value})\"\n\n\nclass DetachedColorJitter(ColorJitter):\n    \"\"\"Sends RGB channels of multi-spectral images to be transformed by :class:`ColorJitter`.\"\"\"\n\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n\n    def forward(self, img: Tensor) -> Tensor:\n        \"\"\"Detaches RGB channels of input image to be sent to :class:`ColorJitter`.\n\n        All other channels bypass :class:`ColorJitter` and are concatenated onto the colour jittered RGB channels.\n\n        Args:\n            img (Tensor): Input image.\n\n        Raises:\n            ValueError: If number of channels of input ``img`` is 2.\n\n        Returns:\n            Tensor: Color jittered image.\n        \"\"\"\n        channels = ft.get_image_num_channels(img)\n\n        jitter_img: Tensor\n        if channels > 3:\n            rgb_jitter = super().forward(img[:3])\n            jitter_img = torch.cat((rgb_jitter, img[3:]), 0)  # type: ignore[attr-defined]\n\n        elif channels in (1, 3):\n            jitter_img = super().forward(img)\n\n        else:\n            raise ValueError(f\"{channels} channel images are not supported!\")\n\n        return jitter_img\n\n    def __call__(self, img: Tensor) -> Tensor:\n        return self.forward(img)\n\n    def __repr__(self) -> Any:\n        return super().__repr__()\n\n\nclass MinervaCompose:\n    \"\"\"Extension of :class:`Compose`. Composes several transforms together. This transform does not support torchscript.\n    Please, see the note below.\n\n    Args:\n        transforms (list of ``Transform`` objects): list of transforms to compose.\n\n    Example:\n        >>> transforms.Compose([\n        >>>     transforms.CenterCrop(10),\n        >>>     transforms.PILToTensor(),\n        >>>     transforms.ConvertImageDtype(torch.float),\n        >>> ])\n\n    .. note::\n        In order to script the transformations, please use ``torch.nn.Sequential`` as below.\n\n        >>> transforms = torch.nn.Sequential(\n        >>>     transforms.CenterCrop(10),\n        >>>     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        >>> )\n        >>> scripted_transforms = torch.jit.script(transforms)\n\n        Make sure to use only scriptable transformations, i.e. that work with ``torch.Tensor``, does not require\n        `lambda` functions or ``PIL.Image``.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        transforms: Union[Sequence[Callable[..., Any]], Callable[..., Any]],\n        key: Optional[str] = None,\n    ) -> None:\n        self.transforms = transforms\n        self.key = key\n\n    @overload\n    def __call__(self, sample: Tensor) -> Tensor:\n        ...  # pragma: no cover\n\n    @overload\n    def __call__(self, sample: Dict[str, Any]) -> Dict[str, Any]:\n        ...  # pragma: no cover\n\n    def __call__(\n        self, sample: Union[Tensor, Dict[str, Any]]\n    ) -> Union[Tensor, Dict[str, Any]]:\n        if isinstance(sample, Tensor):\n            return self._transform_input(sample)\n        elif isinstance(sample, dict):\n            assert self.key is not None\n            sample[self.key] = self._transform_input(sample[self.key])\n            return sample\n        else:\n            raise TypeError(f\"Sample is {type(sample)=}, not Tensor or dict!\")\n\n    def _transform_input(self, img: Tensor) -> Tensor:\n        if isinstance(self.transforms, Sequence):\n            for t in self.transforms:\n                img = t(img)\n        elif callable(self.transforms):\n            img = self.transforms(img)\n\n        else:\n            raise TypeError(\n                f\"`transforms` has type {type(self.transforms)}, not callable\"\n            )\n\n        return img\n\n    def __repr__(self) -> str:\n        format_string = self.__class__.__name__ + \"(\"\n\n        if isinstance(self.transforms, Sequence):\n            for t in self.transforms:\n                format_string += \"\\n\"\n                format_string += \"    {0}\".format(t)\n\n        elif callable(self.transforms):\n            format_string += \"{0})\".format(self.transforms)\n            return format_string\n\n        else:\n            raise TypeError(\n                f\"`transforms` has type {type(self.transforms)}, not callable\"\n            )\n\n        format_string += \"\\n)\"\n\n        return format_string\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 8802,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Module containing custom transforms to be used with :mod:`torchvision.transforms`.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"ClassTransform\",\n    \"PairCreate\",\n    \"Normalise\",\n    \"DetachedColorJitter\",\n    \"MinervaCompose\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nfrom typing import Any, Callable, Dict, Optional, Sequence, Tuple, Union, overload\n\nimport torch\nfrom torch import LongTensor, Tensor\nfrom torchvision.transforms import ColorJitter\nfrom torchvision.transforms import functional_tensor as ft\n\nfrom minerva.utils.utils import mask_transform\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass ClassTransform:\n    \"\"\"Transform to be applied to a mask to convert from one labelling schema to another.\n\n    Attributes:\n        transform (Dict[int, int]): Mapping from one labelling schema to another.\n\n    Args:\n        transform (Dict[int, int]): Mapping from one labelling schema to another.\n    \"\"\"\n\n    def __init__(self, transform: Dict[int, int]) -> None:\n        self.transform = transform\n\n    def __call__(self, mask: LongTensor) -> LongTensor:\n        \"\"\"Transforms the given mask from the original label schema to the new.\n\n        Args:\n            mask (LongTensor): Mask in the original label schema.\n\n        Returns:\n            LongTensor: Mask transformed into new label schema.\n        \"\"\"\n        transformed: LongTensor = mask_transform(mask, self.transform)\n        return transformed\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}(transform={self.transform})\"\n\n\nclass PairCreate:\n    \"\"\"Transform that takes a sample and returns a pair of the same sample.\"\"\"\n\n    def __init__(self) -> None:\n        pass\n\n    def __call__(self, sample: Any) -> Tuple[Any, Any]:\n        \"\"\"Takes a sample and returns it and a copy as a tuple pair.\n\n        Args:\n            sample (Any): Sample to duplicate.\n\n        Returns:\n            Tuple[Any, Any]: Tuple of two copies of the sample.\n        \"\"\"\n        return sample, sample\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}()\"\n\n\nclass Normalise:\n    \"\"\"Transform that normalises an image tensor based on the bit size.\n\n    Attributes:\n        norm_value (int): Value to normalise image with.\n\n    Args:\n        norm_value (int): Value to normalise image with.\n    \"\"\"\n\n    def __init__(self, norm_value: int) -> None:\n        self.norm_value = norm_value\n\n    def __call__(self, img: Tensor) -> Tensor:\n        \"\"\"Normalises inputted image using ``norm_value``.\n\n        Args:\n            img (Tensor): Image tensor to be normalised. Should have a bit size that relates to ``norm_value``.\n\n        Returns:\n            Tensor: Input image tensor normalised by ``norm_value``.\n        \"\"\"\n        return img / self.norm_value\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}(norm_value={self.norm_value})\"\n\n\nclass DetachedColorJitter(ColorJitter):\n    \"\"\"Sends RGB channels of multi-spectral images to be transformed by :class:`ColorJitter`.\"\"\"\n\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n\n    def forward(self, img: Tensor) -> Tensor:\n        \"\"\"Detaches RGB channels of input image to be sent to :class:`ColorJitter`.\n\n        All other channels bypass :class:`ColorJitter` and are concatenated onto the colour jittered RGB channels.\n\n        Args:\n            img (Tensor): Input image.\n\n        Raises:\n            ValueError: If number of channels of input ``img`` is 2.\n\n        Returns:\n            Tensor: Color jittered image.\n        \"\"\"\n        channels = ft.get_image_num_channels(img)\n\n        jitter_img: Tensor\n        if channels > 3:\n            rgb_jitter = super().forward(img[:3])\n            jitter_img = torch.cat((rgb_jitter, img[3:]), 0)  # type: ignore[attr-defined]\n\n        elif channels in (1, 3):\n            jitter_img = super().forward(img)\n\n        else:\n            raise ValueError(f\"{channels} channel images are not supported!\")\n\n        return jitter_img\n\n    def __call__(self, img: Tensor) -> Tensor:\n        return self.forward(img)\n\n    def __repr__(self) -> Any:\n        return super().__repr__()\n\n\nclass MinervaCompose:\n    \"\"\"Extension of :class:`Compose`. Composes several transforms together. This transform does not support torchscript.\n    Please, see the note below.\n\n    Args:\n        transforms (list of ``Transform`` objects): list of transforms to compose.\n\n    Example:\n        >>> transforms.Compose([\n        >>>     transforms.CenterCrop(10),\n        >>>     transforms.PILToTensor(),\n        >>>     transforms.ConvertImageDtype(torch.float),\n        >>> ])\n\n    .. note::\n        In order to script the transformations, please use ``torch.nn.Sequential`` as below.\n\n        >>> transforms = torch.nn.Sequential(\n        >>>     transforms.CenterCrop(10),\n        >>>     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        >>> )\n        >>> scripted_transforms = torch.jit.script(transforms)\n\n        Make sure to use only scriptable transformations, i.e. that work with ``torch.Tensor``, does not require\n        `lambda` functions or ``PIL.Image``.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        transforms: Union[Sequence[Callable[..., Any]], Callable[..., Any]],\n        key: Optional[str] = None,\n    ) -> None:\n        self.transforms = transforms\n        self.key = key\n\n    @overload\n    def __call__(self, sample: Tensor) -> Tensor:\n        ...  # pragma: no cover\n\n    @overload\n    def __call__(self, sample: Dict[str, Any]) -> Dict[str, Any]:\n        ...  # pragma: no cover\n\n    def __call__(\n        self, sample: Union[Tensor, Dict[str, Any]]\n    ) -> Union[Tensor, Dict[str, Any]]:\n        if isinstance(sample, Tensor):\n            return self._transform_input(sample)\n        elif isinstance(sample, dict):\n            assert self.key is not None\n            sample[self.key] = self._transform_input(sample[self.key])\n            return sample\n        else:\n            raise TypeError(f\"Sample is {type(sample)=}, not Tensor or dict!\")\n\n    def _transform_input(self, img: Tensor) -> Tensor:\n        if isinstance(self.transforms, Sequence):\n            for t in self.transforms:\n                img = t(img)\n        elif callable(self.transforms):\n            img = self.transforms(img)\n\n        else:\n            raise TypeError(\n                f\"`transforms` has type {type(self.transforms)}, not callable\"\n            )\n\n        return img\n\n    def __repr__(self) -> str:\n        format_string = self.__class__.__name__ + \"(\"\n\n        if isinstance(self.transforms, Sequence):\n            for t in self.transforms:\n                format_string += \"\\n\"\n                format_string += \"    {0}\".format(t)\n\n        elif callable(self.transforms):\n            format_string += \"{0})\".format(self.transforms)\n            return format_string\n\n        else:\n            raise TypeError(\n                f\"`transforms` has type {type(self.transforms)}, not callable\"\n            )\n\n        format_string += \"\\n)\"\n\n        return format_string\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "09a52789b1927b0933de4745a21d218b2a3582509f18cc7434f06e6652e1d10d"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/utils/config_load.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 8071,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Handles the loading of config files and checking paths.\n\nAttributes:\n    DEFAULT_CONF_DIR_PATH (Path): Path to the default config directory.\n    DEFAULT_CONFIG_NAME (str): Name of the default, example config.\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"DEFAULT_CONF_DIR_PATH\",\n    \"DEFAULT_CONFIG_NAME\",\n    \"ToDefaultConfDir\",\n    \"universal_path\",\n    \"check_paths\",\n    \"chdir_to_default\",\n    \"load_configs\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport os\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional, Tuple, Union\n\nimport yaml\n\n# =====================================================================================================================\n#                                                     GLOBALS\n# =====================================================================================================================\n# Default values for the path to the config directory and config name.\nDEFAULT_CONF_DIR_PATH = Path(\"../../inbuilt_cfgs/\")\nDEFAULT_CONFIG_NAME: str = \"example_config.yml\"\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass ToDefaultConfDir:\n    \"\"\"Changes to the default config directory. Switches back to the previous CWD on close.\"\"\"\n\n    def __init__(self) -> None:\n        self._cwd = os.getcwd()\n        self._def_dir = (Path(__file__).parent / DEFAULT_CONF_DIR_PATH).resolve()\n\n    def __enter__(self) -> None:\n        os.chdir(self._def_dir)\n\n    def __exit__(self, exc_type, exc_value, exc_traceback) -> None:\n        os.chdir(self._cwd)\n\n\n# =====================================================================================================================\n#                                                     METHODS\n# =====================================================================================================================\ndef universal_path(path: Any) -> Path:\n    \"\"\"Creates a :class:`Path` object from ``str`` or ``Iterable`` inputs.\n\n    Args:\n        path (Any): Representation of a path to convert to :class:`Path` object.\n\n    Returns:\n        Path: :class:`Path` object of the input ``path``.\n    \"\"\"\n    if isinstance(path, Path):\n        return path\n    elif type(path) == str:\n        return Path(path)\n    else:\n        return Path(*path)\n\n\ndef check_paths(\n    config: Optional[Union[str, Path]] = None, use_default_conf_dir: bool = False\n) -> Tuple[str, Optional[str], Optional[Path]]:\n    \"\"\"Checks the path given for the config.\n\n    Args:\n        config (Optional[Union[str, PathLike[str]]]): Path to the config given from the CLI.\n        use_default_conf_dir (bool): Assumes that ``config`` is in the default config directory if ``True``.\n\n    Returns:\n        Tuple[str, Optional[str], Optional[Path]]: Tuple of the path for :func:`load_configs` to use,\n        the config name and path to config.\n    \"\"\"\n\n    config_name: Optional[str] = None\n    config_path: Optional[Path] = None\n\n    if config is not None:\n        p = Path(config)\n        head = p.parent\n        tail = p.name\n\n        if str(head) != \"\" or str(head) is not None:\n            config_path = head\n        elif str(head) == \"\" or head is None:\n            config_path = Path(\"\")\n\n        config_name = tail\n\n    # Overwrites the config path if option found in args regardless of -c args.\n    if use_default_conf_dir:\n        if config_path is not None:\n            print(\n                \"Warning: Config path specified with `--default_config_dir` option.\"\n                + \"\\nDefault config directory path will be used.\"\n            )\n        config_path = None\n\n    # If no config_path, change directory to the default config directory.\n    if config_path is None:\n        config_name = chdir_to_default(config_name)\n\n    # Check the config specified exists at the path given. If not, assume its in the default directory.\n    else:\n        if config_name is None or not (config_path / config_name).exists():\n            config_name = chdir_to_default(config_name)\n        else:\n            pass\n\n    path = config_name\n    if config_path is not None and config_path != Path(\"\"):\n        path = str(config_path / config_name)\n\n    return path, config_name, config_path\n\n\ndef chdir_to_default(config_name: Optional[str] = None) -> str:\n    \"\"\"Changes the current working directory to the default config directory.\n\n    Args:\n        config_name (Optional[str]): Optional; Name of the config in the default directory. Defaults to None.\n\n    Returns:\n        str: ``DEFAULT_CONFIG_NAME`` if ``config_name`` not in default directory. ``config_name`` if it does exist.\n    \"\"\"\n\n    this_abs_path = (Path(__file__).parent / DEFAULT_CONF_DIR_PATH).resolve()\n    os.chdir(this_abs_path)\n\n    if config_name is None or not Path(config_name).exists():\n        return DEFAULT_CONFIG_NAME\n    else:\n        return config_name\n\n\ndef load_configs(master_config_path: Union[str, Path]) -> Tuple[Dict[str, Any], ...]:\n    \"\"\"Loads the master config from YAML. Finds other config paths within and loads them.\n\n    Args:\n        master_config_path (str): Path to the master config YAML file.\n\n    Returns:\n        Master config and any other configs found from paths in the master config.\n    \"\"\"\n\n    def yaml_load(path: Union[str, Path]) -> Any:\n        \"\"\"Loads YAML file from path as dict.\n        Args:\n            path(str): Path to YAML file.\n\n        Returns:\n            yml_file (dict): YAML file loaded as dict.\n        \"\"\"\n        with open(path) as f:\n            return yaml.safe_load(f)\n\n    def aux_config_load(paths: Dict[str, str]) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Loads and returns config files from YAML as dicts.\n\n        Args:\n            paths (dict): Dictionary mapping config names to paths to their YAML files.\n\n        Returns:\n            Config dictionaries loaded from YAML from paths.\n        \"\"\"\n        configs = {}\n        for _config_name in paths.keys():\n            # Loads config from YAML as dict.\n            configs[_config_name] = yaml_load(paths[_config_name])\n        return configs\n\n    # First loads the master config.\n    master_config = yaml_load(master_config_path)\n\n    # Gets the paths for the other configs from master config.\n    config_paths = master_config[\"dir\"][\"configs\"]\n\n    # Loads and returns the other configs along with master config.\n    return master_config, aux_config_load(config_paths)\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 8071,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Handles the loading of config files and checking paths.\n\nAttributes:\n    DEFAULT_CONF_DIR_PATH (Path): Path to the default config directory.\n    DEFAULT_CONFIG_NAME (str): Name of the default, example config.\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"DEFAULT_CONF_DIR_PATH\",\n    \"DEFAULT_CONFIG_NAME\",\n    \"ToDefaultConfDir\",\n    \"universal_path\",\n    \"check_paths\",\n    \"chdir_to_default\",\n    \"load_configs\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport os\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional, Tuple, Union\n\nimport yaml\n\n# =====================================================================================================================\n#                                                     GLOBALS\n# =====================================================================================================================\n# Default values for the path to the config directory and config name.\nDEFAULT_CONF_DIR_PATH = Path(\"../../inbuilt_cfgs/\")\nDEFAULT_CONFIG_NAME: str = \"example_config.yml\"\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass ToDefaultConfDir:\n    \"\"\"Changes to the default config directory. Switches back to the previous CWD on close.\"\"\"\n\n    def __init__(self) -> None:\n        self._cwd = os.getcwd()\n        self._def_dir = (Path(__file__).parent / DEFAULT_CONF_DIR_PATH).resolve()\n\n    def __enter__(self) -> None:\n        os.chdir(self._def_dir)\n\n    def __exit__(self, exc_type, exc_value, exc_traceback) -> None:\n        os.chdir(self._cwd)\n\n\n# =====================================================================================================================\n#                                                     METHODS\n# =====================================================================================================================\ndef universal_path(path: Any) -> Path:\n    \"\"\"Creates a :class:`Path` object from ``str`` or ``Iterable`` inputs.\n\n    Args:\n        path (Any): Representation of a path to convert to :class:`Path` object.\n\n    Returns:\n        Path: :class:`Path` object of the input ``path``.\n    \"\"\"\n    if isinstance(path, Path):\n        return path\n    elif type(path) == str:\n        return Path(path)\n    else:\n        return Path(*path)\n\n\ndef check_paths(\n    config: Optional[Union[str, Path]] = None, use_default_conf_dir: bool = False\n) -> Tuple[str, Optional[str], Optional[Path]]:\n    \"\"\"Checks the path given for the config.\n\n    Args:\n        config (Optional[Union[str, PathLike[str]]]): Path to the config given from the CLI.\n        use_default_conf_dir (bool): Assumes that ``config`` is in the default config directory if ``True``.\n\n    Returns:\n        Tuple[str, Optional[str], Optional[Path]]: Tuple of the path for :func:`load_configs` to use,\n        the config name and path to config.\n    \"\"\"\n\n    config_name: Optional[str] = None\n    config_path: Optional[Path] = None\n\n    if config is not None:\n        p = Path(config)\n        head = p.parent\n        tail = p.name\n\n        if str(head) != \"\" or str(head) is not None:\n            config_path = head\n        elif str(head) == \"\" or head is None:\n            config_path = Path(\"\")\n\n        config_name = tail\n\n    # Overwrites the config path if option found in args regardless of -c args.\n    if use_default_conf_dir:\n        if config_path is not None:\n            print(\n                \"Warning: Config path specified with `--default_config_dir` option.\"\n                + \"\\nDefault config directory path will be used.\"\n            )\n        config_path = None\n\n    # If no config_path, change directory to the default config directory.\n    if config_path is None:\n        config_name = chdir_to_default(config_name)\n\n    # Check the config specified exists at the path given. If not, assume its in the default directory.\n    else:\n        if config_name is None or not (config_path / config_name).exists():\n            config_name = chdir_to_default(config_name)\n        else:\n            pass\n\n    path = config_name\n    if config_path is not None and config_path != Path(\"\"):\n        path = str(config_path / config_name)\n\n    return path, config_name, config_path\n\n\ndef chdir_to_default(config_name: Optional[str] = None) -> str:\n    \"\"\"Changes the current working directory to the default config directory.\n\n    Args:\n        config_name (Optional[str]): Optional; Name of the config in the default directory. Defaults to None.\n\n    Returns:\n        str: ``DEFAULT_CONFIG_NAME`` if ``config_name`` not in default directory. ``config_name`` if it does exist.\n    \"\"\"\n\n    this_abs_path = (Path(__file__).parent / DEFAULT_CONF_DIR_PATH).resolve()\n    os.chdir(this_abs_path)\n\n    if config_name is None or not Path(config_name).exists():\n        return DEFAULT_CONFIG_NAME\n    else:\n        return config_name\n\n\ndef load_configs(master_config_path: Union[str, Path]) -> Tuple[Dict[str, Any], ...]:\n    \"\"\"Loads the master config from YAML. Finds other config paths within and loads them.\n\n    Args:\n        master_config_path (str): Path to the master config YAML file.\n\n    Returns:\n        Master config and any other configs found from paths in the master config.\n    \"\"\"\n\n    def yaml_load(path: Union[str, Path]) -> Any:\n        \"\"\"Loads YAML file from path as dict.\n        Args:\n            path(str): Path to YAML file.\n\n        Returns:\n            yml_file (dict): YAML file loaded as dict.\n        \"\"\"\n        with open(path) as f:\n            return yaml.safe_load(f)\n\n    def aux_config_load(paths: Dict[str, str]) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Loads and returns config files from YAML as dicts.\n\n        Args:\n            paths (dict): Dictionary mapping config names to paths to their YAML files.\n\n        Returns:\n            Config dictionaries loaded from YAML from paths.\n        \"\"\"\n        configs = {}\n        for _config_name in paths.keys():\n            # Loads config from YAML as dict.\n            configs[_config_name] = yaml_load(paths[_config_name])\n        return configs\n\n    # First loads the master config.\n    master_config = yaml_load(master_config_path)\n\n    # Gets the paths for the other configs from master config.\n    config_paths = master_config[\"dir\"][\"configs\"]\n\n    # Loads and returns the other configs along with master config.\n    return master_config, aux_config_load(config_paths)\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "36e0b36e29adc175a94a83c2d7a17471cc143629d102fe831154fd5553ebfb76"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/datasets.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 30588,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Functionality and custom code for constructing datasets, samplers and :class:`DataLoaders` for :mod:`minerva`.\n\nAttributes:\n    IMAGERY_CONFIG (Dict[str, Any]): Config defining the properties of the imagery used in the experiment.\n    CACHE_DIR (Path): Path to the cache directory used to store dataset manifests, cached model weights etc.\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"PairedDataset\",\n    \"construct_dataloader\",\n    \"get_collator\",\n    \"get_manifest\",\n    \"get_transform\",\n    \"load_all_samples\",\n    \"make_bounding_box\",\n    \"make_dataset\",\n    \"make_loaders\",\n    \"make_manifest\",\n    \"make_transformations\",\n    \"stack_sample_pairs\",\n    \"intersect_datasets\",\n    \"get_manifest_path\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport inspect\nimport os\nfrom pathlib import Path\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Literal,\n    Optional,\n    Sequence,\n    Tuple,\n    Union,\n)\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.distributed as dist\nfrom alive_progress import alive_it\nfrom catalyst.data.sampler import DistributedSamplerWrapper\nfrom nptyping import NDArray\nfrom pandas import DataFrame\nfrom torch.utils.data import DataLoader\nfrom torchgeo.datasets import (\n    GeoDataset,\n    IntersectionDataset,\n    RasterDataset,\n    UnionDataset,\n)\nfrom torchgeo.datasets.utils import BoundingBox, concat_samples, stack_samples\nfrom torchgeo.samplers import BatchGeoSampler, GeoSampler\nfrom torchvision.transforms import RandomApply\n\nfrom minerva.transforms import MinervaCompose\nfrom minerva.utils import AUX_CONFIGS, CONFIG, universal_path, utils\n\n# =====================================================================================================================\n#                                                     GLOBALS\n# =====================================================================================================================\nIMAGERY_CONFIG: Dict[str, Any] = AUX_CONFIGS[\"imagery_config\"]\n\n# Path to cache directory.\nCACHE_DIR: Path = universal_path(CONFIG[\"dir\"][\"cache\"])\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass TstImgDataset(RasterDataset):\n    \"\"\"Test dataset for imagery.\n\n    Attributes:\n        filename_glob (str): Pattern for image tiff files within dataset root to construct dataset from.\n    \"\"\"\n\n    filename_glob = \"*_img.tif\"\n\n\nclass TstMaskDataset(RasterDataset):\n    \"\"\"Test dataset for land cover data.\n\n    Attributes:\n        filename_glob (str): Pattern for mask tiff files within dataset root to construct dataset from.\n        is_image (bool): Sets flag to false to mark this as not a imagery dataset.\n    \"\"\"\n\n    filename_glob = \"*_lc.tif\"\n    is_image = False\n\n\nclass PairedDataset(RasterDataset):\n    \"\"\"Custom dataset to act as a wrapper to other datasets to handle paired sampling.\n\n    Attributes:\n        dataset (RasterDataset): Wrapped dataset to sampled from.\n\n    Args:\n        dataset_cls (Callable[..., GeoDataset]): Constructor for a :class:`RasterDataset`\n            to be wrapped for paired sampling.\n    \"\"\"\n\n    def __init__(\n        self,\n        dataset_cls: Callable[..., GeoDataset],\n        *args,\n        **kwargs,\n    ) -> None:\n        super_sig = inspect.signature(RasterDataset.__init__).parameters.values()\n        super_kwargs = {\n            key.name: kwargs[key.name] for key in super_sig if key.name in kwargs\n        }\n\n        super().__init__(*args, **super_kwargs)\n        self.dataset = dataset_cls(*args, **kwargs)\n\n    def __getitem__(  # type: ignore[override]\n        self, queries: Tuple[BoundingBox, BoundingBox]\n    ) -> Tuple[Dict[str, Any], ...]:\n        return self.dataset.__getitem__(queries[0]), self.dataset.__getitem__(\n            queries[1]\n        )\n\n    def __getattr__(self, item):\n        if item in self.dataset.__dict__:\n            return getattr(self.dataset, item)  # pragma: no cover\n        elif item in self.__dict__:\n            return getattr(self, item)\n        else:\n            raise AttributeError\n\n    def __repr__(self) -> Any:\n        return self.dataset.__repr__()\n\n\n# =====================================================================================================================\n#                                                     METHODS\n# =====================================================================================================================\ndef get_collator(\n    collator_params: Optional[Dict[str, str]] = None\n) -> Callable[..., Any]:\n    \"\"\"Gets the function defined in parameters to collate samples together to form a batch.\n\n    Args:\n        collator_params (Dict[str, str]): Optional; Dictionary that must contain keys for\n            'module' and 'name' of the collation function. Defaults to config['collator'].\n\n    Returns:\n        Callable[..., Any]: Collation function found from parameters given.\n    \"\"\"\n    collator: Callable[..., Any]\n    if collator_params is not None:\n        module = collator_params.pop(\"module\", \"\")\n        if module == \"\":\n            collator = globals()[collator_params[\"name\"]]\n        else:\n            collator = utils.func_by_str(module, collator_params[\"name\"])\n    else:\n        collator = stack_samples\n\n    assert callable(collator)\n    return collator\n\n\ndef stack_sample_pairs(\n    samples: Iterable[Tuple[Dict[Any, Any], Dict[Any, Any]]]\n) -> Tuple[Dict[Any, Any], Dict[Any, Any]]:\n    \"\"\"Takes a list of paired sample dicts and stacks them into a tuple of batches of sample dicts.\n\n    Args:\n        samples (Iterable[Tuple[Dict[Any, Any]]]): List of paired sample dicts to be stacked.\n\n    Returns:\n        Tuple[Dict[Any, Any], Dict[Any, Any]]: Tuple of batches within dicts.\n    \"\"\"\n    a, b = tuple(zip(*samples))\n    return stack_samples(a), stack_samples(b)\n\n\ndef intersect_datasets(\n    datasets: Sequence[GeoDataset], sample_pairs: bool = False\n) -> IntersectionDataset:\n    \"\"\"Intersects a list of :class:`GeoDataset` together to return a single dataset object.\n\n    Args:\n        datasets (List[GeoDataset]): List of datasets to intersect together. Should have some geospatial overlap.\n        sample_pairs (bool): Optional; True if paired sampling. This will wrap the collation function\n            for paired samples.\n\n    Returns:\n        IntersectionDataset: Final dataset object representing an intersection of all the parsed datasets.\n    \"\"\"\n\n    def intersect_pair_datasets(a: GeoDataset, b: GeoDataset) -> IntersectionDataset:\n        if sample_pairs:\n            return IntersectionDataset(\n                a, b, collate_fn=utils.pair_collate(concat_samples)\n            )\n        else:\n            return a & b\n\n    master_dataset: Union[GeoDataset, IntersectionDataset] = datasets[0]\n\n    for i in range(len(datasets) - 1):\n        master_dataset = intersect_pair_datasets(master_dataset, datasets[i + 1])\n\n    assert isinstance(master_dataset, IntersectionDataset)\n    return master_dataset\n\n\ndef unionise_datasets(\n    datasets: Sequence[GeoDataset], sample_pairs: bool = False\n) -> UnionDataset:\n    \"\"\"Unionises a list of :class:`GeoDataset` together to return a single dataset object.\n\n    Args:\n        datasets (List[GeoDataset]): List of datasets to unionise together.\n        sample_pairs (bool): Optional; True if paired sampling.\n            This will wrap the collation function for paired samples.\n\n    Returns:\n        UnionDataset: Final dataset object representing an union of all the parsed datasets.\n    \"\"\"\n\n    def unionise_pair_datasets(a: GeoDataset, b: GeoDataset) -> UnionDataset:\n        if sample_pairs:\n            return UnionDataset(a, b, collate_fn=utils.pair_collate(concat_samples))\n        else:\n            return a | b\n\n    master_dataset: Union[GeoDataset, UnionDataset] = datasets[0]\n\n    for i in range(len(datasets) - 1):\n        master_dataset = unionise_pair_datasets(master_dataset, datasets[i + 1])\n\n    assert isinstance(master_dataset, UnionDataset)\n    return master_dataset\n\n\ndef make_dataset(\n    data_directory: Union[Iterable[str], str, Path],\n    dataset_params: Dict[Any, Any],\n    transform_params: Optional[Dict[Any, Any]] = None,\n    sample_pairs: bool = False,\n) -> Tuple[Any, List[Any]]:\n    \"\"\"Constructs a dataset object from ``n`` sub-datasets given by the parameters supplied.\n\n    Args:\n        data_directory (Union[Iterable[str], str, Path]): List defining the path to the directory containing the data.\n        dataset_params (dict): Dictionary of parameters defining each sub-datasets to be used.\n        transform_params: Optional; Dictionary defining the parameters of the transforms to perform\n            when sampling from the dataset.\n        sample_pairs (bool): Optional; True if paired sampling. This will ensure paired samples are handled\n            correctly in the datasets.\n\n    Returns:\n        Tuple[Any, List[Any]]: Tuple of Dataset object formed by the parameters given and list of\n        the sub-datasets created that constitute ``dataset``.\n    \"\"\"\n\n    def get_subdataset(\n        this_dataset_params: Dict[str, Any], key: str\n    ) -> Tuple[Callable[..., GeoDataset], str]:\n        # Get the params for this sub-dataset.\n        sub_dataset_params = this_dataset_params[key]\n\n        # Get the constructor for the class of dataset defined in params.\n        _sub_dataset: Callable[..., GeoDataset] = utils.func_by_str(\n            module_path=sub_dataset_params[\"module\"], func=sub_dataset_params[\"name\"]\n        )\n\n        # Construct the root to the sub-dataset's files.\n        sub_dataset_root = str(\n            universal_path(data_directory) / sub_dataset_params[\"root\"]\n        )\n\n        return _sub_dataset, sub_dataset_root\n\n    def create_transforms(this_transform_params: Any, key: str) -> Optional[Any]:\n        # Construct transforms for samples returned from this sub-dataset -- if found.\n        _transformations: Optional[Any] = None\n        if type(this_transform_params) == dict:\n            assert this_transform_params is not None\n            try:\n                if this_transform_params[key]:\n                    _transformations = make_transformations(\n                        this_transform_params[key], key=key\n                    )\n            except (KeyError, TypeError):\n                pass\n        else:\n            pass\n\n        return _transformations\n\n    def create_subdataset(\n        dataset_class: Callable[..., GeoDataset],\n        root: str,\n        subdataset_params: Dict[Literal[\"params\"], Dict[str, Any]],\n        _transformations: Optional[Any],\n    ) -> GeoDataset:\n        if sample_pairs:\n            return PairedDataset(\n                dataset_class,\n                root=root,\n                transforms=_transformations,\n                **subdataset_params[\"params\"],\n            )\n        else:\n            return dataset_class(\n                root=root,\n                transforms=_transformations,\n                **subdataset_params[\"params\"],\n            )\n\n    # --+ MAKE SUB-DATASETS +=========================================================================================+\n    # List to hold all the sub-datasets defined by dataset_params to be intersected together into a single dataset.\n    sub_datasets: List[GeoDataset] = []\n\n    # Iterate through all the sub-datasets defined in `dataset_params`.\n    for type_key in dataset_params.keys():\n\n        type_dataset_params = dataset_params[type_key]\n\n        type_subdatasets = []\n\n        multi_datasets_exist = False\n        for area_key in type_dataset_params.keys():\n            if area_key in (\"module\", \"name\", \"params\", \"root\"):\n                multi_datasets_exist = False\n                continue\n            else:\n                multi_datasets_exist = True\n                _subdataset, subdataset_root = get_subdataset(\n                    type_dataset_params, area_key\n                )\n                transformations: Optional[Any] = None\n                try:\n                    assert transform_params\n                    if transform_params[type_key]:\n                        transformations = create_transforms(\n                            transform_params[type_key], area_key\n                        )\n                except (KeyError, TypeError, AssertionError):\n                    pass\n\n                type_subdatasets.append(\n                    create_subdataset(\n                        _subdataset,\n                        subdataset_root,\n                        type_dataset_params[area_key],\n                        transformations,\n                    )\n                )\n\n        if multi_datasets_exist:\n            sub_datasets.append(unionise_datasets(type_subdatasets, sample_pairs))\n        else:\n            sub_datasets.append(\n                create_subdataset(\n                    *get_subdataset(dataset_params, type_key),\n                    type_dataset_params,\n                    create_transforms(transform_params, type_key),\n                )\n            )\n\n    # Intersect sub-datasets to form single dataset if more than one sub-dataset exists. Else, just set that to dataset.\n    dataset = sub_datasets[0]\n    if len(sub_datasets) > 1:\n        dataset = intersect_datasets(sub_datasets, sample_pairs=sample_pairs)\n\n    return dataset, sub_datasets\n\n\ndef construct_dataloader(\n    data_directory: Iterable[str],\n    dataset_params: Dict[str, Any],\n    sampler_params: Dict[str, Any],\n    dataloader_params: Dict[str, Any],\n    collator_params: Optional[Dict[str, Any]] = None,\n    transform_params: Optional[Dict[str, Any]] = None,\n    rank: int = 0,\n    world_size: int = 1,\n    sample_pairs: bool = False,\n) -> DataLoader[Iterable[Any]]:\n    \"\"\"Constructs a DataLoader object from the parameters provided for the datasets, sampler, collator and transforms.\n\n    Args:\n        data_directory (Iterable[str]): A list of str defining the common path for all datasets to be constructed.\n        dataset_params (dict): Dictionary of parameters defining each sub-datasets to be used.\n        sampler_params (dict): Dictionary of parameters for the sampler to be used to sample from the dataset.\n        dataloader_params (dict): Dictionary of parameters for the DataLoader itself.\n        collator_params (dict): Optional; Dictionary of parameters defining the function to collate\n            and stack samples from the sampler.\n        transform_params: Optional; Dictionary defining the parameters of the transforms to perform\n            when sampling from the dataset.\n        rank (int): Optional; The rank of this process for distributed computing.\n        world_size (int): Optional; The total number of processes within a distributed run.\n        sample_pairs (bool): Optional; True if paired sampling. This will wrap the collation function\n            for paired samples.\n\n    Returns:\n        loader (DataLoader): Object to handle the returning of batched samples from the dataset.\n    \"\"\"\n    dataset, subdatasets = make_dataset(\n        data_directory, dataset_params, transform_params, sample_pairs=sample_pairs\n    )\n\n    # --+ MAKE SAMPLERS +=============================================================================================+\n    _sampler: Callable[..., Union[BatchGeoSampler, GeoSampler]] = utils.func_by_str(\n        module_path=sampler_params[\"module\"], func=sampler_params[\"name\"]\n    )\n\n    batch_sampler = True if \"batch_size\" in sampler_params[\"params\"] else False\n\n    if batch_sampler and dist.is_available() and dist.is_initialized():  # type: ignore[attr-defined]\n        assert sampler_params[\"params\"][\"batch_size\"] % world_size == 0\n        per_device_batch_size = sampler_params[\"params\"][\"batch_size\"] // world_size\n        sampler_params[\"params\"][\"batch_size\"] = per_device_batch_size\n\n    sampler: Union[BatchGeoSampler, GeoSampler, DistributedSamplerWrapper] = _sampler(\n        dataset=subdatasets[0],\n        roi=make_bounding_box(sampler_params[\"roi\"]),\n        **sampler_params[\"params\"],\n    )\n\n    # --+ MAKE DATALOADERS +==========================================================================================+\n    collator = get_collator(collator_params)\n    _dataloader_params = dataloader_params.copy()\n\n    if world_size > 1:\n        # Wraps sampler for distributed computing.\n        sampler = DistributedSamplerWrapper(sampler, num_replicas=world_size, rank=rank)\n\n        # Splits batch size across devices.\n        assert dataloader_params[\"batch_size\"] % world_size == 0\n        per_device_batch_size = dataloader_params[\"batch_size\"] // world_size\n        _dataloader_params[\"batch_size\"] = per_device_batch_size\n\n    if sample_pairs:\n        if not torch.cuda.device_count() > 1:\n            collator = utils.pair_collate(collator)\n\n        # Can't wrap functions in distributed runs due to pickling error.\n        # Therefore, the collator is set to `stack_sample_pairs` automatically.\n        else:\n            collator = stack_sample_pairs\n\n    if batch_sampler:\n        _dataloader_params[\"batch_sampler\"] = sampler\n        del _dataloader_params[\"batch_size\"]\n    else:\n        _dataloader_params[\"sampler\"] = sampler\n\n    return DataLoader(dataset, collate_fn=collator, **_dataloader_params)\n\n\ndef make_bounding_box(\n    roi: Union[Sequence[float], bool] = False\n) -> Optional[BoundingBox]:\n    \"\"\"Construct a BoundingBox object from the corners of the box. False for no BoundingBox.\n\n    Args:\n        roi (tuple[float] or list[float] or bool): Either a tuple or array of values defining the corners\n            of a bounding box or False to designate no BoundingBox is defined.\n\n    Returns:\n        BoundingBox object made from parsed values or None if False was given.\n    \"\"\"\n    if roi is False:\n        return None\n    elif roi is True:\n        raise ValueError(\n            \"``roi`` must be a sequence of floats or ``False``, not ``True``\"\n        )\n    else:\n        return BoundingBox(*roi)\n\n\ndef get_transform(name: str, transform_params: Dict[str, Any]) -> Callable[..., Any]:\n    \"\"\"Creates a transform object based on config parameters.\n\n    Args:\n        name (str): Name of transform object to import e.g ``RandomResizedCrop``.\n        transform_params (Dict[str, Any]): Arguements to construct transform with.\n            Should also include ``\"module\"`` key defining the import path to the transform object.\n\n    Returns:\n        Initialised transform object specified by config parameters.\n\n    .. note::\n        If ``transform_params`` contains no ``\"module\"`` key, it defaults to ``\"torchvision.transforms\"``.\n\n    Example:\n        >>> name = \"RandomResizedCrop\"\n        >>> params = {\"module\": \"torchvision.transforms\", \"size\": 128}\n        >>> transform = get_transform(name, params)\n\n    Raises:\n        TypeError: If created transform :class:`object` is itself not :class:`callable`.\n    \"\"\"\n    params = transform_params.copy()\n    module = params.pop(\"module\", \"torchvision.transforms\")\n\n    # Gets the transform requested by config parameters.\n    _transform: Callable[..., Any] = utils.func_by_str(module, name)\n\n    transform: Callable[..., Any] = _transform(**params)\n    if callable(transform):\n        return transform\n    else:\n        raise TypeError(f\"Transform has type {type(transform)}, not a callable!\")\n\n\ndef make_transformations(\n    transform_params: Union[Dict[str, Any], Literal[False]], key: Optional[str] = None\n) -> Optional[Any]:\n    \"\"\"Constructs a transform or series of transforms based on parameters provided.\n\n    Args:\n        transform_params (dict): Parameters defining transforms desired. The name of each transform should be the key,\n            while the kwargs for the transform should be the value of that key as a dict.\n        key (str): Optional; Key of the type of data within the sample to be transformed.\n            Must be ``\"image\"`` or ``\"mask\"``.\n\n    Example:\n        >>> transform_params = {\n        >>>    \"CenterCrop\": {\"module\": \"torchvision.transforms\", \"size\": 128},\n        >>>     \"RandomHorizontalFlip\": {\"module\": \"torchvision.transforms\", \"p\": 0.7}\n        >>> }\n        >>> transforms = make_transformations(transform_params)\n\n    Returns:\n        If no parameters are parsed, None is returned.\n        If only one transform is defined by the parameters, returns a Transforms object.\n        If multiple transforms are defined, a Compose object of Transform objects is returned.\n    \"\"\"\n    transformations = []\n\n    # If no transforms are specified, return None.\n    if not transform_params:\n        return None\n\n    # Get each transform.\n    for name in transform_params:\n        if name == \"RandomApply\":\n            random_transforms = []\n            random_params = transform_params[name].copy()\n            p = random_params.pop(\"p\", 0.5)\n\n            for ran_name in random_params:\n                random_transforms.append(\n                    get_transform(ran_name, random_params[ran_name])\n                )\n\n            transformations.append(RandomApply(random_transforms, p=p))\n\n        else:\n            transformations.append(get_transform(name, transform_params[name]))\n\n    # Compose transforms together and return.\n    return MinervaCompose(transformations, key)\n\n\n@utils.return_updated_kwargs\ndef make_loaders(\n    rank: int = 0,\n    world_size: int = 1,\n    p_dist: bool = False,\n    **params,\n) -> Tuple[\n    Dict[str, DataLoader[Iterable[Any]]],\n    Dict[str, int],\n    List[Tuple[int, int]],\n    Dict[Any, Any],\n]:\n    \"\"\"Constructs train, validation and test datasets and places into :class:`DataLoader` objects.\n\n    Args:\n        rank (int): Rank number of the process. For use with :class:`DistributedDataParallel`.\n        world_size (int): Total number of processes across all nodes. For use with :class:`DistributedDataParallel`.\n        p_dist (bool): Optional; Whether to print to screen the distribution of classes within each dataset.\n\n    Keyword Args:\n        hyperparams (dict): Dictionary of hyper-parameters for the model.\n        batch_size (int): Number of samples in each batch to be returned by the DataLoaders.\n        elim (bool): Whether to eliminate classes with no samples in.\n\n    Returns:\n        Tuple[Dict[str, DataLoader[Iterable[Any]]], Dict[str, int], List[Tuple[int, int]], Dict[Any, Any]]: Tuple of;\n            * Dictionary of the :class:`DataLoader` s for training, validation and testing.\n            * Dictionary of the number of batches to return/ yield in each train, validation and test epoch.\n            * The class distribution of the entire dataset, sorted from largest to smallest class.\n            * Unused and updated kwargs.\n    \"\"\"\n    # Gets out the parameters for the DataLoaders from params.\n    dataloader_params: Dict[Any, Any] = params[\"hyperparams\"][\"params\"]\n    dataset_params: Dict[str, Any] = params[\"dataset_params\"]\n    sampler_params: Dict[str, Any] = params[\"sampler_params\"]\n    transform_params: Dict[str, Any] = params[\"transform_params\"]\n    batch_size: int = dataloader_params[\"batch_size\"]\n\n    model_type = params[\"model_type\"]\n    class_dist: List[Tuple[int, int]] = [(0, 0)]\n\n    new_classes: Dict[int, str] = {}\n    new_colours: Dict[int, str] = {}\n    forwards: Dict[int, int] = {}\n\n    sample_pairs: Union[bool, Any] = params.get(\"sample_pairs\", False)\n    if type(sample_pairs) != bool:\n        sample_pairs = False\n\n    if model_type != \"siamese\":\n        # Load manifest from cache for this dataset.\n        manifest = get_manifest(get_manifest_path())\n        class_dist = utils.modes_from_manifest(manifest)\n\n        # Finds the empty classes and returns modified classes, a dict to convert between the old and new systems\n        # and new colours.\n        new_classes, forwards, new_colours = utils.load_data_specs(\n            class_dist=class_dist, elim=params.get(\"elim\", False)\n        )\n\n    # Inits dicts to hold the variables and lists for train, validation and test.\n    n_batches = {}\n    loaders = {}\n\n    for mode in dataset_params.keys():\n        this_transform_params = transform_params[mode]\n        if params.get(\"elim\", False) and model_type != \"siamese\":\n            if type(this_transform_params[\"mask\"]) != dict:\n                this_transform_params[\"mask\"] = {\n                    \"ClassTransform\": {\n                        \"module\": \"minerva.transforms\",\n                        \"transform\": forwards,\n                    }\n                }\n            else:\n                this_transform_params[\"mask\"][\"ClassTransform\"] = {\n                    \"module\": \"minerva.transforms\",\n                    \"transform\": forwards,\n                }\n\n        # Calculates number of batches.\n        n_batches[mode] = int(sampler_params[mode][\"params\"][\"length\"] / batch_size)\n\n        # --+ MAKE DATASETS +=========================================================================================+\n        print(f\"CREATING {mode} DATASET\")\n        loaders[mode] = construct_dataloader(\n            params[\"dir\"][\"data\"],\n            dataset_params[mode],\n            sampler_params[mode],\n            dataloader_params,\n            collator_params=params[\"collator\"],\n            transform_params=this_transform_params,\n            rank=rank,\n            world_size=world_size,\n            sample_pairs=sample_pairs if mode == \"train\" else False,\n        )\n        print(\"DONE\")\n\n    if model_type != \"siamese\":\n        # Transform class dist if elimination of classes has occurred.\n        if params.get(\"elim\", False):\n            class_dist = utils.class_dist_transform(class_dist, forwards)\n\n        # Prints class distribution in a pretty text format using tabulate to stdout.\n        if p_dist:\n            utils.print_class_dist(class_dist)\n\n        params[\"hyperparams\"][\"model_params\"][\"n_classes\"] = len(new_classes)\n        params[\"classes\"] = new_classes\n        params[\"colours\"] = new_colours\n\n    params[\"max_pixel_value\"] = IMAGERY_CONFIG[\"data_specs\"][\"max_value\"]\n\n    return loaders, n_batches, class_dist, params\n\n\ndef get_manifest_path() -> str:\n    \"\"\"Gets the path to the manifest for the dataset to be used.\n\n    Returns:\n        str: Path to manifest as string.\n    \"\"\"\n    return str(Path(CACHE_DIR, f\"{utils.get_dataset_name()}_Manifest.csv\"))\n\n\ndef get_manifest(manifest_path: Union[str, Path]) -> DataFrame:\n    manifest_path = Path(manifest_path)\n    try:\n        return pd.read_csv(manifest_path)\n    except FileNotFoundError as err:\n        print(err)\n\n        print(\"CONSTRUCTING MISSING MANIFEST\")\n        mf_config = CONFIG.copy()\n\n        mf_config[\"dataloader_params\"] = CONFIG[\"hyperparams\"][\"params\"]\n\n        manifest = make_manifest(mf_config)\n\n        print(f\"MANIFEST TO FILE -----> {manifest_path}\")\n        path = manifest_path.parent\n        if not path.exists():\n            os.makedirs(path)\n\n        manifest.to_csv(manifest_path)\n\n        return manifest\n\n\ndef make_manifest(mf_config: Dict[Any, Any] = CONFIG) -> DataFrame:\n    \"\"\"Constructs a manifest of the dataset detailing each sample therein.\n\n    The dataset to construct a manifest of is defined by the ``data_config`` value in the config.\n\n    Returns:\n        DataFrame: The completed manifest as a :class:`DataFrame`.\n    \"\"\"\n    dataloader_params = mf_config[\"dataloader_params\"]\n    dataset_params = mf_config[\"dataset_params\"]\n    sampler_params = mf_config[\"sampler_params\"]\n    collator_params = mf_config[\"collator\"]\n\n    keys = list(dataset_params.keys())\n    print(\"CONSTRUCTING DATASET\")\n    loader = construct_dataloader(\n        mf_config[\"dir\"][\"data\"],\n        dataset_params[keys[0]],\n        sampler_params[keys[0]],\n        dataloader_params,\n        collator_params=collator_params,\n    )\n\n    print(\"FETCHING SAMPLES\")\n    df = DataFrame()\n\n    modes = load_all_samples(loader)\n\n    df[\"MODES\"] = [np.array([]) for _ in range(len(modes))]\n\n    for i in range(len(modes)):\n        df[\"MODES\"][i] = modes[i]\n\n    print(\"CALCULATING CLASS FRACTIONS\")\n    # Calculates the fractional size of each class in each patch.\n    df = DataFrame([row for row in df.apply(utils.class_frac, axis=1)])  # type: ignore[arg-type]\n    df.fillna(0, inplace=True)\n\n    # Delete redundant MODES column.\n    del df[\"MODES\"]\n\n    return df\n\n\ndef load_all_samples(dataloader: DataLoader[Iterable[Any]]) -> NDArray[Any, Any]:\n    \"\"\"Loads all sample masks from parsed :class:`DataLoader` and computes the modes of their classes.\n\n    Args:\n        dataloader (DataLoader): DataLoader containing samples. Must be using a dataset with ``__len__`` attribute\n            and a sampler that returns a dict with a ``\"mask\"`` key.\n\n    Returns:\n        np.ndarray: 2D array of the class modes within every sample defined by the parsed :class:`DataLoader`.\n    \"\"\"\n    sample_modes: List[List[Tuple[int, int]]] = []\n    for sample in alive_it(dataloader):\n        modes = utils.find_modes(sample[\"mask\"])\n        sample_modes.append(modes)\n\n    return np.array(sample_modes, dtype=object)\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 30588,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Functionality and custom code for constructing datasets, samplers and :class:`DataLoaders` for :mod:`minerva`.\n\nAttributes:\n    IMAGERY_CONFIG (Dict[str, Any]): Config defining the properties of the imagery used in the experiment.\n    CACHE_DIR (Path): Path to the cache directory used to store dataset manifests, cached model weights etc.\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"PairedDataset\",\n    \"construct_dataloader\",\n    \"get_collator\",\n    \"get_manifest\",\n    \"get_transform\",\n    \"load_all_samples\",\n    \"make_bounding_box\",\n    \"make_dataset\",\n    \"make_loaders\",\n    \"make_manifest\",\n    \"make_transformations\",\n    \"stack_sample_pairs\",\n    \"intersect_datasets\",\n    \"get_manifest_path\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport inspect\nimport os\nfrom pathlib import Path\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Literal,\n    Optional,\n    Sequence,\n    Tuple,\n    Union,\n)\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.distributed as dist\nfrom alive_progress import alive_it\nfrom catalyst.data.sampler import DistributedSamplerWrapper\nfrom nptyping import NDArray\nfrom pandas import DataFrame\nfrom torch.utils.data import DataLoader\nfrom torchgeo.datasets import (\n    GeoDataset,\n    IntersectionDataset,\n    RasterDataset,\n    UnionDataset,\n)\nfrom torchgeo.datasets.utils import BoundingBox, concat_samples, stack_samples\nfrom torchgeo.samplers import BatchGeoSampler, GeoSampler\nfrom torchvision.transforms import RandomApply\n\nfrom minerva.transforms import MinervaCompose\nfrom minerva.utils import AUX_CONFIGS, CONFIG, universal_path, utils\n\n# =====================================================================================================================\n#                                                     GLOBALS\n# =====================================================================================================================\nIMAGERY_CONFIG: Dict[str, Any] = AUX_CONFIGS[\"imagery_config\"]\n\n# Path to cache directory.\nCACHE_DIR: Path = universal_path(CONFIG[\"dir\"][\"cache\"])\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass TstImgDataset(RasterDataset):\n    \"\"\"Test dataset for imagery.\n\n    Attributes:\n        filename_glob (str): Pattern for image tiff files within dataset root to construct dataset from.\n    \"\"\"\n\n    filename_glob = \"*_img.tif\"\n\n\nclass TstMaskDataset(RasterDataset):\n    \"\"\"Test dataset for land cover data.\n\n    Attributes:\n        filename_glob (str): Pattern for mask tiff files within dataset root to construct dataset from.\n        is_image (bool): Sets flag to false to mark this as not a imagery dataset.\n    \"\"\"\n\n    filename_glob = \"*_lc.tif\"\n    is_image = False\n\n\nclass PairedDataset(RasterDataset):\n    \"\"\"Custom dataset to act as a wrapper to other datasets to handle paired sampling.\n\n    Attributes:\n        dataset (RasterDataset): Wrapped dataset to sampled from.\n\n    Args:\n        dataset_cls (Callable[..., GeoDataset]): Constructor for a :class:`RasterDataset`\n            to be wrapped for paired sampling.\n    \"\"\"\n\n    def __init__(\n        self,\n        dataset_cls: Callable[..., GeoDataset],\n        *args,\n        **kwargs,\n    ) -> None:\n        super_sig = inspect.signature(RasterDataset.__init__).parameters.values()\n        super_kwargs = {\n            key.name: kwargs[key.name] for key in super_sig if key.name in kwargs\n        }\n\n        super().__init__(*args, **super_kwargs)\n        self.dataset = dataset_cls(*args, **kwargs)\n\n    def __getitem__(  # type: ignore[override]\n        self, queries: Tuple[BoundingBox, BoundingBox]\n    ) -> Tuple[Dict[str, Any], ...]:\n        return self.dataset.__getitem__(queries[0]), self.dataset.__getitem__(\n            queries[1]\n        )\n\n    def __getattr__(self, item):\n        if item in self.dataset.__dict__:\n            return getattr(self.dataset, item)  # pragma: no cover\n        elif item in self.__dict__:\n            return getattr(self, item)\n        else:\n            raise AttributeError\n\n    def __repr__(self) -> Any:\n        return self.dataset.__repr__()\n\n\n# =====================================================================================================================\n#                                                     METHODS\n# =====================================================================================================================\ndef get_collator(\n    collator_params: Optional[Dict[str, str]] = None\n) -> Callable[..., Any]:\n    \"\"\"Gets the function defined in parameters to collate samples together to form a batch.\n\n    Args:\n        collator_params (Dict[str, str]): Optional; Dictionary that must contain keys for\n            'module' and 'name' of the collation function. Defaults to config['collator'].\n\n    Returns:\n        Callable[..., Any]: Collation function found from parameters given.\n    \"\"\"\n    collator: Callable[..., Any]\n    if collator_params is not None:\n        module = collator_params.pop(\"module\", \"\")\n        if module == \"\":\n            collator = globals()[collator_params[\"name\"]]\n        else:\n            collator = utils.func_by_str(module, collator_params[\"name\"])\n    else:\n        collator = stack_samples\n\n    assert callable(collator)\n    return collator\n\n\ndef stack_sample_pairs(\n    samples: Iterable[Tuple[Dict[Any, Any], Dict[Any, Any]]]\n) -> Tuple[Dict[Any, Any], Dict[Any, Any]]:\n    \"\"\"Takes a list of paired sample dicts and stacks them into a tuple of batches of sample dicts.\n\n    Args:\n        samples (Iterable[Tuple[Dict[Any, Any]]]): List of paired sample dicts to be stacked.\n\n    Returns:\n        Tuple[Dict[Any, Any], Dict[Any, Any]]: Tuple of batches within dicts.\n    \"\"\"\n    a, b = tuple(zip(*samples))\n    return stack_samples(a), stack_samples(b)\n\n\ndef intersect_datasets(\n    datasets: Sequence[GeoDataset], sample_pairs: bool = False\n) -> IntersectionDataset:\n    \"\"\"Intersects a list of :class:`GeoDataset` together to return a single dataset object.\n\n    Args:\n        datasets (List[GeoDataset]): List of datasets to intersect together. Should have some geospatial overlap.\n        sample_pairs (bool): Optional; True if paired sampling. This will wrap the collation function\n            for paired samples.\n\n    Returns:\n        IntersectionDataset: Final dataset object representing an intersection of all the parsed datasets.\n    \"\"\"\n\n    def intersect_pair_datasets(a: GeoDataset, b: GeoDataset) -> IntersectionDataset:\n        if sample_pairs:\n            return IntersectionDataset(\n                a, b, collate_fn=utils.pair_collate(concat_samples)\n            )\n        else:\n            return a & b\n\n    master_dataset: Union[GeoDataset, IntersectionDataset] = datasets[0]\n\n    for i in range(len(datasets) - 1):\n        master_dataset = intersect_pair_datasets(master_dataset, datasets[i + 1])\n\n    assert isinstance(master_dataset, IntersectionDataset)\n    return master_dataset\n\n\ndef unionise_datasets(\n    datasets: Sequence[GeoDataset], sample_pairs: bool = False\n) -> UnionDataset:\n    \"\"\"Unionises a list of :class:`GeoDataset` together to return a single dataset object.\n\n    Args:\n        datasets (List[GeoDataset]): List of datasets to unionise together.\n        sample_pairs (bool): Optional; True if paired sampling.\n            This will wrap the collation function for paired samples.\n\n    Returns:\n        UnionDataset: Final dataset object representing an union of all the parsed datasets.\n    \"\"\"\n\n    def unionise_pair_datasets(a: GeoDataset, b: GeoDataset) -> UnionDataset:\n        if sample_pairs:\n            return UnionDataset(a, b, collate_fn=utils.pair_collate(concat_samples))\n        else:\n            return a | b\n\n    master_dataset: Union[GeoDataset, UnionDataset] = datasets[0]\n\n    for i in range(len(datasets) - 1):\n        master_dataset = unionise_pair_datasets(master_dataset, datasets[i + 1])\n\n    assert isinstance(master_dataset, UnionDataset)\n    return master_dataset\n\n\ndef make_dataset(\n    data_directory: Union[Iterable[str], str, Path],\n    dataset_params: Dict[Any, Any],\n    transform_params: Optional[Dict[Any, Any]] = None,\n    sample_pairs: bool = False,\n) -> Tuple[Any, List[Any]]:\n    \"\"\"Constructs a dataset object from ``n`` sub-datasets given by the parameters supplied.\n\n    Args:\n        data_directory (Union[Iterable[str], str, Path]): List defining the path to the directory containing the data.\n        dataset_params (dict): Dictionary of parameters defining each sub-datasets to be used.\n        transform_params: Optional; Dictionary defining the parameters of the transforms to perform\n            when sampling from the dataset.\n        sample_pairs (bool): Optional; True if paired sampling. This will ensure paired samples are handled\n            correctly in the datasets.\n\n    Returns:\n        Tuple[Any, List[Any]]: Tuple of Dataset object formed by the parameters given and list of\n        the sub-datasets created that constitute ``dataset``.\n    \"\"\"\n\n    def get_subdataset(\n        this_dataset_params: Dict[str, Any], key: str\n    ) -> Tuple[Callable[..., GeoDataset], str]:\n        # Get the params for this sub-dataset.\n        sub_dataset_params = this_dataset_params[key]\n\n        # Get the constructor for the class of dataset defined in params.\n        _sub_dataset: Callable[..., GeoDataset] = utils.func_by_str(\n            module_path=sub_dataset_params[\"module\"], func=sub_dataset_params[\"name\"]\n        )\n\n        # Construct the root to the sub-dataset's files.\n        sub_dataset_root = str(\n            universal_path(data_directory) / sub_dataset_params[\"root\"]\n        )\n\n        return _sub_dataset, sub_dataset_root\n\n    def create_transforms(this_transform_params: Any, key: str) -> Optional[Any]:\n        # Construct transforms for samples returned from this sub-dataset -- if found.\n        _transformations: Optional[Any] = None\n        if type(this_transform_params) == dict:\n            assert this_transform_params is not None\n            try:\n                if this_transform_params[key]:\n                    _transformations = make_transformations(\n                        this_transform_params[key], key=key\n                    )\n            except (KeyError, TypeError):\n                pass\n        else:\n            pass\n\n        return _transformations\n\n    def create_subdataset(\n        dataset_class: Callable[..., GeoDataset],\n        root: str,\n        subdataset_params: Dict[Literal[\"params\"], Dict[str, Any]],\n        _transformations: Optional[Any],\n    ) -> GeoDataset:\n        if sample_pairs:\n            return PairedDataset(\n                dataset_class,\n                root=root,\n                transforms=_transformations,\n                **subdataset_params[\"params\"],\n            )\n        else:\n            return dataset_class(\n                root=root,\n                transforms=_transformations,\n                **subdataset_params[\"params\"],\n            )\n\n    # --+ MAKE SUB-DATASETS +=========================================================================================+\n    # List to hold all the sub-datasets defined by dataset_params to be intersected together into a single dataset.\n    sub_datasets: List[GeoDataset] = []\n\n    # Iterate through all the sub-datasets defined in `dataset_params`.\n    for type_key in dataset_params.keys():\n\n        type_dataset_params = dataset_params[type_key]\n\n        type_subdatasets = []\n\n        multi_datasets_exist = False\n        for area_key in type_dataset_params.keys():\n            if area_key in (\"module\", \"name\", \"params\", \"root\"):\n                multi_datasets_exist = False\n                continue\n            else:\n                multi_datasets_exist = True\n                _subdataset, subdataset_root = get_subdataset(\n                    type_dataset_params, area_key\n                )\n                transformations: Optional[Any] = None\n                try:\n                    assert transform_params\n                    if transform_params[type_key]:\n                        transformations = create_transforms(\n                            transform_params[type_key], area_key\n                        )\n                except (KeyError, TypeError, AssertionError):\n                    pass\n\n                type_subdatasets.append(\n                    create_subdataset(\n                        _subdataset,\n                        subdataset_root,\n                        type_dataset_params[area_key],\n                        transformations,\n                    )\n                )\n\n        if multi_datasets_exist:\n            sub_datasets.append(unionise_datasets(type_subdatasets, sample_pairs))\n        else:\n            sub_datasets.append(\n                create_subdataset(\n                    *get_subdataset(dataset_params, type_key),\n                    type_dataset_params,\n                    create_transforms(transform_params, type_key),\n                )\n            )\n\n    # Intersect sub-datasets to form single dataset if more than one sub-dataset exists. Else, just set that to dataset.\n    dataset = sub_datasets[0]\n    if len(sub_datasets) > 1:\n        dataset = intersect_datasets(sub_datasets, sample_pairs=sample_pairs)\n\n    return dataset, sub_datasets\n\n\ndef construct_dataloader(\n    data_directory: Iterable[str],\n    dataset_params: Dict[str, Any],\n    sampler_params: Dict[str, Any],\n    dataloader_params: Dict[str, Any],\n    collator_params: Optional[Dict[str, Any]] = None,\n    transform_params: Optional[Dict[str, Any]] = None,\n    rank: int = 0,\n    world_size: int = 1,\n    sample_pairs: bool = False,\n) -> DataLoader[Iterable[Any]]:\n    \"\"\"Constructs a DataLoader object from the parameters provided for the datasets, sampler, collator and transforms.\n\n    Args:\n        data_directory (Iterable[str]): A list of str defining the common path for all datasets to be constructed.\n        dataset_params (dict): Dictionary of parameters defining each sub-datasets to be used.\n        sampler_params (dict): Dictionary of parameters for the sampler to be used to sample from the dataset.\n        dataloader_params (dict): Dictionary of parameters for the DataLoader itself.\n        collator_params (dict): Optional; Dictionary of parameters defining the function to collate\n            and stack samples from the sampler.\n        transform_params: Optional; Dictionary defining the parameters of the transforms to perform\n            when sampling from the dataset.\n        rank (int): Optional; The rank of this process for distributed computing.\n        world_size (int): Optional; The total number of processes within a distributed run.\n        sample_pairs (bool): Optional; True if paired sampling. This will wrap the collation function\n            for paired samples.\n\n    Returns:\n        loader (DataLoader): Object to handle the returning of batched samples from the dataset.\n    \"\"\"\n    dataset, subdatasets = make_dataset(\n        data_directory, dataset_params, transform_params, sample_pairs=sample_pairs\n    )\n\n    # --+ MAKE SAMPLERS +=============================================================================================+\n    _sampler: Callable[..., Union[BatchGeoSampler, GeoSampler]] = utils.func_by_str(\n        module_path=sampler_params[\"module\"], func=sampler_params[\"name\"]\n    )\n\n    batch_sampler = True if \"batch_size\" in sampler_params[\"params\"] else False\n\n    if batch_sampler and dist.is_available() and dist.is_initialized():  # type: ignore[attr-defined]\n        assert sampler_params[\"params\"][\"batch_size\"] % world_size == 0\n        per_device_batch_size = sampler_params[\"params\"][\"batch_size\"] // world_size\n        sampler_params[\"params\"][\"batch_size\"] = per_device_batch_size\n\n    sampler: Union[BatchGeoSampler, GeoSampler, DistributedSamplerWrapper] = _sampler(\n        dataset=subdatasets[0],\n        roi=make_bounding_box(sampler_params[\"roi\"]),\n        **sampler_params[\"params\"],\n    )\n\n    # --+ MAKE DATALOADERS +==========================================================================================+\n    collator = get_collator(collator_params)\n    _dataloader_params = dataloader_params.copy()\n\n    if world_size > 1:\n        # Wraps sampler for distributed computing.\n        sampler = DistributedSamplerWrapper(sampler, num_replicas=world_size, rank=rank)\n\n        # Splits batch size across devices.\n        assert dataloader_params[\"batch_size\"] % world_size == 0\n        per_device_batch_size = dataloader_params[\"batch_size\"] // world_size\n        _dataloader_params[\"batch_size\"] = per_device_batch_size\n\n    if sample_pairs:\n        if not torch.cuda.device_count() > 1:\n            collator = utils.pair_collate(collator)\n\n        # Can't wrap functions in distributed runs due to pickling error.\n        # Therefore, the collator is set to `stack_sample_pairs` automatically.\n        else:\n            collator = stack_sample_pairs\n\n    if batch_sampler:\n        _dataloader_params[\"batch_sampler\"] = sampler\n        del _dataloader_params[\"batch_size\"]\n    else:\n        _dataloader_params[\"sampler\"] = sampler\n\n    return DataLoader(dataset, collate_fn=collator, **_dataloader_params)\n\n\ndef make_bounding_box(\n    roi: Union[Sequence[float], bool] = False\n) -> Optional[BoundingBox]:\n    \"\"\"Construct a BoundingBox object from the corners of the box. False for no BoundingBox.\n\n    Args:\n        roi (tuple[float] or list[float] or bool): Either a tuple or array of values defining the corners\n            of a bounding box or False to designate no BoundingBox is defined.\n\n    Returns:\n        BoundingBox object made from parsed values or None if False was given.\n    \"\"\"\n    if roi is False:\n        return None\n    elif roi is True:\n        raise ValueError(\n            \"``roi`` must be a sequence of floats or ``False``, not ``True``\"\n        )\n    else:\n        return BoundingBox(*roi)\n\n\ndef get_transform(name: str, transform_params: Dict[str, Any]) -> Callable[..., Any]:\n    \"\"\"Creates a transform object based on config parameters.\n\n    Args:\n        name (str): Name of transform object to import e.g ``RandomResizedCrop``.\n        transform_params (Dict[str, Any]): Arguements to construct transform with.\n            Should also include ``\"module\"`` key defining the import path to the transform object.\n\n    Returns:\n        Initialised transform object specified by config parameters.\n\n    .. note::\n        If ``transform_params`` contains no ``\"module\"`` key, it defaults to ``\"torchvision.transforms\"``.\n\n    Example:\n        >>> name = \"RandomResizedCrop\"\n        >>> params = {\"module\": \"torchvision.transforms\", \"size\": 128}\n        >>> transform = get_transform(name, params)\n\n    Raises:\n        TypeError: If created transform :class:`object` is itself not :class:`callable`.\n    \"\"\"\n    params = transform_params.copy()\n    module = params.pop(\"module\", \"torchvision.transforms\")\n\n    # Gets the transform requested by config parameters.\n    _transform: Callable[..., Any] = utils.func_by_str(module, name)\n\n    transform: Callable[..., Any] = _transform(**params)\n    if callable(transform):\n        return transform\n    else:\n        raise TypeError(f\"Transform has type {type(transform)}, not a callable!\")\n\n\ndef make_transformations(\n    transform_params: Union[Dict[str, Any], Literal[False]], key: Optional[str] = None\n) -> Optional[Any]:\n    \"\"\"Constructs a transform or series of transforms based on parameters provided.\n\n    Args:\n        transform_params (dict): Parameters defining transforms desired. The name of each transform should be the key,\n            while the kwargs for the transform should be the value of that key as a dict.\n        key (str): Optional; Key of the type of data within the sample to be transformed.\n            Must be ``\"image\"`` or ``\"mask\"``.\n\n    Example:\n        >>> transform_params = {\n        >>>    \"CenterCrop\": {\"module\": \"torchvision.transforms\", \"size\": 128},\n        >>>     \"RandomHorizontalFlip\": {\"module\": \"torchvision.transforms\", \"p\": 0.7}\n        >>> }\n        >>> transforms = make_transformations(transform_params)\n\n    Returns:\n        If no parameters are parsed, None is returned.\n        If only one transform is defined by the parameters, returns a Transforms object.\n        If multiple transforms are defined, a Compose object of Transform objects is returned.\n    \"\"\"\n    transformations = []\n\n    # If no transforms are specified, return None.\n    if not transform_params:\n        return None\n\n    # Get each transform.\n    for name in transform_params:\n        if name == \"RandomApply\":\n            random_transforms = []\n            random_params = transform_params[name].copy()\n            p = random_params.pop(\"p\", 0.5)\n\n            for ran_name in random_params:\n                random_transforms.append(\n                    get_transform(ran_name, random_params[ran_name])\n                )\n\n            transformations.append(RandomApply(random_transforms, p=p))\n\n        else:\n            transformations.append(get_transform(name, transform_params[name]))\n\n    # Compose transforms together and return.\n    return MinervaCompose(transformations, key)\n\n\n@utils.return_updated_kwargs\ndef make_loaders(\n    rank: int = 0,\n    world_size: int = 1,\n    p_dist: bool = False,\n    **params,\n) -> Tuple[\n    Dict[str, DataLoader[Iterable[Any]]],\n    Dict[str, int],\n    List[Tuple[int, int]],\n    Dict[Any, Any],\n]:\n    \"\"\"Constructs train, validation and test datasets and places into :class:`DataLoader` objects.\n\n    Args:\n        rank (int): Rank number of the process. For use with :class:`DistributedDataParallel`.\n        world_size (int): Total number of processes across all nodes. For use with :class:`DistributedDataParallel`.\n        p_dist (bool): Optional; Whether to print to screen the distribution of classes within each dataset.\n\n    Keyword Args:\n        hyperparams (dict): Dictionary of hyper-parameters for the model.\n        batch_size (int): Number of samples in each batch to be returned by the DataLoaders.\n        elim (bool): Whether to eliminate classes with no samples in.\n\n    Returns:\n        Tuple[Dict[str, DataLoader[Iterable[Any]]], Dict[str, int], List[Tuple[int, int]], Dict[Any, Any]]: Tuple of;\n            * Dictionary of the :class:`DataLoader` s for training, validation and testing.\n            * Dictionary of the number of batches to return/ yield in each train, validation and test epoch.\n            * The class distribution of the entire dataset, sorted from largest to smallest class.\n            * Unused and updated kwargs.\n    \"\"\"\n    # Gets out the parameters for the DataLoaders from params.\n    dataloader_params: Dict[Any, Any] = params[\"hyperparams\"][\"params\"]\n    dataset_params: Dict[str, Any] = params[\"dataset_params\"]\n    sampler_params: Dict[str, Any] = params[\"sampler_params\"]\n    transform_params: Dict[str, Any] = params[\"transform_params\"]\n    batch_size: int = dataloader_params[\"batch_size\"]\n\n    model_type = params[\"model_type\"]\n    class_dist: List[Tuple[int, int]] = [(0, 0)]\n\n    new_classes: Dict[int, str] = {}\n    new_colours: Dict[int, str] = {}\n    forwards: Dict[int, int] = {}\n\n    sample_pairs: Union[bool, Any] = params.get(\"sample_pairs\", False)\n    if type(sample_pairs) != bool:\n        sample_pairs = False\n\n    if model_type != \"siamese\":\n        # Load manifest from cache for this dataset.\n        manifest = get_manifest(get_manifest_path())\n        class_dist = utils.modes_from_manifest(manifest)\n\n        # Finds the empty classes and returns modified classes, a dict to convert between the old and new systems\n        # and new colours.\n        new_classes, forwards, new_colours = utils.load_data_specs(\n            class_dist=class_dist, elim=params.get(\"elim\", False)\n        )\n\n    # Inits dicts to hold the variables and lists for train, validation and test.\n    n_batches = {}\n    loaders = {}\n\n    for mode in dataset_params.keys():\n        this_transform_params = transform_params[mode]\n        if params.get(\"elim\", False) and model_type != \"siamese\":\n            if type(this_transform_params[\"mask\"]) != dict:\n                this_transform_params[\"mask\"] = {\n                    \"ClassTransform\": {\n                        \"module\": \"minerva.transforms\",\n                        \"transform\": forwards,\n                    }\n                }\n            else:\n                this_transform_params[\"mask\"][\"ClassTransform\"] = {\n                    \"module\": \"minerva.transforms\",\n                    \"transform\": forwards,\n                }\n\n        # Calculates number of batches.\n        n_batches[mode] = int(sampler_params[mode][\"params\"][\"length\"] / batch_size)\n\n        # --+ MAKE DATASETS +=========================================================================================+\n        print(f\"CREATING {mode} DATASET\")\n        loaders[mode] = construct_dataloader(\n            params[\"dir\"][\"data\"],\n            dataset_params[mode],\n            sampler_params[mode],\n            dataloader_params,\n            collator_params=params[\"collator\"],\n            transform_params=this_transform_params,\n            rank=rank,\n            world_size=world_size,\n            sample_pairs=sample_pairs if mode == \"train\" else False,\n        )\n        print(\"DONE\")\n\n    if model_type != \"siamese\":\n        # Transform class dist if elimination of classes has occurred.\n        if params.get(\"elim\", False):\n            class_dist = utils.class_dist_transform(class_dist, forwards)\n\n        # Prints class distribution in a pretty text format using tabulate to stdout.\n        if p_dist:\n            utils.print_class_dist(class_dist)\n\n        params[\"hyperparams\"][\"model_params\"][\"n_classes\"] = len(new_classes)\n        params[\"classes\"] = new_classes\n        params[\"colours\"] = new_colours\n\n    params[\"max_pixel_value\"] = IMAGERY_CONFIG[\"data_specs\"][\"max_value\"]\n\n    return loaders, n_batches, class_dist, params\n\n\ndef get_manifest_path() -> str:\n    \"\"\"Gets the path to the manifest for the dataset to be used.\n\n    Returns:\n        str: Path to manifest as string.\n    \"\"\"\n    return str(Path(CACHE_DIR, f\"{utils.get_dataset_name()}_Manifest.csv\"))\n\n\ndef get_manifest(manifest_path: Union[str, Path]) -> DataFrame:\n    manifest_path = Path(manifest_path)\n    try:\n        return pd.read_csv(manifest_path)\n    except FileNotFoundError as err:\n        print(err)\n\n        print(\"CONSTRUCTING MISSING MANIFEST\")\n        mf_config = CONFIG.copy()\n\n        mf_config[\"dataloader_params\"] = CONFIG[\"hyperparams\"][\"params\"]\n\n        manifest = make_manifest(mf_config)\n\n        print(f\"MANIFEST TO FILE -----> {manifest_path}\")\n        path = manifest_path.parent\n        if not path.exists():\n            os.makedirs(path)\n\n        manifest.to_csv(manifest_path)\n\n        return manifest\n\n\ndef make_manifest(mf_config: Dict[Any, Any] = CONFIG) -> DataFrame:\n    \"\"\"Constructs a manifest of the dataset detailing each sample therein.\n\n    The dataset to construct a manifest of is defined by the ``data_config`` value in the config.\n\n    Returns:\n        DataFrame: The completed manifest as a :class:`DataFrame`.\n    \"\"\"\n    dataloader_params = mf_config[\"dataloader_params\"]\n    dataset_params = mf_config[\"dataset_params\"]\n    sampler_params = mf_config[\"sampler_params\"]\n    collator_params = mf_config[\"collator\"]\n\n    keys = list(dataset_params.keys())\n    print(\"CONSTRUCTING DATASET\")\n    loader = construct_dataloader(\n        mf_config[\"dir\"][\"data\"],\n        dataset_params[keys[0]],\n        sampler_params[keys[0]],\n        dataloader_params,\n        collator_params=collator_params,\n    )\n\n    print(\"FETCHING SAMPLES\")\n    df = DataFrame()\n\n    modes = load_all_samples(loader)\n\n    df[\"MODES\"] = [np.array([]) for _ in range(len(modes))]\n\n    for i in range(len(modes)):\n        df[\"MODES\"][i] = modes[i]\n\n    print(\"CALCULATING CLASS FRACTIONS\")\n    # Calculates the fractional size of each class in each patch.\n    df = DataFrame([row for row in df.apply(utils.class_frac, axis=1)])  # type: ignore[arg-type]\n    df.fillna(0, inplace=True)\n\n    # Delete redundant MODES column.\n    del df[\"MODES\"]\n\n    return df\n\n\ndef load_all_samples(dataloader: DataLoader[Iterable[Any]]) -> NDArray[Any, Any]:\n    \"\"\"Loads all sample masks from parsed :class:`DataLoader` and computes the modes of their classes.\n\n    Args:\n        dataloader (DataLoader): DataLoader containing samples. Must be using a dataset with ``__len__`` attribute\n            and a sampler that returns a dict with a ``\"mask\"`` key.\n\n    Returns:\n        np.ndarray: 2D array of the class modes within every sample defined by the parsed :class:`DataLoader`.\n    \"\"\"\n    sample_modes: List[List[Tuple[int, int]]] = []\n    for sample in alive_it(dataloader):\n        modes = utils.find_modes(sample[\"mask\"])\n        sample_modes.append(modes)\n\n    return np.array(sample_modes, dtype=object)\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "498b0282c54803c63c53607d6a38b98c79ab42317da69fb2903c6f8e1d119d04"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/logger.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 20612,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Module to handle the logging of results from various model types.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"MinervaLogger\",\n    \"STGLogger\",\n    \"SSLLogger\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport abc\nimport math\nfrom abc import ABC\nfrom typing import Any, Dict, Optional, SupportsFloat, Tuple, Union\n\nimport mlflow\nimport numpy as np\nimport torch\nfrom sklearn.metrics import jaccard_score\nfrom torch import Tensor\nfrom torch.utils.tensorboard.writer import SummaryWriter\nfrom torchgeo.datasets.utils import BoundingBox\nfrom wandb.sdk.wandb_run import Run\n\nfrom minerva.utils import utils\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass MinervaLogger(ABC):\n    \"\"\"Base abstract class for all `minerva` logger classes to ensure intercompatibility with `trainer`.\n\n    Attributes:\n        record_int (bool): Whether to record the integer values from an epoch of model fitting.\n        record_float (bool): Whether to record the floating point values from an epoch of model fitting.\n        n_batches (int): Number of batches in the epoch.\n        batch_size (int): Size of the batch.\n        n_samples (int): Total number of samples in the epoch.\n        logs (Dict[str, Any]): Dictionary to hold the logs from the epoch.\n            Logs should be more lightweight than `results`.\n        results (Dict[str, Any]): Dictionary to hold the results from the epoch.\n\n    Args:\n        n_batches (int): Number of batches in the epoch.\n        batch_size (int): Size of the batch.\n        n_samples (int): Total number of samples in the epoch.\n        record_int (bool): Optional; Whether to record the integer values from an epoch of model fitting.\n            Defaults to ``True``.\n        record_float (bool): Optional; Whether to record the floating point values from an epoch of model fitting.\n            Defaults to ``False``.\n        writer (Union[SummaryWriter, Run]): Optional; Writer object from :mod:`tensorboard`,\n            a :mod:`wandb` :class:`Run` object or ``None``.\n    \"\"\"\n\n    __metaclass__ = abc.ABCMeta\n\n    def __init__(\n        self,\n        n_batches: int,\n        batch_size: int,\n        n_samples: int,\n        record_int: bool = True,\n        record_float: bool = False,\n        writer: Optional[Union[SummaryWriter, Run]] = None,\n        **kwargs,\n    ) -> None:\n\n        super(MinervaLogger, self).__init__()\n        self.record_int = record_int\n        self.record_float = record_float\n        self.n_batches = n_batches\n        self.batch_size = batch_size\n        self.n_samples = n_samples\n        self.writer = writer\n\n        self.logs: Dict[str, Any] = {}\n        self.results: Dict[str, Any] = {}\n\n    def __call__(self, mode: str, step_num: int, loss: Tensor, *args) -> None:\n        \"\"\"Call :func:`log`.\n\n        Args:\n            mode (str): Mode of model fitting.\n            step_num (int): The global step number of for the mode of model fitting.\n            loss (Tensor): Loss from this step of model fitting.\n\n        Returns:\n            None\n        \"\"\"\n        self.log(mode, step_num, loss, *args)\n\n    @abc.abstractmethod\n    def log(\n        self,\n        mode: str,\n        step_num: int,\n        loss: Tensor,\n        z: Optional[Tensor] = None,\n        y: Optional[Tensor] = None,\n        bbox: Optional[BoundingBox] = None,\n        *args,\n        **kwargs,\n    ) -> None:\n        \"\"\"Abstract logging method, the core functionality of a logger. Must be overwritten.\n\n        Args:\n            mode (str): Mode of model fitting.\n            step_num (int): The global step number of for the mode of model fitting.\n            loss (Tensor): Loss from this step of model fitting.\n            z (Tensor): Optional; Output tensor from the model.\n            y (Tensor): Optional; Labels to assess model output against.\n            bbox (BoundingBox): Optional; Bounding boxes of the input samples.\n\n        Returns:\n            None\n        \"\"\"\n        pass  # pragma: no cover\n\n    def write_metric(\n        self, mode: str, key: str, value: SupportsFloat, step_num: Optional[int] = None\n    ):\n        \"\"\"Write metric values to logging backends after calculation\"\"\"\n        # TODO: Are values being reduced across nodes / logged from rank 0?\n        if self.writer:\n            if isinstance(self.writer, SummaryWriter):\n                self.writer.add_scalar(\n                    tag=f\"{mode}_{key}\",\n                    scalar_value=value,  # type: ignore[attr-defined]\n                    global_step=step_num,\n                )\n            elif isinstance(self.writer, Run):\n                self.writer.log({f\"{mode}/step\": step_num, f\"{mode}/{key}\": value})\n\n        if mlflow.active_run():\n            # If running in Azure Machine Learning, tracking URI / experiment ID set already\n            # https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow-cli-runs?tabs=python%2Cmlflow#creating-a-training-routine  # noqa: E501\n            mlflow.log_metric(key, value)  # pragma: no cover\n\n    @property\n    def get_logs(self) -> Dict[str, Any]:\n        \"\"\"Gets the logs dictionary.\n\n        Returns:\n            Dict[str, Any]: Log dictionary of the logger.\n        \"\"\"\n        return self.logs\n\n    @property\n    def get_results(self) -> Dict[str, Any]:\n        \"\"\"Gets the results dictionary.\n\n        Returns:\n            Dict[str,Any]: Results dictionary of the logger.\n        \"\"\"\n        return self.results\n\n\nclass STGLogger(MinervaLogger):\n    \"\"\"Logger designed for supervised learning using `torchgeo` datasets.\n\n    Args:\n        n_batches (int): Number of batches in the epoch.\n        batch_size (int): Size of the batch.\n        n_samples (int): Total number of samples in the epoch.\n        out_shape (Tuple[int, ...]): Shape of the model output.\n        n_classes (int): Number of classes in dataset.\n        record_int (bool): Optional; Whether to record the integer values from an epoch of model fitting.\n            Defaults to True.\n        record_float (bool): Optional; Whether to record the floating point values from an epoch of model fitting.\n            Defaults to False.\n        writer (Union[SummaryWriter, Run]): Optional; Writer object from :mod:`tensorboard`,\n            a :mod:`wandb` :class:`Run` object or ``None``.\n\n    Raises:\n        MemoryError: If trying to allocate memory to hold the probabilites of predictions\n            from the model exceeds capacity.\n        MemoryError: If trying to allocate memory to hold the bounding boxes of samples would exceed capacity.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_batches: int,\n        batch_size: int,\n        n_samples: int,\n        out_shape: Tuple[int, ...],\n        n_classes: int,\n        record_int: bool = True,\n        record_float: bool = False,\n        writer: Optional[Union[SummaryWriter, Run]] = None,\n        **kwargs,\n    ) -> None:\n\n        super(STGLogger, self).__init__(\n            n_batches,\n            batch_size,\n            n_samples,\n            record_int,\n            record_float,\n            writer,\n        )\n\n        self.logs: Dict[str, Any] = {\n            \"batch_num\": 0,\n            \"total_loss\": 0.0,\n            \"total_correct\": 0.0,\n        }\n\n        self.results: Dict[str, Any] = {\n            \"y\": None,\n            \"z\": None,\n            \"probs\": None,\n            \"ids\": [],\n            \"bounds\": None,\n        }\n        self.calc_miou = True if kwargs.get(\"model_type\") == \"segmentation\" else False\n\n        if self.calc_miou:\n            self.logs[\"total_miou\"] = 0.0\n\n        # Allocate memory for the integer values to be recorded.\n        if self.record_int:\n            self.results[\"y\"] = np.empty(\n                (self.n_batches, self.batch_size, *out_shape), dtype=np.uint8\n            )\n            self.results[\"z\"] = np.empty(\n                (self.n_batches, self.batch_size, *out_shape), dtype=np.uint8\n            )\n\n        # Allocate memory for the floating point values to be recorded.\n        if self.record_float:\n            try:\n                self.results[\"probs\"] = np.empty(\n                    (self.n_batches, self.batch_size, n_classes, *out_shape),\n                    dtype=np.float16,\n                )\n            except MemoryError:  # pragma: no cover\n                raise MemoryError(\n                    \"Dataset too large to record probabilities of predicted classes!\"\n                )\n\n            try:\n                self.results[\"bounds\"] = np.empty(\n                    (self.n_batches, self.batch_size), dtype=object\n                )\n            except MemoryError:  # pragma: no cover\n                raise MemoryError(\n                    \"Dataset too large to record bounding boxes of samples!\"\n                )\n\n    def log(\n        self,\n        mode: str,\n        step_num: int,\n        loss: Tensor,\n        z: Optional[Tensor] = None,\n        y: Optional[Tensor] = None,\n        bbox: Optional[BoundingBox] = None,\n        *args,\n        **kwargs,\n    ) -> None:\n        \"\"\"Logs the outputs and results from a step of model fitting. Overwrites abstract method.\n\n        Args:\n            mode (str): Mode of model fitting.\n            step_num (int): The global step number of for the mode of model fitting.\n            loss (Tensor): Loss from this step of model fitting.\n            z (Tensor): Output tensor from the model.\n            y (Tensor): Labels to assess model output against.\n            bbox (BoundingBox): Bounding boxes of the input samples.\n\n        Returns:\n            None\n        \"\"\"\n\n        assert z is not None\n        assert y is not None\n\n        if self.record_int:\n            # Arg max the estimated probabilities and add to predictions.\n            self.results[\"z\"][self.logs[\"batch_num\"]] = torch.argmax(z, 1).cpu().numpy()  # type: ignore[attr-defined]\n\n            # Add the labels and sample IDs to lists.\n            self.results[\"y\"][self.logs[\"batch_num\"]] = y.cpu().numpy()\n            batch_ids = []\n            for i in range(\n                self.logs[\"batch_num\"] * self.batch_size,\n                (self.logs[\"batch_num\"] + 1) * self.batch_size,\n            ):\n                batch_ids.append(str(i).zfill(len(str(self.n_samples))))\n            self.results[\"ids\"].append(batch_ids)\n\n        if self.record_float:\n            assert bbox is not None\n            # Add the estimated probabilities to probs.\n            self.results[\"probs\"][self.logs[\"batch_num\"]] = z.detach().cpu().numpy()\n            self.results[\"bounds\"][self.logs[\"batch_num\"]] = bbox\n\n        # Computes the loss and the correct predictions from this step.\n        ls = loss.item()\n        correct = (torch.argmax(z, 1) == y).sum().item()  # type: ignore[attr-defined]\n\n        # Adds loss and correct predictions to logs.\n        self.logs[\"total_loss\"] += ls\n        self.logs[\"total_correct\"] += correct\n\n        if self.calc_miou:\n            assert y is not None\n            y_true = y.detach().cpu().numpy()\n            y_pred = torch.argmax(z, 1).detach().cpu().numpy()  # type: ignore[attr-defined]\n            miou = 0.0\n            for i in range(len(y)):\n                miou += float(\n                    jaccard_score(\n                        y_true[i].flatten(), y_pred[i].flatten(), average=\"macro\"\n                    )\n                )  # noqa: E501 type: ignore[attr-defined]\n            self.logs[\"total_miou\"] += miou\n\n            self.write_metric(mode, \"miou\", miou / len(y), step_num=step_num)\n\n        # Writes loss and correct predictions to the writer.\n        self.write_metric(mode, \"loss\", ls, step_num=step_num)\n        self.write_metric(\n            mode, \"acc\", correct / len(torch.flatten(y)), step_num=step_num\n        )\n\n        # Adds 1 to batch number (step number).\n        self.logs[\"batch_num\"] += 1\n\n\nclass KNNLogger(MinervaLogger):\n    def __init__(\n        self,\n        n_batches: int,\n        batch_size: int,\n        n_samples: int,\n        record_int: bool = True,\n        record_float: bool = False,\n        writer: Optional[Union[SummaryWriter, Run]] = None,\n        **kwargs,\n    ) -> None:\n        super().__init__(\n            n_batches, batch_size, n_samples, record_int, record_float, writer, **kwargs\n        )\n\n        self.logs: Dict[str, Any] = {\n            \"batch_num\": 0,\n            \"total_loss\": 0.0,\n            \"total_correct\": 0.0,\n            \"total_top5\": 0.0,\n        }\n\n        self.results: Dict[str, Any] = {\n            \"y\": None,\n            \"z\": None,\n            \"probs\": None,\n            \"ids\": [],\n            \"bounds\": None,\n        }\n\n    def log(\n        self,\n        mode: str,\n        step_num: int,\n        loss: Tensor,\n        z: Optional[Tensor] = None,\n        y: Optional[Tensor] = None,\n        bbox: Optional[BoundingBox] = None,\n        *args,\n        **kwargs,\n    ) -> None:\n\n        assert isinstance(z, Tensor)\n        assert isinstance(y, Tensor)\n\n        # Extract loss.\n        ls = loss.item()\n\n        # Calculate the top-1 (standard) accuracy.\n        top1 = torch.sum((z[:, :1] == y.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n\n        # Calculate the top-5 accuracy\n        top5 = torch.sum((z[:, :5] == y.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n\n        # Add results to logs.\n        self.logs[\"total_loss\"] += ls\n        self.logs[\"total_correct\"] += top1\n        self.logs[\"total_top5\"] += top5\n\n        # Write results to the writer.\n        self.write_metric(mode, \"loss\", loss, step_num)\n        self.write_metric(mode, \"acc\", top1, step_num)\n        self.write_metric(mode, \"top5\", top5, step_num)\n\n        # Adds 1 to batch number (step number).\n        self.logs[\"batch_num\"] += 1\n\n\nclass SSLLogger(MinervaLogger):\n    \"\"\"Logger designed for self-supervised learning.\n\n    Args:\n        n_batches (int): Number of batches in the epoch.\n        batch_size (int): Size of the batch.\n        n_samples (int): Total number of samples in the epoch.\n        out_shape (Tuple[int, ...]): Shape of the model output.\n        n_classes (int): Number of classes in dataset.\n        record_int (bool): Optional; Whether to record the integer values from an epoch of model fitting.\n            Defaults to True.\n        record_float (bool): Optional; Whether to record the floating point values from an epoch of model fitting.\n            Defaults to False.\n        writer (Union[SummaryWriter, Run]): Optional; Writer object from :mod:`tensorboard`,\n            a :mod:`wandb` :class:`Run` object or ``None``.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_batches: int,\n        batch_size: int,\n        n_samples: int,\n        out_shape: Optional[Tuple[int, ...]] = None,\n        n_classes: Optional[int] = None,\n        record_int: bool = True,\n        record_float: bool = False,\n        writer: Optional[Union[SummaryWriter, Run]] = None,\n        **kwargs,\n    ) -> None:\n\n        super(SSLLogger, self).__init__(\n            n_batches,\n            batch_size,\n            n_samples,\n            record_int,\n            record_float=record_float,\n            writer=writer,\n        )\n\n        self.logs: Dict[str, Any] = {\n            \"batch_num\": 0,\n            \"total_loss\": 0.0,\n            \"total_correct\": 0.0,\n            \"total_top5\": 0.0,\n            \"avg_loss\": 0.0,\n            \"avg_output_std\": 0.0,\n        }\n\n        self.collapse_level = kwargs.get(\"collapse_level\", False)\n        self.euclidean = kwargs.get(\"euclidean\", False)\n\n        if self.collapse_level:\n            self.logs[\"collapse_level\"] = 0\n        if self.euclidean:\n            self.logs[\"euc_dist\"] = 0\n\n    def log(\n        self,\n        mode: str,\n        step_num: int,\n        loss: Tensor,\n        z: Optional[Tensor] = None,\n        y: Optional[Tensor] = None,\n        bbox: Optional[BoundingBox] = None,\n        *args,\n        **kwargs,\n    ) -> None:\n        \"\"\"Logs the outputs and results from a step of model fitting. Overwrites abstract method.\n\n        Args:\n            mode (str): Mode of model fitting.\n            step_num (int): The global step number of for the mode of model fitting.\n            loss (Tensor): Loss from this step of model fitting.\n            z (Tensor): Optional; Output tensor from the model.\n            y (Tensor): Optional; Labels to assess model output against.\n            bbox (BoundingBox): Optional; Bounding boxes of the input samples.\n        \"\"\"\n        assert z is not None\n\n        # Adds the loss for this step to the logs.\n        ls = loss.item()\n        self.logs[\"total_loss\"] += ls\n\n        # Compute the TOP1 and TOP5 accuracies.\n        sim_argsort = utils.calc_contrastive_acc(z)\n        correct = float((sim_argsort == 0).float().mean().cpu().numpy())\n        top5 = float((sim_argsort < 5).float().mean().cpu().numpy())\n\n        if self.euclidean:\n            z_a, z_b = torch.split(z, int(0.5 * len(z)), 0)\n\n            euc_dists = []\n            for i in range(len(z_a)):\n                euc_dists.append(\n                    utils.calc_norm_euc_dist(\n                        z_a[i].detach().cpu().numpy(), z_b[i].detach().cpu().numpy()\n                    )\n                )\n\n            euc_dist = sum(euc_dists) / len(euc_dists)\n            self.write_metric(mode, \"euc_dist\", euc_dist, step_num)\n            self.logs[\"euc_dist\"] += euc_dist\n\n        if self.collapse_level:\n            # calculate the per-dimension standard deviation of the outputs\n            # we can use this later to check whether the embeddings are collapsing\n            output = torch.split(z, int(0.5 * len(z)), 0)[0].detach()\n            output = torch.nn.functional.normalize(output, dim=1)\n\n            output_std = torch.std(output, 0)  # type: ignore[attr-defined]\n            output_std = output_std.mean()\n\n            # use moving averages to track the loss and standard deviation\n            w = 0.9\n            self.logs[\"avg_loss\"] = w * self.logs[\"avg_loss\"] + (1 - w) * ls\n            self.logs[\"avg_output_std\"] = (\n                w * self.logs[\"avg_output_std\"] + (1 - w) * output_std.item()\n            )\n\n            # the level of collapse is large if the standard deviation of the l2\n            # normalized output is much smaller than 1 / sqrt(dim)\n            collapse_level = max(\n                0.0, 1 - math.sqrt(len(output)) * self.logs[\"avg_output_std\"]\n            )\n\n            self.write_metric(mode, \"collapse_level\", collapse_level, step_num)\n\n            self.logs[\"collapse_level\"] = collapse_level\n\n        # Add accuracies to log.\n        self.logs[\"total_correct\"] += correct\n        self.logs[\"total_top5\"] += top5\n\n        # Writes the loss to the writer.\n        self.write_metric(mode, \"loss\", ls, step_num=step_num)\n        self.write_metric(mode, \"acc\", correct / 2 * len(z[0]), step_num)\n        self.write_metric(mode, \"top5_acc\", top5 / 2 * len(z[0]), step_num)\n\n        # Adds 1 to the batch number (step number).\n        self.logs[\"batch_num\"] += 1\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 20612,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Module to handle the logging of results from various model types.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"MinervaLogger\",\n    \"STGLogger\",\n    \"SSLLogger\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport abc\nimport math\nfrom abc import ABC\nfrom typing import Any, Dict, Optional, SupportsFloat, Tuple, Union\n\nimport mlflow\nimport numpy as np\nimport torch\nfrom sklearn.metrics import jaccard_score\nfrom torch import Tensor\nfrom torch.utils.tensorboard.writer import SummaryWriter\nfrom torchgeo.datasets.utils import BoundingBox\nfrom wandb.sdk.wandb_run import Run\n\nfrom minerva.utils import utils\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass MinervaLogger(ABC):\n    \"\"\"Base abstract class for all `minerva` logger classes to ensure intercompatibility with `trainer`.\n\n    Attributes:\n        record_int (bool): Whether to record the integer values from an epoch of model fitting.\n        record_float (bool): Whether to record the floating point values from an epoch of model fitting.\n        n_batches (int): Number of batches in the epoch.\n        batch_size (int): Size of the batch.\n        n_samples (int): Total number of samples in the epoch.\n        logs (Dict[str, Any]): Dictionary to hold the logs from the epoch.\n            Logs should be more lightweight than `results`.\n        results (Dict[str, Any]): Dictionary to hold the results from the epoch.\n\n    Args:\n        n_batches (int): Number of batches in the epoch.\n        batch_size (int): Size of the batch.\n        n_samples (int): Total number of samples in the epoch.\n        record_int (bool): Optional; Whether to record the integer values from an epoch of model fitting.\n            Defaults to ``True``.\n        record_float (bool): Optional; Whether to record the floating point values from an epoch of model fitting.\n            Defaults to ``False``.\n        writer (Union[SummaryWriter, Run]): Optional; Writer object from :mod:`tensorboard`,\n            a :mod:`wandb` :class:`Run` object or ``None``.\n    \"\"\"\n\n    __metaclass__ = abc.ABCMeta\n\n    def __init__(\n        self,\n        n_batches: int,\n        batch_size: int,\n        n_samples: int,\n        record_int: bool = True,\n        record_float: bool = False,\n        writer: Optional[Union[SummaryWriter, Run]] = None,\n        **kwargs,\n    ) -> None:\n\n        super(MinervaLogger, self).__init__()\n        self.record_int = record_int\n        self.record_float = record_float\n        self.n_batches = n_batches\n        self.batch_size = batch_size\n        self.n_samples = n_samples\n        self.writer = writer\n\n        self.logs: Dict[str, Any] = {}\n        self.results: Dict[str, Any] = {}\n\n    def __call__(self, mode: str, step_num: int, loss: Tensor, *args) -> None:\n        \"\"\"Call :func:`log`.\n\n        Args:\n            mode (str): Mode of model fitting.\n            step_num (int): The global step number of for the mode of model fitting.\n            loss (Tensor): Loss from this step of model fitting.\n\n        Returns:\n            None\n        \"\"\"\n        self.log(mode, step_num, loss, *args)\n\n    @abc.abstractmethod\n    def log(\n        self,\n        mode: str,\n        step_num: int,\n        loss: Tensor,\n        z: Optional[Tensor] = None,\n        y: Optional[Tensor] = None,\n        bbox: Optional[BoundingBox] = None,\n        *args,\n        **kwargs,\n    ) -> None:\n        \"\"\"Abstract logging method, the core functionality of a logger. Must be overwritten.\n\n        Args:\n            mode (str): Mode of model fitting.\n            step_num (int): The global step number of for the mode of model fitting.\n            loss (Tensor): Loss from this step of model fitting.\n            z (Tensor): Optional; Output tensor from the model.\n            y (Tensor): Optional; Labels to assess model output against.\n            bbox (BoundingBox): Optional; Bounding boxes of the input samples.\n\n        Returns:\n            None\n        \"\"\"\n        pass  # pragma: no cover\n\n    def write_metric(\n        self, mode: str, key: str, value: SupportsFloat, step_num: Optional[int] = None\n    ):\n        \"\"\"Write metric values to logging backends after calculation\"\"\"\n        # TODO: Are values being reduced across nodes / logged from rank 0?\n        if self.writer:\n            if isinstance(self.writer, SummaryWriter):\n                self.writer.add_scalar(\n                    tag=f\"{mode}_{key}\",\n                    scalar_value=value,  # type: ignore[attr-defined]\n                    global_step=step_num,\n                )\n            elif isinstance(self.writer, Run):\n                self.writer.log({f\"{mode}/step\": step_num, f\"{mode}/{key}\": value})\n\n        if mlflow.active_run():\n            # If running in Azure Machine Learning, tracking URI / experiment ID set already\n            # https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow-cli-runs?tabs=python%2Cmlflow#creating-a-training-routine  # noqa: E501\n            mlflow.log_metric(key, value)  # pragma: no cover\n\n    @property\n    def get_logs(self) -> Dict[str, Any]:\n        \"\"\"Gets the logs dictionary.\n\n        Returns:\n            Dict[str, Any]: Log dictionary of the logger.\n        \"\"\"\n        return self.logs\n\n    @property\n    def get_results(self) -> Dict[str, Any]:\n        \"\"\"Gets the results dictionary.\n\n        Returns:\n            Dict[str,Any]: Results dictionary of the logger.\n        \"\"\"\n        return self.results\n\n\nclass STGLogger(MinervaLogger):\n    \"\"\"Logger designed for supervised learning using `torchgeo` datasets.\n\n    Args:\n        n_batches (int): Number of batches in the epoch.\n        batch_size (int): Size of the batch.\n        n_samples (int): Total number of samples in the epoch.\n        out_shape (Tuple[int, ...]): Shape of the model output.\n        n_classes (int): Number of classes in dataset.\n        record_int (bool): Optional; Whether to record the integer values from an epoch of model fitting.\n            Defaults to True.\n        record_float (bool): Optional; Whether to record the floating point values from an epoch of model fitting.\n            Defaults to False.\n        writer (Union[SummaryWriter, Run]): Optional; Writer object from :mod:`tensorboard`,\n            a :mod:`wandb` :class:`Run` object or ``None``.\n\n    Raises:\n        MemoryError: If trying to allocate memory to hold the probabilites of predictions\n            from the model exceeds capacity.\n        MemoryError: If trying to allocate memory to hold the bounding boxes of samples would exceed capacity.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_batches: int,\n        batch_size: int,\n        n_samples: int,\n        out_shape: Tuple[int, ...],\n        n_classes: int,\n        record_int: bool = True,\n        record_float: bool = False,\n        writer: Optional[Union[SummaryWriter, Run]] = None,\n        **kwargs,\n    ) -> None:\n\n        super(STGLogger, self).__init__(\n            n_batches,\n            batch_size,\n            n_samples,\n            record_int,\n            record_float,\n            writer,\n        )\n\n        self.logs: Dict[str, Any] = {\n            \"batch_num\": 0,\n            \"total_loss\": 0.0,\n            \"total_correct\": 0.0,\n        }\n\n        self.results: Dict[str, Any] = {\n            \"y\": None,\n            \"z\": None,\n            \"probs\": None,\n            \"ids\": [],\n            \"bounds\": None,\n        }\n        self.calc_miou = True if kwargs.get(\"model_type\") == \"segmentation\" else False\n\n        if self.calc_miou:\n            self.logs[\"total_miou\"] = 0.0\n\n        # Allocate memory for the integer values to be recorded.\n        if self.record_int:\n            self.results[\"y\"] = np.empty(\n                (self.n_batches, self.batch_size, *out_shape), dtype=np.uint8\n            )\n            self.results[\"z\"] = np.empty(\n                (self.n_batches, self.batch_size, *out_shape), dtype=np.uint8\n            )\n\n        # Allocate memory for the floating point values to be recorded.\n        if self.record_float:\n            try:\n                self.results[\"probs\"] = np.empty(\n                    (self.n_batches, self.batch_size, n_classes, *out_shape),\n                    dtype=np.float16,\n                )\n            except MemoryError:  # pragma: no cover\n                raise MemoryError(\n                    \"Dataset too large to record probabilities of predicted classes!\"\n                )\n\n            try:\n                self.results[\"bounds\"] = np.empty(\n                    (self.n_batches, self.batch_size), dtype=object\n                )\n            except MemoryError:  # pragma: no cover\n                raise MemoryError(\n                    \"Dataset too large to record bounding boxes of samples!\"\n                )\n\n    def log(\n        self,\n        mode: str,\n        step_num: int,\n        loss: Tensor,\n        z: Optional[Tensor] = None,\n        y: Optional[Tensor] = None,\n        bbox: Optional[BoundingBox] = None,\n        *args,\n        **kwargs,\n    ) -> None:\n        \"\"\"Logs the outputs and results from a step of model fitting. Overwrites abstract method.\n\n        Args:\n            mode (str): Mode of model fitting.\n            step_num (int): The global step number of for the mode of model fitting.\n            loss (Tensor): Loss from this step of model fitting.\n            z (Tensor): Output tensor from the model.\n            y (Tensor): Labels to assess model output against.\n            bbox (BoundingBox): Bounding boxes of the input samples.\n\n        Returns:\n            None\n        \"\"\"\n\n        assert z is not None\n        assert y is not None\n\n        if self.record_int:\n            # Arg max the estimated probabilities and add to predictions.\n            self.results[\"z\"][self.logs[\"batch_num\"]] = torch.argmax(z, 1).cpu().numpy()  # type: ignore[attr-defined]\n\n            # Add the labels and sample IDs to lists.\n            self.results[\"y\"][self.logs[\"batch_num\"]] = y.cpu().numpy()\n            batch_ids = []\n            for i in range(\n                self.logs[\"batch_num\"] * self.batch_size,\n                (self.logs[\"batch_num\"] + 1) * self.batch_size,\n            ):\n                batch_ids.append(str(i).zfill(len(str(self.n_samples))))\n            self.results[\"ids\"].append(batch_ids)\n\n        if self.record_float:\n            assert bbox is not None\n            # Add the estimated probabilities to probs.\n            self.results[\"probs\"][self.logs[\"batch_num\"]] = z.detach().cpu().numpy()\n            self.results[\"bounds\"][self.logs[\"batch_num\"]] = bbox\n\n        # Computes the loss and the correct predictions from this step.\n        ls = loss.item()\n        correct = (torch.argmax(z, 1) == y).sum().item()  # type: ignore[attr-defined]\n\n        # Adds loss and correct predictions to logs.\n        self.logs[\"total_loss\"] += ls\n        self.logs[\"total_correct\"] += correct\n\n        if self.calc_miou:\n            assert y is not None\n            y_true = y.detach().cpu().numpy()\n            y_pred = torch.argmax(z, 1).detach().cpu().numpy()  # type: ignore[attr-defined]\n            miou = 0.0\n            for i in range(len(y)):\n                miou += float(\n                    jaccard_score(\n                        y_true[i].flatten(), y_pred[i].flatten(), average=\"macro\"\n                    )\n                )  # noqa: E501 type: ignore[attr-defined]\n            self.logs[\"total_miou\"] += miou\n\n            self.write_metric(mode, \"miou\", miou / len(y), step_num=step_num)\n\n        # Writes loss and correct predictions to the writer.\n        self.write_metric(mode, \"loss\", ls, step_num=step_num)\n        self.write_metric(\n            mode, \"acc\", correct / len(torch.flatten(y)), step_num=step_num\n        )\n\n        # Adds 1 to batch number (step number).\n        self.logs[\"batch_num\"] += 1\n\n\nclass KNNLogger(MinervaLogger):\n    def __init__(\n        self,\n        n_batches: int,\n        batch_size: int,\n        n_samples: int,\n        record_int: bool = True,\n        record_float: bool = False,\n        writer: Optional[Union[SummaryWriter, Run]] = None,\n        **kwargs,\n    ) -> None:\n        super().__init__(\n            n_batches, batch_size, n_samples, record_int, record_float, writer, **kwargs\n        )\n\n        self.logs: Dict[str, Any] = {\n            \"batch_num\": 0,\n            \"total_loss\": 0.0,\n            \"total_correct\": 0.0,\n            \"total_top5\": 0.0,\n        }\n\n        self.results: Dict[str, Any] = {\n            \"y\": None,\n            \"z\": None,\n            \"probs\": None,\n            \"ids\": [],\n            \"bounds\": None,\n        }\n\n    def log(\n        self,\n        mode: str,\n        step_num: int,\n        loss: Tensor,\n        z: Optional[Tensor] = None,\n        y: Optional[Tensor] = None,\n        bbox: Optional[BoundingBox] = None,\n        *args,\n        **kwargs,\n    ) -> None:\n\n        assert isinstance(z, Tensor)\n        assert isinstance(y, Tensor)\n\n        # Extract loss.\n        ls = loss.item()\n\n        # Calculate the top-1 (standard) accuracy.\n        top1 = torch.sum((z[:, :1] == y.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n\n        # Calculate the top-5 accuracy\n        top5 = torch.sum((z[:, :5] == y.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n\n        # Add results to logs.\n        self.logs[\"total_loss\"] += ls\n        self.logs[\"total_correct\"] += top1\n        self.logs[\"total_top5\"] += top5\n\n        # Write results to the writer.\n        self.write_metric(mode, \"loss\", loss, step_num)\n        self.write_metric(mode, \"acc\", top1, step_num)\n        self.write_metric(mode, \"top5\", top5, step_num)\n\n        # Adds 1 to batch number (step number).\n        self.logs[\"batch_num\"] += 1\n\n\nclass SSLLogger(MinervaLogger):\n    \"\"\"Logger designed for self-supervised learning.\n\n    Args:\n        n_batches (int): Number of batches in the epoch.\n        batch_size (int): Size of the batch.\n        n_samples (int): Total number of samples in the epoch.\n        out_shape (Tuple[int, ...]): Shape of the model output.\n        n_classes (int): Number of classes in dataset.\n        record_int (bool): Optional; Whether to record the integer values from an epoch of model fitting.\n            Defaults to True.\n        record_float (bool): Optional; Whether to record the floating point values from an epoch of model fitting.\n            Defaults to False.\n        writer (Union[SummaryWriter, Run]): Optional; Writer object from :mod:`tensorboard`,\n            a :mod:`wandb` :class:`Run` object or ``None``.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_batches: int,\n        batch_size: int,\n        n_samples: int,\n        out_shape: Optional[Tuple[int, ...]] = None,\n        n_classes: Optional[int] = None,\n        record_int: bool = True,\n        record_float: bool = False,\n        writer: Optional[Union[SummaryWriter, Run]] = None,\n        **kwargs,\n    ) -> None:\n\n        super(SSLLogger, self).__init__(\n            n_batches,\n            batch_size,\n            n_samples,\n            record_int,\n            record_float=record_float,\n            writer=writer,\n        )\n\n        self.logs: Dict[str, Any] = {\n            \"batch_num\": 0,\n            \"total_loss\": 0.0,\n            \"total_correct\": 0.0,\n            \"total_top5\": 0.0,\n            \"avg_loss\": 0.0,\n            \"avg_output_std\": 0.0,\n        }\n\n        self.collapse_level = kwargs.get(\"collapse_level\", False)\n        self.euclidean = kwargs.get(\"euclidean\", False)\n\n        if self.collapse_level:\n            self.logs[\"collapse_level\"] = 0\n        if self.euclidean:\n            self.logs[\"euc_dist\"] = 0\n\n    def log(\n        self,\n        mode: str,\n        step_num: int,\n        loss: Tensor,\n        z: Optional[Tensor] = None,\n        y: Optional[Tensor] = None,\n        bbox: Optional[BoundingBox] = None,\n        *args,\n        **kwargs,\n    ) -> None:\n        \"\"\"Logs the outputs and results from a step of model fitting. Overwrites abstract method.\n\n        Args:\n            mode (str): Mode of model fitting.\n            step_num (int): The global step number of for the mode of model fitting.\n            loss (Tensor): Loss from this step of model fitting.\n            z (Tensor): Optional; Output tensor from the model.\n            y (Tensor): Optional; Labels to assess model output against.\n            bbox (BoundingBox): Optional; Bounding boxes of the input samples.\n        \"\"\"\n        assert z is not None\n\n        # Adds the loss for this step to the logs.\n        ls = loss.item()\n        self.logs[\"total_loss\"] += ls\n\n        # Compute the TOP1 and TOP5 accuracies.\n        sim_argsort = utils.calc_contrastive_acc(z)\n        correct = float((sim_argsort == 0).float().mean().cpu().numpy())\n        top5 = float((sim_argsort < 5).float().mean().cpu().numpy())\n\n        if self.euclidean:\n            z_a, z_b = torch.split(z, int(0.5 * len(z)), 0)\n\n            euc_dists = []\n            for i in range(len(z_a)):\n                euc_dists.append(\n                    utils.calc_norm_euc_dist(\n                        z_a[i].detach().cpu().numpy(), z_b[i].detach().cpu().numpy()\n                    )\n                )\n\n            euc_dist = sum(euc_dists) / len(euc_dists)\n            self.write_metric(mode, \"euc_dist\", euc_dist, step_num)\n            self.logs[\"euc_dist\"] += euc_dist\n\n        if self.collapse_level:\n            # calculate the per-dimension standard deviation of the outputs\n            # we can use this later to check whether the embeddings are collapsing\n            output = torch.split(z, int(0.5 * len(z)), 0)[0].detach()\n            output = torch.nn.functional.normalize(output, dim=1)\n\n            output_std = torch.std(output, 0)  # type: ignore[attr-defined]\n            output_std = output_std.mean()\n\n            # use moving averages to track the loss and standard deviation\n            w = 0.9\n            self.logs[\"avg_loss\"] = w * self.logs[\"avg_loss\"] + (1 - w) * ls\n            self.logs[\"avg_output_std\"] = (\n                w * self.logs[\"avg_output_std\"] + (1 - w) * output_std.item()\n            )\n\n            # the level of collapse is large if the standard deviation of the l2\n            # normalized output is much smaller than 1 / sqrt(dim)\n            collapse_level = max(\n                0.0, 1 - math.sqrt(len(output)) * self.logs[\"avg_output_std\"]\n            )\n\n            self.write_metric(mode, \"collapse_level\", collapse_level, step_num)\n\n            self.logs[\"collapse_level\"] = collapse_level\n\n        # Add accuracies to log.\n        self.logs[\"total_correct\"] += correct\n        self.logs[\"total_top5\"] += top5\n\n        # Writes the loss to the writer.\n        self.write_metric(mode, \"loss\", ls, step_num=step_num)\n        self.write_metric(mode, \"acc\", correct / 2 * len(z[0]), step_num)\n        self.write_metric(mode, \"top5_acc\", top5 / 2 * len(z[0]), step_num)\n\n        # Adds 1 to the batch number (step number).\n        self.logs[\"batch_num\"] += 1\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "0bbcec6d1e2fed143d26eb213c65e357c154bab06eb2da74ceb0fa6b95b1d5db"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/models/core.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 14959,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n#\n\"\"\"Module containing core utility functions and abstract classes for models.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n__all__ = [\n    \"MinervaModel\",\n    \"MinervaDataParallel\",\n    \"MinervaBackbone\",\n    \"MinervaOnnxModel\",\n    \"get_model\",\n    \"get_torch_weights\",\n    \"get_output_shape\",\n    \"bilinear_init\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport abc\nimport os\nfrom abc import ABC\nfrom pathlib import Path\nfrom typing import (\n    Any,\n    Callable,\n    Iterable,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n    overload,\n)\n\nimport numpy as np\nimport torch\nfrom nptyping import NDArray\nfrom torch import Tensor\nfrom torch.nn.modules import Module\nfrom torch.nn.parallel import DataParallel, DistributedDataParallel\nfrom torch.optim import Optimizer\nfrom torchvision.models._api import WeightsEnum\n\nfrom minerva.utils.utils import func_by_str\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass MinervaModel(Module, ABC):\n    \"\"\"Abstract class to act as a base for all Minerva Models.\n\n    Designed to provide inter-compatability with :class:`Trainer`.\n\n    Attributes:\n        criterion (Module): PyTorch loss function model will use.\n        input_shape (tuple[int, int, int] or list[int]): The shape of the input data in order of\n            number of channels, image width, image height.\n        n_classes (int): Number of classes in input data.\n        output_shape: The shape of the output of the network. Determined and set by determine_output_dim.\n        optimiser: PyTorch optimiser model will use, to be initialised with inherited model's parameters.\n\n    Args:\n        criterion (Module): Optional; PyTorch loss function model will use.\n        input_shape (tuple[int, int, int] or list[int]): Optional; Defines the shape of the input data in order of\n            number of channels, image width, image height.\n        n_classes (int): Optional; Number of classes in input data.\n    \"\"\"\n\n    __metaclass__ = abc.ABCMeta\n\n    def __init__(\n        self,\n        criterion: Optional[Module] = None,\n        input_size: Optional[Tuple[int, ...]] = None,\n        n_classes: Optional[int] = None,\n    ) -> None:\n\n        super(MinervaModel, self).__init__()\n\n        # Sets loss function\n        self.criterion: Optional[Module] = criterion\n\n        self.input_size = input_size\n        self.n_classes = n_classes\n\n        # Output shape initialised as None. Should be set by calling determine_output_dim.\n        self.output_shape: Optional[Union[int, Iterable[int]]] = None\n\n        # Optimiser initialised as None as the model parameters created by its init is required to init a\n        # torch optimiser. The optimiser MUST be set by calling set_optimiser before the model can be trained.\n        self.optimiser: Optional[Optimizer] = None\n\n    def set_optimiser(self, optimiser: Optimizer) -> None:\n        \"\"\"Sets the optimiser used by the model.\n\n        .. warning::\n            *MUST* be called after initialising a model and supplied with a PyTorch optimiser\n            using this model's parameters.\n\n        Args:\n            optimiser (Optimizer): PyTorch optimiser model will use, initialised with this model's parameters.\n        \"\"\"\n        self.optimiser = optimiser\n\n    def determine_output_dim(self, sample_pairs: bool = False) -> None:\n        \"\"\"Uses get_output_shape to find the dimensions of the output of this model and sets to attribute.\"\"\"\n\n        assert self.input_size is not None\n\n        self.output_shape = get_output_shape(\n            self, self.input_size, sample_pairs=sample_pairs\n        )\n\n    @overload\n    def step(\n        self, x: Tensor, y: Tensor, train: bool = False\n    ) -> Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]]]:\n        ...  # pragma: no cover\n\n    @overload\n    def step(\n        self, x: Tensor, *, train: bool = False\n    ) -> Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]]]:\n        ...  # pragma: no cover\n\n    def step(\n        self,\n        x: Tensor,\n        y: Optional[Tensor] = None,\n        train: bool = False,\n    ) -> Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]]]:\n        \"\"\"Generic step of model fitting using a batch of data.\n\n        Raises:\n            NotImplementedError: If ``self.optimiser`` is None.\n            NotImplementedError: If ``self.criterion`` is None.\n\n        Args:\n            x (Tensor): Batch of input data to network.\n            y (Tensor): Either a batch of ground truth labels or generated labels/ pairs.\n            train (bool): Sets whether this shall be a training step or not. True for training step which will then\n                clear the optimiser, and perform a backward pass of the network then update the optimiser.\n                If False for a validation or testing step, these actions are not taken.\n\n        Returns:\n            Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]]]: Tuple of the loss computed by the loss function\n            and the model outputs.\n        \"\"\"\n\n        if self.optimiser is None:\n            raise NotImplementedError(\"Optimiser has not been set!\")\n\n        if self.criterion is None:\n            raise NotImplementedError(\"Criterion has not been set!\")\n\n        # Resets the optimiser's gradients if this is a training step.\n        if train:\n            self.optimiser.zero_grad()\n\n        # Forward pass.\n        z: Union[Tensor, Tuple[Tensor, ...]] = self.forward(x)\n\n        # Compute Loss.\n        loss: Tensor = self.criterion(z, y)\n\n        # Performs a backward pass if this is a training step.\n        if train:\n            loss.backward()\n            self.optimiser.step()\n\n        return loss, z\n\n\nclass MinervaBackbone(MinervaModel):\n    \"\"\"Abstract class to mark a model for use as a backbone.\"\"\"\n\n    __metaclass__ = abc.ABCMeta\n\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n\n        self.backbone: MinervaModel\n\n    def get_backbone(self) -> Module:\n        \"\"\"Gets the backbone network of the model.\n        Returns:\n            Module: The backbone of the model.\n        \"\"\"\n        return self.backbone\n\n\nclass MinervaDataParallel(Module):\n    \"\"\"Custom wrapper for DataParallel that automatically fetches the attributes of the wrapped model.\n\n    Attributes:\n        model (Module): PyTorch Model to be wrapped by :class:`DataParallel`.\n        paralleliser (Union[DataParallel, DistributedDataParallel]): The paralleliser to wrap the model in.\n\n    Args:\n        model (Module): PyTorch Model to be wrapped by :class:`DataParallel`.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: Module,\n        paralleliser: Union[Type[DataParallel], Type[DistributedDataParallel]],\n        *args,\n        **kwargs,\n    ) -> None:\n        super(MinervaDataParallel, self).__init__()\n        self.model = paralleliser(model, *args, **kwargs).cuda()\n\n    def forward(self, *input: Tuple[Tensor, ...]) -> Tuple[Tensor, ...]:\n        \"\"\"Ensures a forward call to the model goes to the actual wrapped model.\n\n        Args:\n            input (Tuple[Tensor, ...]): Input of tensors to be parsed to the model forward.\n\n        Returns:\n            Tuple[Tensor, ...]: Output of model.\n        \"\"\"\n        z = self.model(*input)\n        assert isinstance(z, tuple) and list(map(type, z)) == [Tensor] * len(z)\n        return z\n\n    def __call__(self, *input):\n        return self.model(*input)\n\n    def __getattr__(self, name):\n        try:\n            return super().__getattr__(name)\n        except AttributeError:\n            return getattr(self.model.module, name)\n\n    def __repr__(self) -> Any:\n        return self.model.__repr__()\n\n\nclass MinervaOnnxModel(MinervaModel):\n    \"\"\"Special model class for enabling :mod:`onnx` models to be used within :mod:`minerva`.\n\n    Attributes:\n        model (Module): :mod:`onnx` model imported into :mod:`torch`.\n\n    Args:\n        model (Module): :mod:`onnx` model imported into :mod:`torch`.\n    \"\"\"\n\n    def __init__(self, model: Module, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n\n        self.model = model\n\n    def __call__(self, *input) -> Any:\n        return self.model.forward(*input)\n\n    def __getattr__(self, name) -> Any:\n        try:\n            return super().__getattr__(name)\n        except AttributeError:\n            return getattr(self.model, name)\n\n    def __repr__(self) -> Any:\n        return self.model.__repr__()\n\n    def forward(self, *input: Any) -> Any:\n        \"\"\"Performs a forward pass of the ``model`` within.\n\n        Args:\n            input (Any): Input to be parsed to ``model.forward``.\n\n        Returns:\n            Any: Output of model.\n        \"\"\"\n        return self.model.forward(*input)\n\n\n# =====================================================================================================================\n#                                                     METHODS\n# =====================================================================================================================\ndef get_model(model_name: str) -> Callable[..., MinervaModel]:\n    \"\"\"Returns the constructor of the ``model_name`` in :mod:`models`.\n\n    Args:\n        model_name (str): Name of the model to get.\n\n    Returns:\n        Callable[..., MinervaModel]: Constructor of the model requested.\n    \"\"\"\n    model: Callable[..., MinervaModel] = func_by_str(\"minerva.models\", model_name)\n    return model\n\n\ndef get_torch_weights(weights_name: str) -> Optional[WeightsEnum]:\n    \"\"\"Loads pre-trained model weights from ``torchvision`` via Torch Hub API.\n\n    Args:\n        weights_name (str): Name of model weights. See ... for a list of possible pre-trained weights.\n\n    Returns:\n        Optional[WeightsEnum]: API query for the specified weights. None if query cannot be found. See note on use:\n\n    Note:\n        This function only returns a query for the API of the weights. To actually use them, you need to call\n        ``get_state_dict(progress)`` where progress is a ``bool`` on whether to show a progress bar for the\n        downloading of the weights (if not already in cache).\n    \"\"\"\n    weights: Optional[WeightsEnum] = None\n    try:\n        weights = torch.hub.load(\"pytorch/vision\", \"get_weight\", name=weights_name)\n    except OSError:\n        th_dir = os.environ.get(\"TORCH_HUB\", Path(\"~/.cache/torch/hub\").expanduser())\n        try:\n            weights = torch.hub.load(\n                f\"{th_dir}/pytorch_vision_main\",\n                \"get_weight\",\n                name=weights_name,\n                source=\"local\",\n            )\n        except FileNotFoundError as err:  # pragma: no cover\n            print(err)\n            weights = None\n\n    return weights\n\n\ndef get_output_shape(\n    model: Module,\n    image_dim: Union[Sequence[int], int],\n    sample_pairs: bool = False,\n) -> Union[int, Sequence[int]]:\n    \"\"\"Gets the output shape of a model.\n\n    Args:\n        model (Module): Model for which the shape of the output needs to be found.\n        image_dim (Union[Sequence[int], int]): Expected shape of the input data to the model.\n        sample_pairs (bool): Optional; Flag for if paired sampling is active.\n            Will send a paired sample through the model.\n\n    Returns:\n        The shape of the output data from the model.\n    \"\"\"\n    _image_dim: Union[Sequence[int], int] = image_dim\n    try:\n        assert not isinstance(image_dim, int)\n        if len(image_dim) == 1:\n            _image_dim = image_dim[0]\n    except (AssertionError, TypeError):\n        if not hasattr(image_dim, \"__len__\"):\n            pass\n\n    if not hasattr(_image_dim, \"__len__\"):\n        assert isinstance(_image_dim, int)\n        random_input = torch.rand([4, _image_dim])\n    elif sample_pairs:\n        assert isinstance(_image_dim, Iterable)\n        random_input = torch.rand([2, 4, *_image_dim])\n    else:\n        assert isinstance(_image_dim, Iterable)\n        random_input = torch.rand([4, *_image_dim])\n\n    output: Tensor = model(random_input)\n\n    if len(output[0].data.shape) == 1:\n        return output[0].data.shape[0]\n\n    else:\n        return output[0].data.shape[1:]\n\n\ndef bilinear_init(in_channels: int, out_channels: int, kernel_size: int) -> Tensor:\n    \"\"\"Constructs the weights for the bi-linear interpolation kernel for use in transpose convolutional layers.\n\n    Source: https://github.com/haoran1062/FCN-pytorch/blob/master/FCN.py\n\n    Args:\n        in_channels (int): Number of input channels to the layer.\n        out_channels (int): Number of output channels from the layer.\n        kernel_size (int): Size of the (square) kernel.\n\n    Returns:\n        Tensor of the initialised bi-linear interpolated weights for the transpose convolutional layer's kernels.\n    \"\"\"\n    factor = (kernel_size + 1) // 2\n\n    if kernel_size % 2 == 1:\n        center = factor - 1\n    else:\n        center = int(factor - 0.5)\n\n    og = np.ogrid[:kernel_size, :kernel_size]\n    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n    weight: NDArray[Any, Any] = np.zeros(\n        (in_channels, out_channels, kernel_size, kernel_size), dtype=\"float32\"\n    )\n    weight[range(in_channels), range(out_channels), :, :] = filt\n\n    weights = torch.from_numpy(weight)  # type: ignore[attr-defined]\n    assert isinstance(weights, Tensor)\n    return weights\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 14959,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n#\n\"\"\"Module containing core utility functions and abstract classes for models.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n__all__ = [\n    \"MinervaModel\",\n    \"MinervaDataParallel\",\n    \"MinervaBackbone\",\n    \"MinervaOnnxModel\",\n    \"get_model\",\n    \"get_torch_weights\",\n    \"get_output_shape\",\n    \"bilinear_init\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport abc\nimport os\nfrom abc import ABC\nfrom pathlib import Path\nfrom typing import (\n    Any,\n    Callable,\n    Iterable,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n    overload,\n)\n\nimport numpy as np\nimport torch\nfrom nptyping import NDArray\nfrom torch import Tensor\nfrom torch.nn.modules import Module\nfrom torch.nn.parallel import DataParallel, DistributedDataParallel\nfrom torch.optim import Optimizer\nfrom torchvision.models._api import WeightsEnum\n\nfrom minerva.utils.utils import func_by_str\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass MinervaModel(Module, ABC):\n    \"\"\"Abstract class to act as a base for all Minerva Models.\n\n    Designed to provide inter-compatability with :class:`Trainer`.\n\n    Attributes:\n        criterion (Module): PyTorch loss function model will use.\n        input_shape (tuple[int, int, int] or list[int]): The shape of the input data in order of\n            number of channels, image width, image height.\n        n_classes (int): Number of classes in input data.\n        output_shape: The shape of the output of the network. Determined and set by determine_output_dim.\n        optimiser: PyTorch optimiser model will use, to be initialised with inherited model's parameters.\n\n    Args:\n        criterion (Module): Optional; PyTorch loss function model will use.\n        input_shape (tuple[int, int, int] or list[int]): Optional; Defines the shape of the input data in order of\n            number of channels, image width, image height.\n        n_classes (int): Optional; Number of classes in input data.\n    \"\"\"\n\n    __metaclass__ = abc.ABCMeta\n\n    def __init__(\n        self,\n        criterion: Optional[Module] = None,\n        input_size: Optional[Tuple[int, ...]] = None,\n        n_classes: Optional[int] = None,\n    ) -> None:\n\n        super(MinervaModel, self).__init__()\n\n        # Sets loss function\n        self.criterion: Optional[Module] = criterion\n\n        self.input_size = input_size\n        self.n_classes = n_classes\n\n        # Output shape initialised as None. Should be set by calling determine_output_dim.\n        self.output_shape: Optional[Union[int, Iterable[int]]] = None\n\n        # Optimiser initialised as None as the model parameters created by its init is required to init a\n        # torch optimiser. The optimiser MUST be set by calling set_optimiser before the model can be trained.\n        self.optimiser: Optional[Optimizer] = None\n\n    def set_optimiser(self, optimiser: Optimizer) -> None:\n        \"\"\"Sets the optimiser used by the model.\n\n        .. warning::\n            *MUST* be called after initialising a model and supplied with a PyTorch optimiser\n            using this model's parameters.\n\n        Args:\n            optimiser (Optimizer): PyTorch optimiser model will use, initialised with this model's parameters.\n        \"\"\"\n        self.optimiser = optimiser\n\n    def determine_output_dim(self, sample_pairs: bool = False) -> None:\n        \"\"\"Uses get_output_shape to find the dimensions of the output of this model and sets to attribute.\"\"\"\n\n        assert self.input_size is not None\n\n        self.output_shape = get_output_shape(\n            self, self.input_size, sample_pairs=sample_pairs\n        )\n\n    @overload\n    def step(\n        self, x: Tensor, y: Tensor, train: bool = False\n    ) -> Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]]]:\n        ...  # pragma: no cover\n\n    @overload\n    def step(\n        self, x: Tensor, *, train: bool = False\n    ) -> Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]]]:\n        ...  # pragma: no cover\n\n    def step(\n        self,\n        x: Tensor,\n        y: Optional[Tensor] = None,\n        train: bool = False,\n    ) -> Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]]]:\n        \"\"\"Generic step of model fitting using a batch of data.\n\n        Raises:\n            NotImplementedError: If ``self.optimiser`` is None.\n            NotImplementedError: If ``self.criterion`` is None.\n\n        Args:\n            x (Tensor): Batch of input data to network.\n            y (Tensor): Either a batch of ground truth labels or generated labels/ pairs.\n            train (bool): Sets whether this shall be a training step or not. True for training step which will then\n                clear the optimiser, and perform a backward pass of the network then update the optimiser.\n                If False for a validation or testing step, these actions are not taken.\n\n        Returns:\n            Tuple[Tensor, Union[Tensor, Tuple[Tensor, ...]]]: Tuple of the loss computed by the loss function\n            and the model outputs.\n        \"\"\"\n\n        if self.optimiser is None:\n            raise NotImplementedError(\"Optimiser has not been set!\")\n\n        if self.criterion is None:\n            raise NotImplementedError(\"Criterion has not been set!\")\n\n        # Resets the optimiser's gradients if this is a training step.\n        if train:\n            self.optimiser.zero_grad()\n\n        # Forward pass.\n        z: Union[Tensor, Tuple[Tensor, ...]] = self.forward(x)\n\n        # Compute Loss.\n        loss: Tensor = self.criterion(z, y)\n\n        # Performs a backward pass if this is a training step.\n        if train:\n            loss.backward()\n            self.optimiser.step()\n\n        return loss, z\n\n\nclass MinervaBackbone(MinervaModel):\n    \"\"\"Abstract class to mark a model for use as a backbone.\"\"\"\n\n    __metaclass__ = abc.ABCMeta\n\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n\n        self.backbone: MinervaModel\n\n    def get_backbone(self) -> Module:\n        \"\"\"Gets the backbone network of the model.\n        Returns:\n            Module: The backbone of the model.\n        \"\"\"\n        return self.backbone\n\n\nclass MinervaDataParallel(Module):\n    \"\"\"Custom wrapper for DataParallel that automatically fetches the attributes of the wrapped model.\n\n    Attributes:\n        model (Module): PyTorch Model to be wrapped by :class:`DataParallel`.\n        paralleliser (Union[DataParallel, DistributedDataParallel]): The paralleliser to wrap the model in.\n\n    Args:\n        model (Module): PyTorch Model to be wrapped by :class:`DataParallel`.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: Module,\n        paralleliser: Union[Type[DataParallel], Type[DistributedDataParallel]],\n        *args,\n        **kwargs,\n    ) -> None:\n        super(MinervaDataParallel, self).__init__()\n        self.model = paralleliser(model, *args, **kwargs).cuda()\n\n    def forward(self, *input: Tuple[Tensor, ...]) -> Tuple[Tensor, ...]:\n        \"\"\"Ensures a forward call to the model goes to the actual wrapped model.\n\n        Args:\n            input (Tuple[Tensor, ...]): Input of tensors to be parsed to the model forward.\n\n        Returns:\n            Tuple[Tensor, ...]: Output of model.\n        \"\"\"\n        z = self.model(*input)\n        assert isinstance(z, tuple) and list(map(type, z)) == [Tensor] * len(z)\n        return z\n\n    def __call__(self, *input):\n        return self.model(*input)\n\n    def __getattr__(self, name):\n        try:\n            return super().__getattr__(name)\n        except AttributeError:\n            return getattr(self.model.module, name)\n\n    def __repr__(self) -> Any:\n        return self.model.__repr__()\n\n\nclass MinervaOnnxModel(MinervaModel):\n    \"\"\"Special model class for enabling :mod:`onnx` models to be used within :mod:`minerva`.\n\n    Attributes:\n        model (Module): :mod:`onnx` model imported into :mod:`torch`.\n\n    Args:\n        model (Module): :mod:`onnx` model imported into :mod:`torch`.\n    \"\"\"\n\n    def __init__(self, model: Module, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n\n        self.model = model\n\n    def __call__(self, *input) -> Any:\n        return self.model.forward(*input)\n\n    def __getattr__(self, name) -> Any:\n        try:\n            return super().__getattr__(name)\n        except AttributeError:\n            return getattr(self.model, name)\n\n    def __repr__(self) -> Any:\n        return self.model.__repr__()\n\n    def forward(self, *input: Any) -> Any:\n        \"\"\"Performs a forward pass of the ``model`` within.\n\n        Args:\n            input (Any): Input to be parsed to ``model.forward``.\n\n        Returns:\n            Any: Output of model.\n        \"\"\"\n        return self.model.forward(*input)\n\n\n# =====================================================================================================================\n#                                                     METHODS\n# =====================================================================================================================\ndef get_model(model_name: str) -> Callable[..., MinervaModel]:\n    \"\"\"Returns the constructor of the ``model_name`` in :mod:`models`.\n\n    Args:\n        model_name (str): Name of the model to get.\n\n    Returns:\n        Callable[..., MinervaModel]: Constructor of the model requested.\n    \"\"\"\n    model: Callable[..., MinervaModel] = func_by_str(\"minerva.models\", model_name)\n    return model\n\n\ndef get_torch_weights(weights_name: str) -> Optional[WeightsEnum]:\n    \"\"\"Loads pre-trained model weights from ``torchvision`` via Torch Hub API.\n\n    Args:\n        weights_name (str): Name of model weights. See ... for a list of possible pre-trained weights.\n\n    Returns:\n        Optional[WeightsEnum]: API query for the specified weights. None if query cannot be found. See note on use:\n\n    Note:\n        This function only returns a query for the API of the weights. To actually use them, you need to call\n        ``get_state_dict(progress)`` where progress is a ``bool`` on whether to show a progress bar for the\n        downloading of the weights (if not already in cache).\n    \"\"\"\n    weights: Optional[WeightsEnum] = None\n    try:\n        weights = torch.hub.load(\"pytorch/vision\", \"get_weight\", name=weights_name)\n    except OSError:\n        th_dir = os.environ.get(\"TORCH_HUB\", Path(\"~/.cache/torch/hub\").expanduser())\n        try:\n            weights = torch.hub.load(\n                f\"{th_dir}/pytorch_vision_main\",\n                \"get_weight\",\n                name=weights_name,\n                source=\"local\",\n            )\n        except FileNotFoundError as err:  # pragma: no cover\n            print(err)\n            weights = None\n\n    return weights\n\n\ndef get_output_shape(\n    model: Module,\n    image_dim: Union[Sequence[int], int],\n    sample_pairs: bool = False,\n) -> Union[int, Sequence[int]]:\n    \"\"\"Gets the output shape of a model.\n\n    Args:\n        model (Module): Model for which the shape of the output needs to be found.\n        image_dim (Union[Sequence[int], int]): Expected shape of the input data to the model.\n        sample_pairs (bool): Optional; Flag for if paired sampling is active.\n            Will send a paired sample through the model.\n\n    Returns:\n        The shape of the output data from the model.\n    \"\"\"\n    _image_dim: Union[Sequence[int], int] = image_dim\n    try:\n        assert not isinstance(image_dim, int)\n        if len(image_dim) == 1:\n            _image_dim = image_dim[0]\n    except (AssertionError, TypeError):\n        if not hasattr(image_dim, \"__len__\"):\n            pass\n\n    if not hasattr(_image_dim, \"__len__\"):\n        assert isinstance(_image_dim, int)\n        random_input = torch.rand([4, _image_dim])\n    elif sample_pairs:\n        assert isinstance(_image_dim, Iterable)\n        random_input = torch.rand([2, 4, *_image_dim])\n    else:\n        assert isinstance(_image_dim, Iterable)\n        random_input = torch.rand([4, *_image_dim])\n\n    output: Tensor = model(random_input)\n\n    if len(output[0].data.shape) == 1:\n        return output[0].data.shape[0]\n\n    else:\n        return output[0].data.shape[1:]\n\n\ndef bilinear_init(in_channels: int, out_channels: int, kernel_size: int) -> Tensor:\n    \"\"\"Constructs the weights for the bi-linear interpolation kernel for use in transpose convolutional layers.\n\n    Source: https://github.com/haoran1062/FCN-pytorch/blob/master/FCN.py\n\n    Args:\n        in_channels (int): Number of input channels to the layer.\n        out_channels (int): Number of output channels from the layer.\n        kernel_size (int): Size of the (square) kernel.\n\n    Returns:\n        Tensor of the initialised bi-linear interpolated weights for the transpose convolutional layer's kernels.\n    \"\"\"\n    factor = (kernel_size + 1) // 2\n\n    if kernel_size % 2 == 1:\n        center = factor - 1\n    else:\n        center = int(factor - 0.5)\n\n    og = np.ogrid[:kernel_size, :kernel_size]\n    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n    weight: NDArray[Any, Any] = np.zeros(\n        (in_channels, out_channels, kernel_size, kernel_size), dtype=\"float32\"\n    )\n    weight[range(in_channels), range(out_channels), :, :] = filt\n\n    weights = torch.from_numpy(weight)  # type: ignore[attr-defined]\n    assert isinstance(weights, Tensor)\n    return weights\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "605092577ba0b135a25efced79980258835488cd0f6cb3e27ee4a7a723904d75"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/utils/visutils.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 50011,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n#\n# TODO: Reduce boilerplate.\n#\n\"\"\"Module to visualise .tiff images, label masks and results from the fitting of neural networks for remote sensing.\n\nAttributes:\n    DATA_CONFIG (dict): Config defining the properties of the data used in the experiment.\n    IMAGERY_CONFIG (dict): Config defining the properties of the imagery used in the experiment.\n    DATA_DIR (list): Path to directory holding dataset.\n    BAND_IDS (dict): Band IDs and position in sample image.\n    MAX_PIXEL_VALUE (int): Maximum pixel value (e.g. 255 for 8-bit integer).\n    WGS84 (CRS): WGS84 co-ordinate reference system acting as a default CRS for transformations.\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"DATA_CONFIG\",\n    \"IMAGERY_CONFIG\",\n    \"DATA_DIR\",\n    \"BAND_IDS\",\n    \"MAX_PIXEL_VALUE\",\n    \"WGS84\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport os\nimport random\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Sequence, Tuple, Union\n\nimport imageio\nimport matplotlib as mlp\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nfrom alive_progress import alive_bar\nfrom matplotlib import offsetbox\nfrom matplotlib.colors import Colormap, ListedColormap\nfrom matplotlib.gridspec import GridSpec\nfrom matplotlib.image import AxesImage\nfrom matplotlib.ticker import MaxNLocator\nfrom matplotlib.transforms import Bbox\nfrom nptyping import Float, Int, NDArray, Shape\nfrom numpy.typing import ArrayLike\nfrom rasterio.crs import CRS\nfrom scipy import stats\nfrom torchgeo.datasets.utils import BoundingBox\n\nfrom minerva.utils import AUX_CONFIGS, CONFIG, universal_path, utils\n\n# =====================================================================================================================\n#                                                     GLOBALS\n# =====================================================================================================================\nDATA_CONFIG = AUX_CONFIGS.get(\"data_config\")\nIMAGERY_CONFIG = AUX_CONFIGS[\"imagery_config\"]\n\n# Path to directory holding dataset.\nDATA_DIR = CONFIG[\"dir\"][\"data\"]\n\n# Band IDs and position in sample image.\nBAND_IDS = IMAGERY_CONFIG[\"data_specs\"][\"band_ids\"]\n\n# Maximum pixel value (e.g. 255 for 8-bit integer).\nMAX_PIXEL_VALUE = IMAGERY_CONFIG[\"data_specs\"][\"max_value\"]\n\nWGS84 = CRS.from_epsg(4326)\n\n# Automatically fixes the layout of the figures to accommodate the colour bar legends.\nplt.rcParams[\"figure.constrained_layout.use\"] = True\n\n# Increases DPI to avoid strange plotting errors for class heatmaps.\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"savefig.dpi\"] = 300\n\n# Removes margin in x-axis of plots.\nplt.rcParams[\"axes.xmargin\"] = 0\n\n# Filters out all TensorFlow messages other than errors.\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\n_MAX_SAMPLES = 25\n\n\n# =====================================================================================================================\n#                                                     METHODS\n# =====================================================================================================================\ndef de_interlace(x: Sequence[Any], f: int) -> NDArray[Any, Any]:\n    \"\"\"Separates interlaced arrays, ``x`` at a frequency of ``f`` from each other.\n\n    Args:\n        x (Sequence): Array of data to be de-interlaced.\n        f (int): Frequency at which interlacing occurs. Equivalent to number of sources interlaced together.\n\n    Returns:\n        NDArray: De-interlaced array. Each source array is now sequentially connected.\n    \"\"\"\n    new_x: List[NDArray[Any, Any]] = []\n    for i in range(f):\n        x_i = []\n        for j in np.arange(start=i, stop=len(x), step=f):\n            x_i.append(x[j])\n        new_x.append(np.array(x_i).flatten())\n\n    return np.array(new_x).flatten()\n\n\ndef dec_extent_to_deg(\n    shape: Tuple[int, int],\n    bounds: BoundingBox,\n    src_crs: CRS,\n    new_crs: CRS = WGS84,\n    spacing: int = 32,\n) -> Tuple[Tuple[int, int, int, int], NDArray[Any, Float], NDArray[Any, Float]]:\n    \"\"\"Gets the extent of the image with ``shape`` and with ``bounds`` in latitude, longitude of system ``new_crs``.\n\n    Args:\n        shape (Tuple[int, int]): 2D shape of image to be used to define the extents of the composite image.\n        bounds (BoundingBox): Object describing a geospatial bounding box.\n            Must contain ``minx``, ``maxx``, ``miny`` and ``maxy`` parameters.\n        src_crs (CRS): Source co-ordinate reference system (CRS).\n        new_crs (CRS): Optional; The co-ordinate reference system (CRS) to transform to.\n        spacing (int): Spacing of the lat - lon ticks.\n\n    Returns:\n        Tuple[Tuple[int, int, int, int], NDArray[Any, Float], NDArray[Any, Float]]:\n            * The corners of the image in pixel co-ordinates e.g. ``(0, 256, 0, 256)``.\n            * The latitude extent of the image with ticks at intervals defined by ``spacing``.\n            * The longitude extent of the image with ticks at intervals defined by ``spacing``.\n    \"\"\"\n    # Defines the 'extent' for a composite image based on the size of shape.\n    extent = 0, shape[0], 0, shape[1]\n\n    # Gets the co-ordinates of the corners of the image in decimal lat-lon.\n    corners = utils.transform_coordinates(\n        x=[bounds.minx, bounds.maxx],\n        y=[bounds.miny, bounds.maxy],\n        src_crs=src_crs,\n        new_crs=new_crs,\n    )\n\n    # Creates a discrete mapping of the spaced ticks to latitude longitude extent of the image.\n    lat_extent = np.around(\n        np.linspace(\n            start=corners[1][0],\n            stop=corners[1][1],\n            num=int(shape[0] / spacing) + 1,\n            endpoint=True,\n        ),\n        decimals=3,\n    )\n    lon_extent = np.around(\n        np.linspace(\n            start=corners[0][0],\n            stop=corners[0][1],\n            num=int(shape[0] / spacing) + 1,\n            endpoint=True,\n        ),\n        decimals=3,\n    )\n\n    return extent, lat_extent, lon_extent\n\n\ndef get_mlp_cmap(\n    cmap_style: Optional[Union[Colormap, str]] = None, n_classes: Optional[int] = None\n) -> Optional[Colormap]:\n    \"\"\"Creates a cmap from query\n\n    Args:\n        cmap_style (Union[Colormap, str]): Optional; :mod:`matplotlib` colourmap style to get.\n        n_classes (int): Optional; Number of classes in data to assign colours to.\n\n    Returns:\n        Union[Colormap, None]:\n        * If ``cmap_style`` and ``n_classes`` provided, returns a :class:`ListedColormap` instance.\n        * If ``cmap_style`` provided but no ``n_classes``, returns a :class:`Colormap` instance.\n        * If neither arguments are provided, ``None`` is returned.\n    \"\"\"\n    cmap: Optional[Colormap] = None\n\n    if cmap_style:\n        if isinstance(cmap_style, str):\n            cmap = mlp.colormaps[cmap_style]  # type: ignore\n        else:\n            cmap = cmap_style\n\n        if n_classes:\n            assert isinstance(cmap, Colormap)\n            cmap = cmap.resampled(n_classes)  # type: ignore\n\n    return cmap\n\n\ndef discrete_heatmap(\n    data: NDArray[Shape[\"*, *\"], Int],  # noqa: F722\n    classes: Union[List[str], Tuple[str, ...]],\n    cmap_style: Optional[Union[str, ListedColormap]] = None,\n    block_size: int = 32,\n) -> None:\n    \"\"\"Plots a heatmap with a discrete colour bar. Designed for Radiant Earth MLHub 256x256 SENTINEL images.\n\n    Args:\n        data (NDArray[Shape[*, *], Int]): 2D Array of data to be plotted as a heat map.\n        classes (list[str]): Optional; List of all possible class labels.\n        cmap_style (str, ListedColormap): Optional; Name or object for colour map style.\n        block_size (int): Optional; Size of block image subdivision in pixels.\n\n    Returns:\n        None\n    \"\"\"\n    # Initialises a figure.\n    plt.figure()\n\n    # Creates a cmap from query.\n    cmap = get_mlp_cmap(cmap_style, len(classes))\n\n    # Plots heatmap onto figure.\n    heatmap = plt.imshow(data, cmap=cmap, vmin=-0.5, vmax=len(classes) - 0.5)  # type: ignore[arg-type]\n\n    # Sets tick intervals to block size. Default 32 x 32.\n    plt.xticks(np.arange(0, data.shape[0] + 1, block_size))\n    plt.yticks(np.arange(0, data.shape[1] + 1, block_size))\n\n    # Add grid overlay.\n    plt.grid(which=\"both\", color=\"#CCCCCC\", linestyle=\":\")\n\n    # Plots colour bar onto figure.\n    clb = plt.colorbar(heatmap, ticks=np.arange(0, len(classes)), shrink=0.77)\n\n    # Sets colour bar ticks to class labels.\n    clb.ax.set_yticklabels(classes)\n\n    # Display figure.\n    plt.show()\n\n    # Close figure.\n    plt.close()\n\n\ndef stack_rgb(\n    image: NDArray[Shape[\"3, *, *\"], Float],  # noqa: F722\n    rgb: Dict[str, int] = BAND_IDS,\n    max_value: int = MAX_PIXEL_VALUE,\n) -> NDArray[Shape[\"*, *, 3\"], Float]:  # noqa: F722\n    \"\"\"Stacks together red, green and blue image bands to create a RGB array.\n\n    Args:\n        image (NDArray[Shape[3, *, *], Float]): Image of separate channels to be normalised\n            and reshaped into stacked RGB image.\n        rgb (Dict[str, int]): Optional; Dictionary of which channels in image are the R, G & B bands.\n        max_value (int): Optional; The maximum pixel value in ``image``. e.g. for 8 bit this will be 255.\n\n    Returns:\n        NDArray[Shape[*, *, 3], Float]: Normalised and stacked red, green, blue arrays into RGB array.\n    \"\"\"\n\n    # Extract R, G, B bands from image and normalise.\n    channels: List[Any] = []\n    for channel in [\"R\", \"G\", \"B\"]:\n        band = image[rgb[channel]] / max_value\n        channels.append(band)\n\n    # Stack together RGB bands.\n    # Note that it has to be order BGR not RGB due to the order numpy stacks arrays.\n    rgb_image: NDArray[Shape[\"3, *, *\"], Any] = np.dstack(  # noqa: F722\n        (channels[2], channels[1], channels[0])\n    )\n    assert isinstance(rgb_image, np.ndarray)\n    return rgb_image\n\n\ndef make_rgb_image(\n    image: NDArray[Shape[\"3, *, *\"], Float],  # noqa: F722\n    rgb: Dict[str, int],\n    block_size: int = 32,\n) -> AxesImage:\n    \"\"\"Creates an RGB image from a composition of red, green and blue bands.\n\n    Args:\n        image (np.ndarray[int]): Array representing the image of shape (bands x height x width).\n        rgb (dict): Dictionary of channel numbers of R, G & B bands within ``image``.\n        block_size (int): Optional; Size of block image sub-division in pixels.\n\n    Returns:\n        AxesImage: Plotted RGB image object.\n    \"\"\"\n    # Stack RGB image data together.\n    rgb_image_array = stack_rgb(image, rgb)\n\n    # Create RGB image.\n    rgb_image = plt.imshow(rgb_image_array)\n\n    # Sets tick intervals to block size. Default 32 x 32.\n    plt.xticks(np.arange(0, rgb_image_array.shape[0] + 1, block_size))\n    plt.yticks(np.arange(0, rgb_image_array.shape[1] + 1, block_size))\n\n    # Add grid overlay.\n    plt.grid(which=\"both\", color=\"#CCCCCC\", linestyle=\":\")\n\n    plt.show()\n\n    return rgb_image\n\n\ndef labelled_rgb_image(\n    image: NDArray[Shape[\"*, *, 3\"], Float],  # noqa: F722\n    mask: NDArray[Shape[\"*, *\"], Int],  # noqa: F722\n    bounds: BoundingBox,\n    src_crs: CRS,\n    path: Union[str, Path],\n    name: str,\n    classes: Union[List[str], Tuple[str, ...]],\n    cmap_style: Optional[Union[str, ListedColormap]] = None,\n    new_crs: Optional[CRS] = WGS84,\n    block_size: int = 32,\n    alpha: float = 0.5,\n    show: bool = True,\n    save: bool = True,\n    figdim: Tuple[Union[int, float], Union[int, float]] = (8.02, 10.32),\n) -> str:\n    \"\"\"Produces a layered image of an RGB image, and it's associated label mask heat map alpha blended on top.\n\n    Args:\n        image (np.ndarray[int]): Array representing the image of shape (height x width x bands).\n        mask (np.ndarray[int]): Ground truth mask. Should be of shape (height x width) matching ``image``.\n        bounds (BoundingBox): Object describing a geospatial bounding box.\n            Must contain ``minx``, ``maxx``, ``miny`` and ``maxy`` parameters.\n        src_crs (CRS): Source co-ordinate reference system (CRS).\n        path (str): Path to where to save created figure.\n        name (str): Name of figure. Will be used for title and in the filename.\n        classes (list[str]): Optional; List of all possible class labels.\n        cmap_style (str or ListedColormap): Optional; Name or object for colour map style.\n        new_crs (CRS): Optional; The co-ordinate reference system (CRS) to transform to.\n        block_size (int): Optional; Size of block image subdivision in pixels.\n        alpha (float): Optional; Fraction determining alpha blending of label mask.\n        show (bool): Optional; ``True`` for show figure when plotted. ``False`` if not.\n        save (bool): Optional; ``True`` to save figure to file. ``False`` if not.\n        figdim (tuple): Optional; Figure (height, width) in inches.\n\n    Returns:\n        str: Path to figure save location.\n    \"\"\"\n    # Checks that the mask and image shapes will align.\n    assert mask.shape == image.shape[:2]\n\n    assert new_crs is not None\n\n    # Gets the extent of the image in pixel, lattitude and longitude dimensions.\n    extent, lat_extent, lon_extent = dec_extent_to_deg(\n        mask.shape,\n        bounds=bounds,\n        src_crs=src_crs,\n        spacing=block_size,\n        new_crs=new_crs,\n    )\n\n    # Initialises a figure.\n    fig, ax1 = plt.subplots()\n\n    # Create RGB image.\n    ax1.imshow(image, extent=extent)\n\n    # Creates a cmap from query.\n    cmap = get_mlp_cmap(cmap_style, len(classes))\n\n    # Plots heatmap onto figure.\n    heatmap = ax1.imshow(\n        mask, cmap=cmap, vmin=-0.5, vmax=len(classes) - 0.5, extent=extent, alpha=alpha  # type: ignore[arg-type]\n    )\n\n    # Sets tick intervals to standard 32x32 block size.\n    ax1.set_xticks(np.arange(0, mask.shape[0] + 1, block_size))\n    ax1.set_yticks(np.arange(0, mask.shape[1] + 1, block_size))\n\n    # Creates a secondary x and y-axis to hold lat-lon.\n    ax2 = ax1.twiny().twinx()\n\n    # Plots an invisible line across the diagonal of the image to create the secondary axis for lat-lon.\n    ax2.plot(\n        lon_extent,\n        lat_extent,\n        \" \",\n        clip_box=Bbox.from_extents(\n            lon_extent[0], lat_extent[0], lon_extent[-1], lat_extent[-1]\n        ),\n    )\n\n    # Set ticks for lat-lon.\n    ax2.set_xticks(lon_extent)\n    ax2.set_yticks(lat_extent)\n\n    print(f\"{lat_extent=}\")\n    print(f\"{lon_extent=}\")\n\n    # Sets the limits of the secondary axis, so they should align with the primary.\n    ax2.set_xlim(left=lon_extent[0], right=lon_extent[-1])\n    ax2.set_ylim(top=lat_extent[-1], bottom=lat_extent[0])\n\n    # Converts the decimal lat-lon into degrees, minutes, seconds to label the axis.\n    lat_labels = utils.dec2deg(lat_extent, axis=\"lat\")\n    lon_labels = utils.dec2deg(lon_extent, axis=\"lon\")\n\n    # Sets the secondary axis tick labels.\n    ax2.set_xticklabels(lon_labels, fontsize=11)\n    ax2.set_yticklabels(lat_labels, fontsize=10, rotation=-30, ha=\"left\")\n\n    # Add grid overlay.\n    ax1.grid(which=\"both\", color=\"#CCCCCC\", linestyle=\":\")\n\n    # Plots colour bar onto figure.\n    clb = plt.colorbar(\n        heatmap, ticks=np.arange(0, len(classes)), shrink=0.9, aspect=75, drawedges=True\n    )\n\n    # Sets colour bar ticks to class labels.\n    clb.ax.set_yticklabels(classes, fontsize=11)\n\n    # Bodge to get a figure title by using the colour bar title.\n    clb.ax.set_title(f\"{name}\\nLand Cover\", loc=\"left\", fontsize=15)\n\n    # Set axis labels.\n    ax1.set_xlabel(\"(x) - Pixel Position\", fontsize=14)\n    ax1.set_ylabel(\"(y) - Pixel Position\", fontsize=14)\n    ax2.set_ylabel(\"Latitude\", fontsize=14, rotation=270, labelpad=12)\n    ax2.set_title(\"Longitude\")  # Bodge\n\n    # Manual trial and error fig size which fixes aspect ratio issue.\n    fig.set_figheight(figdim[0])\n    fig.set_figwidth(figdim[1])\n\n    # Display figure.\n    if show:\n        plt.show()\n\n    # Path and file name of figure.\n    fn = f\"{path}/{name}_RGBHM.png\"\n\n    # If true, save file to fn.\n    if save:\n        # Checks if file already exists. Deletes if true.\n        utils.exist_delete_check(fn)\n\n        # Save figure to fn.\n        fig.savefig(fn)\n\n    # Close figure.\n    plt.close()\n\n    return fn\n\n\ndef make_gif(\n    dates: Sequence[str],\n    images: NDArray[Shape[\"*, *, *, 3\"], Any],  # noqa: F722\n    masks: NDArray[Shape[\"*, *, *\"], Any],  # noqa: F722\n    bounds: BoundingBox,\n    src_crs: CRS,\n    classes: Union[List[str], Tuple[str, ...]],\n    gif_name: str,\n    path: Union[str, Path],\n    cmap_style: Optional[Union[str, ListedColormap]] = None,\n    fps: float = 1.0,\n    new_crs: Optional[CRS] = WGS84,\n    alpha: float = 0.5,\n    figdim: Tuple[Union[int, float], Union[int, float]] = (8.02, 10.32),\n) -> None:\n    \"\"\"Wrapper to :func:`labelled_rgb_image` to make a GIF for a patch out of scenes.\n\n    Args:\n        dates (Sequence[str]): Dates of scenes to be used as the frames in the GIF.\n        images (NDArray[Shape[*, *, *, 3], Any]): All the frames of imagery to make the GIF from.\n            Leading dimension must be the same length as ``dates`` and ``masks``.\n        masks (NDArray[Shape[*, *, *, 3], Any]): The masks for each frame of the GIF.\n            Leading dimension must be the same length as ``dates`` and ``image``.\n        bounds (BoundingBox): The bounding box (in the ``src_crs`` CRS) of the patch the GIF will be of.\n        src_crs (CRS): Source co-ordinate reference system (CRS).\n        classes (list[str]): List of all possible class labels.\n        gif_name (str): Path to and name of GIF to be made.\n        path (Union[Path, str]): Path to where to save frames of the GIF.\n        cmap_style (str or ListedColormap): Optional; Name or object for colour map style.\n        fps (float): Optional; Frames per second of GIF.\n        new_crs (CRS): Optional; The co-ordinate reference system (CRS) to transform to.\n        alpha (float): Optional; Fraction determining alpha blending of label mask.\n        figdim (tuple): Optional; Figure (height, width) in inches.\n\n    Returns:\n        None\n    \"\"\"\n    # Initialise progress bar.\n    with alive_bar(len(dates), bar=\"blocks\") as bar:\n\n        # List to hold filenames and paths of images created.\n        frames = []\n        for i in range(len(dates)):\n            # Update progress bar with current scene.\n            bar.text(\"SCENE ON %s\" % dates[i])\n\n            # Create a frame of the GIF for a scene of the patch.\n            frame = labelled_rgb_image(\n                images[i],\n                masks[i],\n                bounds,\n                src_crs,\n                path,\n                name=f\"{i}\",\n                classes=classes,\n                cmap_style=cmap_style,\n                new_crs=new_crs,\n                alpha=alpha,\n                save=True,\n                show=False,\n                figdim=figdim,\n            )\n\n            # Read in frame just created and add to list of frames.\n            frames.append(imageio.imread(frame))\n\n            # Update bar with step completion.\n            bar()\n\n    # Checks GIF doesn't already exist. Deletes if it does.\n    utils.exist_delete_check(gif_name)\n\n    # Create a 'unknown' bar to 'spin' while the GIF is created.\n    with alive_bar(unknown=\"waves\") as bar:\n        # Add current operation to spinner bar.\n        bar.text(\"MAKING PATCH GIF\")\n\n        # Create GIF.\n        imageio.mimwrite(gif_name, frames, format=\".gif\", fps=fps)  # type: ignore\n\n\ndef prediction_plot(\n    sample: Dict[str, Any],\n    sample_id: str,\n    classes: Dict[int, str],\n    src_crs: CRS,\n    new_crs: CRS = WGS84,\n    cmap_style: Optional[Union[str, ListedColormap]] = None,\n    exp_id: Optional[str] = None,\n    fig_dim: Optional[Tuple[Union[int, float], Union[int, float]]] = None,\n    block_size: int = 32,\n    show: bool = True,\n    save: bool = True,\n    fn_prefix: Optional[str] = None,\n) -> None:\n    \"\"\"\n    Produces a figure containing subplots of the predicted label mask, the ground truth label mask\n    and a reference RGB image of the same patch.\n\n    Args:\n        sample (dict[str, Any]): Dictionary holding the `image`, ground truth (`mask`) and predicted (`pred`) masks\n            and the bounding box for this sample.\n        sample_id (str): ID for the sample.\n        classes (dict[str]): Dictionary mapping class labels to class names.\n        src_crs (CRS): Existing co-ordinate system of the image.\n        new_crs(CRS): Optional; Co-ordinate system to convert image to and use for labelling.\n        exp_id (str): Optional; Unique ID for the experiment run that predictions and labels come from.\n        block_size (int): Optional; Size of block image sub-division in pixels.\n        cmap_style (str, ListedColormap): Optional; Name or object for colour map style.\n        show (bool): Optional; True for show figure when plotted. False if not.\n        save (bool): Optional; True to save figure to file. False if not.\n        fig_dim (Tuple[float, float]): Optional; Figure (height, width) in inches.\n        fn_prefix (str): Optional; Common filename prefix (including path to file) for all plots of this type\n            from this experiment. Appended with the sample ID to give the filename to save the plot to.\n\n    Returns:\n        None\n    \"\"\"\n    # Stacks together the R, G, & B bands to form an array of the RGB image.\n    rgb_image = sample[\"image\"]\n    z = sample[\"pred\"]\n    y = sample[\"mask\"]\n    bounds = sample[\"bounds\"]\n\n    extent, lat_extent, lon_extent = dec_extent_to_deg(\n        y.shape, bounds, src_crs, new_crs=new_crs, spacing=block_size\n    )\n\n    centre = utils.transform_coordinates(\n        *utils.get_centre_loc(bounds), src_crs=src_crs, new_crs=new_crs\n    )\n\n    # Initialises a figure.\n    fig = plt.figure(figsize=fig_dim)\n\n    gs = GridSpec(nrows=2, ncols=2, figure=fig)\n\n    axes: NDArray[Shape[\"3\"], Any] = np.array(\n        [\n            fig.add_subplot(gs[0, 0]),\n            fig.add_subplot(gs[0, 1]),\n            fig.add_subplot(gs[1, :]),\n        ]\n    )\n\n    cmap = get_mlp_cmap(cmap_style, len(classes))\n\n    # Plots heatmap onto figure.\n    z_heatmap = axes[0].imshow(z, cmap=cmap, vmin=-0.5, vmax=len(classes) - 0.5)\n    _ = axes[1].imshow(y, cmap=cmap, vmin=-0.5, vmax=len(classes) - 0.5)\n\n    # Create RGB image.\n    axes[2].imshow(rgb_image, extent=extent)\n\n    # Sets tick intervals to standard 32x32 block size.\n    axes[0].set_xticks(np.arange(0, z.shape[0] + 1, block_size))\n    axes[0].set_yticks(np.arange(0, z.shape[1] + 1, block_size))\n\n    axes[1].set_xticks(np.arange(0, y.shape[0] + 1, block_size))\n    axes[1].set_yticks(np.arange(0, y.shape[1] + 1, block_size))\n\n    axes[2].set_xticks(np.arange(0, rgb_image.shape[0] + 1, block_size))\n    axes[2].set_yticks(np.arange(0, rgb_image.shape[1] + 1, block_size))\n\n    # Add grid overlay.\n    axes[0].grid(which=\"both\", color=\"#CCCCCC\", linestyle=\":\")\n    axes[1].grid(which=\"both\", color=\"#CCCCCC\", linestyle=\":\")\n    axes[2].grid(which=\"both\", color=\"#CCCCCC\", linestyle=\":\")\n\n    # Converts the decimal lat-lon into degrees, minutes, seconds to label the axis.\n    lat_labels = utils.dec2deg(lat_extent, axis=\"lat\")\n    lon_labels = utils.dec2deg(lon_extent, axis=\"lon\")\n\n    # Sets the secondary axis tick labels.\n    axes[2].set_xticklabels(lon_labels, fontsize=9, rotation=30)\n    axes[2].set_yticklabels(lat_labels, fontsize=9)\n\n    # Plots colour bar onto figure.\n    clb = fig.colorbar(\n        z_heatmap,\n        ax=axes.ravel().tolist(),\n        location=\"top\",\n        ticks=np.arange(0, len(classes)),\n        aspect=75,\n        drawedges=True,\n    )\n\n    # Sets colour bar ticks to class labels.\n    clb.ax.set_xticklabels(classes.values(), fontsize=9)\n\n    # Set figure title and subplot titles.\n    fig.suptitle(\n        f\"{sample_id}: {utils.lat_lon_to_loc(lat=str(centre[1]), lon=str(centre[0]))}\",\n        fontsize=15,\n    )\n    axes[0].set_title(\"Predicted\", fontsize=13)\n    axes[1].set_title(\"Ground Truth\", fontsize=13)\n    axes[2].set_title(\"Reference Imagery\", fontsize=13)\n\n    # Set axis labels.\n    axes[0].set_xlabel(\"(x) - Pixel Position\", fontsize=10)\n    axes[0].set_ylabel(\"(y) - Pixel Position\", fontsize=10)\n    axes[1].set_xlabel(\"(x) - Pixel Position\", fontsize=10)\n    axes[1].set_ylabel(\"(y) - Pixel Position\", fontsize=10)\n    axes[2].set_xlabel(\"Longitude\", fontsize=10)\n    axes[2].set_ylabel(\"Latitude\", fontsize=10)\n\n    # Display figure.\n    if show:\n        plt.show()\n\n    if fn_prefix is None:\n        path = universal_path(CONFIG[\"dir\"][\"results\"])\n        fn_prefix = str(path / f\"{exp_id}_{utils.timestamp_now()}_Mask\")\n\n    # Path and file name of figure.\n    fn = f\"{fn_prefix}_{sample_id}.png\"\n\n    # If true, save file to fn.\n    if save:\n        # Checks if file already exists. Deletes if true.\n        utils.exist_delete_check(fn)\n\n        # Save figure to fn.\n        fig.savefig(fn)\n\n    # Close figure.\n    plt.close()\n\n\ndef seg_plot(\n    z: Union[List[int], NDArray[Any, Any]],\n    y: Union[List[int], NDArray[Any, Any]],\n    ids: List[str],\n    bounds: Union[Sequence[Any], NDArray[Any, Any]],\n    mode: str,\n    classes: Dict[int, str],\n    colours: Dict[int, str],\n    fn_prefix: str,\n    frac: float = 0.05,\n    fig_dim: Optional[Tuple[Union[int, float], Union[int, float]]] = (9.3, 10.5),\n) -> None:\n    \"\"\"Custom function for pre-processing the outputs from image segmentation testing for data visualisation.\n\n    Args:\n        z (list[float]): Predicted segmentation masks by the network.\n        y (list[float]): Corresponding ground truth masks.\n        ids (list[str]): Corresponding patch IDs for the test data supplied to the network.\n        bounds (list[BoundingBox] or np.ndarray[BoundingBox]): Array of objects describing a geospatial bounding box.\n            Must contain `minx`, `maxx`, `miny` and `maxy` parameters.\n        mode (str): Mode samples are from. Must be 'train', 'val' or 'test'.\n        classes (dict): Dictionary mapping class labels to class names.\n        colours (dict): Dictionary mapping class labels to colours.\n        fn_prefix (str): Common filename prefix (including path to file) for all plots of this type\n            from this experiment to use.\n        frac (float): Optional; Fraction of patch samples to plot.\n        fig_dim (tuple[float, float]): Optional; Figure (height, width) in inches.\n\n    Returns:\n        None\n    \"\"\"\n    # TODO: This is a very naughty way of avoiding a circular import.\n    # Need to reorganise package to avoid need for this.\n    from minerva.datasets import make_dataset\n\n    if not isinstance(z, np.ndarray):\n        z = np.array(z)\n\n    if not isinstance(y, np.ndarray):\n        y = np.array(y)\n\n    z = np.reshape(z, (z.shape[0] * z.shape[1], z.shape[2], z.shape[3]))\n    y = np.reshape(y, (y.shape[0] * y.shape[1], y.shape[2], y.shape[3]))\n    flat_ids: NDArray[Any, Any] = np.array(ids).flatten()\n\n    print(\"\\nRE-CONSTRUCTING DATASET\")\n    dataset, _ = make_dataset(CONFIG[\"dir\"][\"data\"], CONFIG[\"dataset_params\"][mode])\n\n    # Create a new projection system in lat-lon.\n    crs = dataset.crs\n\n    print(\"\\nPRODUCING PREDICTED MASKS\")\n\n    # Limits number of masks to produce to a fractional number of total and no more than `_MAX_SAMPLES`.\n    n_samples = int(frac * len(flat_ids))\n    if n_samples > _MAX_SAMPLES:\n        n_samples = _MAX_SAMPLES\n\n    # Initialises a progress bar for the epoch.\n    with alive_bar(n_samples, bar=\"blocks\") as bar:\n\n        # Plots the predicted versus ground truth labels for all test patches supplied.\n        for i in random.sample(range(len(flat_ids)), n_samples):\n            image = stack_rgb(dataset[bounds[i]][\"image\"].numpy())\n            sample = {\"image\": image, \"pred\": z[i], \"mask\": y[i], \"bounds\": bounds[i]}\n\n            prediction_plot(\n                sample,\n                flat_ids[i],\n                classes=classes,\n                src_crs=crs,\n                exp_id=CONFIG[\"model_name\"],\n                show=False,\n                fn_prefix=fn_prefix,\n                fig_dim=fig_dim,\n                cmap_style=ListedColormap(colours.values(), N=len(colours)),  # type: ignore\n            )\n\n            bar()\n\n\ndef plot_subpopulations(\n    class_dist: List[Tuple[int, int]],\n    class_names: Dict[int, str],\n    cmap_dict: Dict[int, str],\n    filename: Optional[Union[str, Path]] = None,\n    save: bool = True,\n    show: bool = False,\n) -> None:\n    \"\"\"Creates a pie chart of the distribution of the classes within the data.\n\n    Args:\n        class_dist (list[tuple[int, int]]): Modal distribution of classes in the dataset provided.\n        class_names (dict): Optional; Dictionary mapping class labels to class names.\n        cmap_dict (dict): Optional; Dictionary mapping class labels to class colours.\n        filename (str): Optional; Name of file to save plot to.\n        show (bool): Optional; Whether to show plot.\n        save (bool): Optional; Whether to save plot to file.\n\n    Returns:\n        None\n    \"\"\"\n    # List to hold the name and percentage distribution of each class in the data as str.\n    class_data = []\n\n    # List to hold the total counts of each class.\n    counts = []\n\n    # List to hold colours of classes in the correct order.\n    colours = []\n\n    # Finds total number of samples to normalise data.\n    n_samples = 0\n    for mode in class_dist:\n        n_samples += mode[1]\n\n    # For each class, find the percentage of data that is that class and the total counts for that class.\n    for label in class_dist:\n        # Sets percentage label to <0.01% for classes matching that equality.\n        if (label[1] * 100.0 / n_samples) > 0.01:\n            class_data.append(\n                \"{} \\n{:.2f}%\".format(\n                    class_names[label[0]], (label[1] * 100.0 / n_samples)\n                )\n            )\n        else:\n            class_data.append(\"{} \\n<0.01%\".format(class_names[label[0]]))\n        counts.append(label[1])\n        colours.append(cmap_dict[label[0]])\n\n    # Locks figure size.\n    plt.figure(figsize=(6, 5))\n\n    # Plot a pie chart of the data distribution amongst the classes.\n    patches, _ = plt.pie(\n        counts, colors=colours, explode=[i * 0.05 for i in range(len(class_data))]\n    )\n\n    # Adds legend.\n    plt.legend(\n        patches, class_data, loc=\"center left\", bbox_to_anchor=(1, 0.5), frameon=False\n    )\n\n    # Shows and/or saves plot.\n    if show:\n        plt.show()\n    if save:\n        plt.savefig(filename)\n        plt.close()\n\n\ndef plot_history(\n    metrics: Dict[str, Any],\n    filename: Optional[Union[str, Path]] = None,\n    save: bool = True,\n    show: bool = False,\n) -> None:\n    \"\"\"Plots model history based on metrics supplied.\n\n    Args:\n        metrics (dict): Dictionary containing the names and results of the metrics by which model was assessed.\n        filename (str): Optional; Name of file to save plot to.\n        show (bool): Optional; Whether to show plot.\n        save (bool): Optional; Whether to save plot to file.\n\n    Returns:\n        None\n    \"\"\"\n    # Initialise figure.\n    ax = plt.figure().gca()\n\n    # Plots each metric in metrics, appending their artist handles.\n    handles = []\n    labels = []\n    for key in metrics:\n        # Checks that the length of x matches y and is greater than 1 so can be plotted.\n        if len(metrics[key][\"x\"]) == len(metrics[key][\"y\"]) >= 1.0:\n\n            # Plot metric.\n            handles.append(ax.plot(metrics[key][\"x\"], metrics[key][\"y\"])[0])\n            labels.append(key)\n\n    # Creates legend from plot artist handles and names of metrics.\n    ax.legend(handles=handles, labels=labels)\n\n    # Forces x-axis ticks to be integers.\n    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n\n    # Adds a grid overlay with green dashed lines.\n    ax.grid(color=\"green\", linestyle=\"--\", linewidth=0.5)  # For some funky gridlines\n\n    # Adds axis labels.\n    ax.set_xlabel(\"Epoch\")\n    ax.set_ylabel(\"Loss/Accuracy\")\n\n    # Shows and/or saves plot.\n    if show:\n        plt.show()\n    if save:\n        plt.savefig(filename)\n        plt.close()\n\n\ndef make_confusion_matrix(\n    pred: Union[List[int], NDArray[Any, Int]],\n    labels: Union[List[int], NDArray[Any, Int]],\n    classes: Dict[int, str],\n    filename: Optional[Union[str, Path]] = None,\n    cmap_style: str = \"Blues\",\n    show: bool = True,\n    save: bool = False,\n) -> None:\n    \"\"\"Creates a heat-map of the confusion matrix of the given model.\n\n    Args:\n        pred(list[int]): Predictions made by model on test images.\n        labels (list[int]): Accompanying ground truth labels for testing images.\n        classes (dict): Dictionary mapping class labels to class names.\n        filename (str): Optional; Name of file to save plot to.\n        cmap_style (str): Colourmap style to use in the confusion matrix.\n        show (bool): Optional; Whether to show plot.\n        save (bool): Optional; Whether to save plot to file.\n\n    Returns:\n        None\n    \"\"\"\n    _pred, _labels, new_classes = utils.check_test_empty(pred, labels, classes)\n\n    # Creates the confusion matrix based on these predictions and the corresponding ground truth labels.\n    cm_norm: Any = None\n    try:\n        cm = tf.math.confusion_matrix(\n            labels=_labels, predictions=_pred, dtype=np.uint16  # type: ignore\n        ).numpy()  # type: ignore\n\n        # Normalises confusion matrix.\n        cm_norm = np.around(\n            cm.astype(np.float16) / cm.sum(axis=1)[:, np.newaxis], decimals=2\n        )\n\n    except RuntimeWarning as err:  # pragma: no cover\n        print(\"\\n\", err)\n        print(\"At least one class had no ground truth or no predicted labels!\")\n\n    np.nan_to_num(cm_norm, copy=False)\n\n    # Extract class names from dict in numeric order to ensure labels match matrix.\n    class_names = [new_classes[key] for key in range(len(new_classes.keys()))]\n\n    # Converts confusion matrix to Pandas.DataFrame.\n    cm_df = pd.DataFrame(cm_norm, index=class_names, columns=class_names)\n\n    if DATA_CONFIG is not None:\n        figsize = DATA_CONFIG[\"fig_sizes\"][\"CM\"]\n    else:  # pragma: no cover\n        figsize = None\n\n    # Plots figure.\n    plt.figure(figsize=figsize)\n\n    cmap = get_mlp_cmap(cmap_style)\n    sns.heatmap(\n        cm_df,\n        annot=True,\n        square=True,\n        cmap=cmap,\n        vmin=0.0,\n        vmax=1.0,\n    )\n    plt.ylabel(\"Ground Truth\")\n    plt.xlabel(\"Predicted\")\n\n    # Shows and/or saves plot.\n    if show:\n        plt.show()\n    if save:\n        plt.savefig(filename)\n        plt.close()\n\n\ndef make_roc_curves(\n    probs: ArrayLike,\n    labels: Union[Sequence[int], NDArray[Any, Int]],\n    class_names: Dict[int, str],\n    colours: Dict[int, str],\n    micro: bool = True,\n    macro: bool = True,\n    filename: Optional[str] = None,\n    show: bool = False,\n    save: bool = True,\n) -> None:\n    \"\"\"Plots ROC curves for each class, the micro and macro average ROC curves and accompanying AUCs.\n\n    Adapted from Scikit-learn's example at:\n    https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n\n    Args:\n        probs (list or np.ndarray): Array of probabilistic predicted classes from model where each sample\n            should have a list of the predicted probability for each class.\n        labels (list or np.ndarray): List of corresponding ground truth labels.\n        class_names (dict): Dictionary mapping class labels to class names.\n        colours (dict): Dictionary mapping class labels to colours.\n        micro (bool): Optional; Whether to compute and plot the micro average ROC curves.\n        macro (bool): Optional; Whether to compute and plot the macro average ROC curves.\n        filename (str): Optional; Name of file to save plot to.\n        save (bool): Optional; Whether to save the plots to file.\n        show (bool): Optional; Whether to show the plots.\n\n    Returns:\n        None\n    \"\"\"\n    # Gets the class labels as a list from the class_names dict.\n    class_labels = [key for key in class_names.keys()]\n\n    # Reshapes the probabilities to be (n_samples, n_classes).\n    probs = np.reshape(probs, (len(labels), len(class_labels)))\n\n    # Computes all class, micro and macro average ROC curves and AUCs.\n    fpr, tpr, roc_auc = utils.compute_roc_curves(\n        probs, labels, class_labels, micro=micro, macro=macro\n    )\n\n    # Plot all ROC curves\n    print(\"\\nPlotting ROC Curves\")\n    plt.figure()\n\n    if micro:\n        # Plot micro average ROC curves.\n        plt.plot(\n            fpr[\"micro\"],\n            tpr[\"micro\"],\n            label=\"Micro-average (AUC = {:.2f})\".format(roc_auc[\"micro\"]),\n            color=\"deeppink\",\n            linestyle=\"dotted\",\n        )\n\n    if macro:\n        # Plot macro average ROC curves.\n        plt.plot(\n            fpr[\"macro\"],\n            tpr[\"macro\"],\n            label=\"Macro-average (AUC = {:.2f})\".format(roc_auc[\"macro\"]),\n            color=\"navy\",\n            linestyle=\"dotted\",\n        )\n\n    # Plot all class ROC curves.\n    for key in class_labels:\n        plt.plot(\n            fpr[key],\n            tpr[key],\n            color=colours[key],\n            label=f\"{class_names[key]} \" + \"(AUC = {:.2f})\".format(roc_auc[key]),\n        )\n\n    # Plot random classifier diagonal.\n    plt.plot([0, 1], [0, 1], \"k--\")\n\n    # Set limits.\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n\n    # Set axis labels.\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n\n    # Position legend in lower right corner of figure where no classifiers should exist.\n    plt.legend(loc=\"lower right\")\n\n    # Shows and/or saves plot.\n    if show:\n        plt.show()\n    if save:\n        plt.savefig(filename)\n        print(\"ROC Curves plot SAVED\")\n        plt.close()\n\n\ndef plot_embedding(\n    embeddings: Any,\n    bounds: Union[Sequence[Any], NDArray[Any, Any]],\n    mode: str,\n    title: Optional[str] = None,\n    show: bool = False,\n    save: bool = True,\n    filename: Optional[Union[Path, str]] = None,\n) -> None:\n    \"\"\"Using TSNE Clustering, visualises the embeddings from a model.\n\n    Args:\n        embeddings (Any): Embeddings from a model.\n        bounds (Union[Sequence[Any], NDArray[Any, Any]]): Array of objects describing a geospatial bounding box.\n            Must contain `minx`, `maxx`, `miny` and `maxy` parameters.\n        mode (str): Mode samples are from. Must be 'train', 'val' or 'test'.\n        title (Optional[str], optional): Title of plot.\n        show (bool): Optional; Whether to show plot.\n        save (bool): Optional; Whether to save plot to file.\n        filename (str): Optional; Name of file to save plot to.\n\n    Returns:\n        None\n    \"\"\"\n\n    x = utils.tsne_cluster(embeddings)\n\n    # TODO: This is a very naughty way of avoiding a circular import.\n    # Need to reorganise package to avoid need for this.\n    from minerva.datasets import make_dataset\n\n    print(\"\\nRE-CONSTRUCTING DATASET\")\n    dataset, _ = make_dataset(CONFIG[\"dir\"][\"data\"], CONFIG[\"dataset_params\"][mode])\n\n    images = []\n    targets = []\n\n    # Initialises a progress bar for the epoch.\n    with alive_bar(len(x), bar=\"blocks\") as bar:\n\n        # Plots the predicted versus ground truth labels for all test patches supplied.\n        for i in range(len(x)):\n            sample = dataset[bounds[i]]\n            images.append(stack_rgb(sample[\"image\"].numpy()))\n            targets.append(\n                [\n                    int(stats.mode(mask.flatten(), keepdims=False).mode)\n                    for mask in sample[\"mask\"].numpy()\n                ]\n            )\n\n            bar()\n\n    x_min, x_max = np.min(x, 0), np.max(x, 0)\n    x = (x - x_min) / (x_max - x_min)\n\n    plt.figure(figsize=(10, 10))\n    ax = plt.subplot(111)\n\n    for i in range(len(x)):\n        plt.text(\n            x[i, 0],\n            x[i, 1],\n            str(targets[i]),\n            color=plt.cm.Set1(targets[i][0] / 10.0),  # type: ignore\n            fontdict={\"weight\": \"bold\", \"size\": 9},\n        )\n\n    if hasattr(offsetbox, \"AnnotationBbox\"):\n        # only print thumbnails with matplotlib > 1.0\n        shown_images: NDArray[Any, Any] = np.array([[1.0, 1.0]])  # just something big\n\n        for i in range(len(images)):\n            dist = np.sum((x[i] - shown_images) ** 2, 1)\n            if np.min(dist) < 4e-3:\n                # don’t show points that are too close\n                continue\n\n            shown_images = np.r_[shown_images, [x[i]]]\n            imagebox = offsetbox.AnnotationBbox(\n                offsetbox.OffsetImage(images[i], cmap=plt.cm.gray_r), x[i]  # type: ignore\n            )\n\n            ax.add_artist(imagebox)\n\n    plt.xticks([]), plt.yticks([])  # type: ignore\n\n    if title is not None:\n        plt.title(title)\n\n    # Shows and/or saves plot.\n    if show:\n        plt.show()\n    if save:\n        if filename is None:  # pragma: no cover\n            filename = \"tsne_cluster_vis.png\"\n        os.makedirs(Path(filename).parent, exist_ok=True)\n        plt.savefig(filename)\n        print(\"TSNE cluster visualisation SAVED\")\n        plt.close()\n\n\ndef format_plot_names(\n    model_name: str, timestamp: str, path: Union[Sequence[str], str, Path]\n) -> Dict[str, str]:\n    \"\"\"Creates unique filenames of plots in a standardised format.\n\n    Args:\n        model_name (str): Name of model. e.g. MLP-MkVI.\n        timestamp (str): Time and date to be used to identify experiment.\n        path (Union[list[str], str, Path]): Path to the directory for storing plots as a list of strings for each level.\n\n    Returns:\n        filenames (dict): Formatted filenames for plots.\n    \"\"\"\n\n    def standard_format(plot_type: str, *sub_dir) -> str:\n        \"\"\"Creates a unique filename for a plot in a standardised format.\n\n        Args:\n            plot_type (str): Plot type to use in filename.\n            sub_dir (str): Additional subdirectories to add to path to filename.\n\n        Returns:\n            String of path to filename of the form \"{model_name}_{timestamp}_{plot_type}.{file_ext}\"\n        \"\"\"\n        filename = f\"{model_name}_{timestamp}_{plot_type}\"\n        return str(universal_path(path) / universal_path(sub_dir) / filename)\n\n    filenames = {\n        \"History\": standard_format(\"MH\") + \".png\",\n        \"Pred\": standard_format(\"TP\") + \".png\",\n        \"CM\": standard_format(\"CM\") + \".png\",\n        \"ROC\": standard_format(\"ROC\" + \".png\"),\n        \"Mask\": standard_format(\"Mask\", \"Masks\"),\n        \"PvT\": standard_format(\"PvT\", \"PvTs\"),\n        \"TSNE\": standard_format(\"TSNE\") + \".png\",\n    }\n\n    return filenames\n\n\ndef plot_results(\n    plots: Dict[str, bool],\n    z: Optional[Union[List[int], NDArray[Any, Int]]] = None,\n    y: Optional[Union[List[int], NDArray[Any, Int]]] = None,\n    metrics: Optional[Dict[str, Any]] = None,\n    ids: Optional[List[str]] = None,\n    mode: str = \"test\",\n    bounds: Optional[NDArray[Any, Any]] = None,\n    probs: Optional[Union[List[float], NDArray[Any, Float]]] = None,\n    embeddings: Optional[NDArray[Any, Any]] = None,\n    class_names: Optional[Dict[int, str]] = None,\n    colours: Optional[Dict[int, str]] = None,\n    save: bool = True,\n    show: bool = False,\n    model_name: Optional[str] = None,\n    timestamp: Optional[str] = None,\n    results_dir: Optional[Union[Sequence[str], str, Path]] = None,\n) -> None:\n    \"\"\"Orchestrates the creation of various plots from the results of a model fitting.\n\n    Args:\n        plots (dict): Dictionary defining which plots to make.\n        z (list[list[int]] or np.ndarray[np.ndarray[int]]): List of predicted label masks.\n        y (list[list[int]] or np.ndarray[np.ndarray[int]]): List of corresponding ground truth label masks.\n        metrics (dict): Optional; Dictionary containing a log of various metrics used to assess\n            the performance of a model.\n        ids (list[str]): Optional; List of IDs defining the origin of samples to the model.\n            Maybe either patch IDs or scene tags.\n        mode (str): Optional; Mode samples are from. Must be 'train', 'val' or 'test'.\n        bounds (np.ndarray[BoundingBox]): Optional; Array of objects describing a geospatial bounding box for\n            each sample. Must contain `minx`, `maxx`, `miny` and `maxy` parameters.\n        probs (list or np.ndarray): Optional; Array of probabilistic predicted classes from model where each sample\n            should have a list of the predicted probability for each class.\n        embeddings (NDArray[Any, Any]): Embeddings from the model to visualise with TSNE clustering.\n        class_names (dict): Optional; Dictionary mapping class labels to class names.\n        colours (dict): Optional; Dictionary mapping class labels to colours.\n        save (bool): Optional; Whether to save the plots to file.\n        show (bool): Optional; Whether to show the plots.\n        model_name (str): Optional; Name of model. e.g. MLP-MkVI.\n        timestamp (str): Optional; Time and date to be used to identify experiment.\n            If not specified, the current date-time is used.\n        results_dir (Union[list[str], str, Path]): Optional; Path to the directory for storing plots.\n\n    Notes:\n        save = True, show = False regardless of input for plots made for each sample such as PvT or Mask plots.\n\n    Returns:\n        None\n    \"\"\"\n    if not show:\n        # Ensures that there is no attempt to display figures incase no display is present.\n        try:\n            mlp.use(\"agg\")\n        except ImportError:  # pragma: no cover\n            pass\n\n    flat_z = None\n    flat_y = None\n\n    if z is not None:\n        flat_z = utils.batch_flatten(z)\n\n    if y is not None:\n        flat_y = utils.batch_flatten(y)\n\n    if timestamp is None:\n        timestamp = utils.timestamp_now(fmt=\"%d-%m-%Y_%H%M\")\n\n    if model_name is None:\n        model_name = CONFIG[\"model_name\"]\n    assert model_name is not None\n\n    if results_dir is None:\n        results_dir = CONFIG[\"dir\"][\"results\"]\n        assert isinstance(results_dir, (Sequence, str, Path))\n\n    filenames = format_plot_names(model_name, timestamp, results_dir)\n\n    try:\n        os.mkdir(universal_path(results_dir))\n    except FileExistsError as err:\n        print(err)\n\n    if plots.get(\"History\", False):\n        assert metrics is not None\n\n        print(\"\\nPLOTTING MODEL HISTORY\")\n        plot_history(metrics, filename=filenames[\"History\"], save=save, show=show)\n\n    if plots.get(\"CM\", False):\n        assert class_names is not None\n        assert flat_y is not None\n        assert flat_z is not None\n\n        print(\"\\nPLOTTING CONFUSION MATRIX\")\n        make_confusion_matrix(\n            labels=flat_y,\n            pred=flat_z,\n            classes=class_names,\n            filename=filenames[\"CM\"],\n            save=save,\n            show=show,\n        )\n\n    if plots.get(\"Pred\", False):\n        assert class_names is not None\n        assert colours is not None\n        assert flat_z is not None\n\n        print(\"\\nPLOTTING CLASS DISTRIBUTION OF PREDICTIONS\")\n        plot_subpopulations(\n            utils.find_modes(flat_z),\n            class_names=class_names,\n            cmap_dict=colours,\n            filename=filenames[\"Pred\"],\n            save=save,\n            show=show,\n        )\n\n    if plots.get(\"ROC\", False):\n        assert class_names is not None\n        assert colours is not None\n        assert probs is not None\n        assert flat_y is not None\n\n        print(\"\\nPLOTTING ROC CURVES\")\n        make_roc_curves(\n            probs,\n            flat_y,\n            class_names=class_names,\n            colours=colours,\n            filename=filenames[\"ROC\"],\n            micro=plots[\"micro\"],\n            macro=plots[\"macro\"],\n            save=save,\n            show=show,\n        )\n\n    if plots.get(\"Mask\", False):\n        assert class_names is not None\n        assert colours is not None\n        assert z is not None\n        assert y is not None\n        assert ids is not None\n        assert bounds is not None\n        assert mode is not None\n\n        figsize = None\n        if DATA_CONFIG is not None:\n            figsize = DATA_CONFIG[\"fig_sizes\"][\"Mask\"]\n\n        flat_bbox = utils.batch_flatten(bounds)\n        os.makedirs(universal_path(results_dir) / \"Masks\", exist_ok=True)\n        seg_plot(\n            z,\n            y,\n            ids,\n            flat_bbox,\n            mode,\n            fn_prefix=filenames[\"Mask\"],\n            classes=class_names,\n            colours=colours,\n            fig_dim=figsize,\n        )\n\n    if plots.get(\"TSNE\", False):\n        assert embeddings is not None\n        assert bounds is not None\n        assert mode is not None\n\n        print(\"\\nPERFORMING TSNE CLUSTERING\")\n        plot_embedding(\n            embeddings,\n            bounds,\n            mode,\n            show=show,\n            save=save,\n            filename=filenames[\"TSNE\"],\n        )\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 50011,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n#\n# TODO: Reduce boilerplate.\n#\n\"\"\"Module to visualise .tiff images, label masks and results from the fitting of neural networks for remote sensing.\n\nAttributes:\n    DATA_CONFIG (dict): Config defining the properties of the data used in the experiment.\n    IMAGERY_CONFIG (dict): Config defining the properties of the imagery used in the experiment.\n    DATA_DIR (list): Path to directory holding dataset.\n    BAND_IDS (dict): Band IDs and position in sample image.\n    MAX_PIXEL_VALUE (int): Maximum pixel value (e.g. 255 for 8-bit integer).\n    WGS84 (CRS): WGS84 co-ordinate reference system acting as a default CRS for transformations.\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"DATA_CONFIG\",\n    \"IMAGERY_CONFIG\",\n    \"DATA_DIR\",\n    \"BAND_IDS\",\n    \"MAX_PIXEL_VALUE\",\n    \"WGS84\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport os\nimport random\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Sequence, Tuple, Union\n\nimport imageio\nimport matplotlib as mlp\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nfrom alive_progress import alive_bar\nfrom matplotlib import offsetbox\nfrom matplotlib.colors import Colormap, ListedColormap\nfrom matplotlib.gridspec import GridSpec\nfrom matplotlib.image import AxesImage\nfrom matplotlib.ticker import MaxNLocator\nfrom matplotlib.transforms import Bbox\nfrom nptyping import Float, Int, NDArray, Shape\nfrom numpy.typing import ArrayLike\nfrom rasterio.crs import CRS\nfrom scipy import stats\nfrom torchgeo.datasets.utils import BoundingBox\n\nfrom minerva.utils import AUX_CONFIGS, CONFIG, universal_path, utils\n\n# =====================================================================================================================\n#                                                     GLOBALS\n# =====================================================================================================================\nDATA_CONFIG = AUX_CONFIGS.get(\"data_config\")\nIMAGERY_CONFIG = AUX_CONFIGS[\"imagery_config\"]\n\n# Path to directory holding dataset.\nDATA_DIR = CONFIG[\"dir\"][\"data\"]\n\n# Band IDs and position in sample image.\nBAND_IDS = IMAGERY_CONFIG[\"data_specs\"][\"band_ids\"]\n\n# Maximum pixel value (e.g. 255 for 8-bit integer).\nMAX_PIXEL_VALUE = IMAGERY_CONFIG[\"data_specs\"][\"max_value\"]\n\nWGS84 = CRS.from_epsg(4326)\n\n# Automatically fixes the layout of the figures to accommodate the colour bar legends.\nplt.rcParams[\"figure.constrained_layout.use\"] = True\n\n# Increases DPI to avoid strange plotting errors for class heatmaps.\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"savefig.dpi\"] = 300\n\n# Removes margin in x-axis of plots.\nplt.rcParams[\"axes.xmargin\"] = 0\n\n# Filters out all TensorFlow messages other than errors.\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\n_MAX_SAMPLES = 25\n\n\n# =====================================================================================================================\n#                                                     METHODS\n# =====================================================================================================================\ndef de_interlace(x: Sequence[Any], f: int) -> NDArray[Any, Any]:\n    \"\"\"Separates interlaced arrays, ``x`` at a frequency of ``f`` from each other.\n\n    Args:\n        x (Sequence): Array of data to be de-interlaced.\n        f (int): Frequency at which interlacing occurs. Equivalent to number of sources interlaced together.\n\n    Returns:\n        NDArray: De-interlaced array. Each source array is now sequentially connected.\n    \"\"\"\n    new_x: List[NDArray[Any, Any]] = []\n    for i in range(f):\n        x_i = []\n        for j in np.arange(start=i, stop=len(x), step=f):\n            x_i.append(x[j])\n        new_x.append(np.array(x_i).flatten())\n\n    return np.array(new_x).flatten()\n\n\ndef dec_extent_to_deg(\n    shape: Tuple[int, int],\n    bounds: BoundingBox,\n    src_crs: CRS,\n    new_crs: CRS = WGS84,\n    spacing: int = 32,\n) -> Tuple[Tuple[int, int, int, int], NDArray[Any, Float], NDArray[Any, Float]]:\n    \"\"\"Gets the extent of the image with ``shape`` and with ``bounds`` in latitude, longitude of system ``new_crs``.\n\n    Args:\n        shape (Tuple[int, int]): 2D shape of image to be used to define the extents of the composite image.\n        bounds (BoundingBox): Object describing a geospatial bounding box.\n            Must contain ``minx``, ``maxx``, ``miny`` and ``maxy`` parameters.\n        src_crs (CRS): Source co-ordinate reference system (CRS).\n        new_crs (CRS): Optional; The co-ordinate reference system (CRS) to transform to.\n        spacing (int): Spacing of the lat - lon ticks.\n\n    Returns:\n        Tuple[Tuple[int, int, int, int], NDArray[Any, Float], NDArray[Any, Float]]:\n            * The corners of the image in pixel co-ordinates e.g. ``(0, 256, 0, 256)``.\n            * The latitude extent of the image with ticks at intervals defined by ``spacing``.\n            * The longitude extent of the image with ticks at intervals defined by ``spacing``.\n    \"\"\"\n    # Defines the 'extent' for a composite image based on the size of shape.\n    extent = 0, shape[0], 0, shape[1]\n\n    # Gets the co-ordinates of the corners of the image in decimal lat-lon.\n    corners = utils.transform_coordinates(\n        x=[bounds.minx, bounds.maxx],\n        y=[bounds.miny, bounds.maxy],\n        src_crs=src_crs,\n        new_crs=new_crs,\n    )\n\n    # Creates a discrete mapping of the spaced ticks to latitude longitude extent of the image.\n    lat_extent = np.around(\n        np.linspace(\n            start=corners[1][0],\n            stop=corners[1][1],\n            num=int(shape[0] / spacing) + 1,\n            endpoint=True,\n        ),\n        decimals=3,\n    )\n    lon_extent = np.around(\n        np.linspace(\n            start=corners[0][0],\n            stop=corners[0][1],\n            num=int(shape[0] / spacing) + 1,\n            endpoint=True,\n        ),\n        decimals=3,\n    )\n\n    return extent, lat_extent, lon_extent\n\n\ndef get_mlp_cmap(\n    cmap_style: Optional[Union[Colormap, str]] = None, n_classes: Optional[int] = None\n) -> Optional[Colormap]:\n    \"\"\"Creates a cmap from query\n\n    Args:\n        cmap_style (Union[Colormap, str]): Optional; :mod:`matplotlib` colourmap style to get.\n        n_classes (int): Optional; Number of classes in data to assign colours to.\n\n    Returns:\n        Union[Colormap, None]:\n        * If ``cmap_style`` and ``n_classes`` provided, returns a :class:`ListedColormap` instance.\n        * If ``cmap_style`` provided but no ``n_classes``, returns a :class:`Colormap` instance.\n        * If neither arguments are provided, ``None`` is returned.\n    \"\"\"\n    cmap: Optional[Colormap] = None\n\n    if cmap_style:\n        if isinstance(cmap_style, str):\n            cmap = mlp.colormaps[cmap_style]  # type: ignore\n        else:\n            cmap = cmap_style\n\n        if n_classes:\n            assert isinstance(cmap, Colormap)\n            cmap = cmap.resampled(n_classes)  # type: ignore\n\n    return cmap\n\n\ndef discrete_heatmap(\n    data: NDArray[Shape[\"*, *\"], Int],  # noqa: F722\n    classes: Union[List[str], Tuple[str, ...]],\n    cmap_style: Optional[Union[str, ListedColormap]] = None,\n    block_size: int = 32,\n) -> None:\n    \"\"\"Plots a heatmap with a discrete colour bar. Designed for Radiant Earth MLHub 256x256 SENTINEL images.\n\n    Args:\n        data (NDArray[Shape[*, *], Int]): 2D Array of data to be plotted as a heat map.\n        classes (list[str]): Optional; List of all possible class labels.\n        cmap_style (str, ListedColormap): Optional; Name or object for colour map style.\n        block_size (int): Optional; Size of block image subdivision in pixels.\n\n    Returns:\n        None\n    \"\"\"\n    # Initialises a figure.\n    plt.figure()\n\n    # Creates a cmap from query.\n    cmap = get_mlp_cmap(cmap_style, len(classes))\n\n    # Plots heatmap onto figure.\n    heatmap = plt.imshow(data, cmap=cmap, vmin=-0.5, vmax=len(classes) - 0.5)  # type: ignore[arg-type]\n\n    # Sets tick intervals to block size. Default 32 x 32.\n    plt.xticks(np.arange(0, data.shape[0] + 1, block_size))\n    plt.yticks(np.arange(0, data.shape[1] + 1, block_size))\n\n    # Add grid overlay.\n    plt.grid(which=\"both\", color=\"#CCCCCC\", linestyle=\":\")\n\n    # Plots colour bar onto figure.\n    clb = plt.colorbar(heatmap, ticks=np.arange(0, len(classes)), shrink=0.77)\n\n    # Sets colour bar ticks to class labels.\n    clb.ax.set_yticklabels(classes)\n\n    # Display figure.\n    plt.show()\n\n    # Close figure.\n    plt.close()\n\n\ndef stack_rgb(\n    image: NDArray[Shape[\"3, *, *\"], Float],  # noqa: F722\n    rgb: Dict[str, int] = BAND_IDS,\n    max_value: int = MAX_PIXEL_VALUE,\n) -> NDArray[Shape[\"*, *, 3\"], Float]:  # noqa: F722\n    \"\"\"Stacks together red, green and blue image bands to create a RGB array.\n\n    Args:\n        image (NDArray[Shape[3, *, *], Float]): Image of separate channels to be normalised\n            and reshaped into stacked RGB image.\n        rgb (Dict[str, int]): Optional; Dictionary of which channels in image are the R, G & B bands.\n        max_value (int): Optional; The maximum pixel value in ``image``. e.g. for 8 bit this will be 255.\n\n    Returns:\n        NDArray[Shape[*, *, 3], Float]: Normalised and stacked red, green, blue arrays into RGB array.\n    \"\"\"\n\n    # Extract R, G, B bands from image and normalise.\n    channels: List[Any] = []\n    for channel in [\"R\", \"G\", \"B\"]:\n        band = image[rgb[channel]] / max_value\n        channels.append(band)\n\n    # Stack together RGB bands.\n    # Note that it has to be order BGR not RGB due to the order numpy stacks arrays.\n    rgb_image: NDArray[Shape[\"3, *, *\"], Any] = np.dstack(  # noqa: F722\n        (channels[2], channels[1], channels[0])\n    )\n    assert isinstance(rgb_image, np.ndarray)\n    return rgb_image\n\n\ndef make_rgb_image(\n    image: NDArray[Shape[\"3, *, *\"], Float],  # noqa: F722\n    rgb: Dict[str, int],\n    block_size: int = 32,\n) -> AxesImage:\n    \"\"\"Creates an RGB image from a composition of red, green and blue bands.\n\n    Args:\n        image (np.ndarray[int]): Array representing the image of shape (bands x height x width).\n        rgb (dict): Dictionary of channel numbers of R, G & B bands within ``image``.\n        block_size (int): Optional; Size of block image sub-division in pixels.\n\n    Returns:\n        AxesImage: Plotted RGB image object.\n    \"\"\"\n    # Stack RGB image data together.\n    rgb_image_array = stack_rgb(image, rgb)\n\n    # Create RGB image.\n    rgb_image = plt.imshow(rgb_image_array)\n\n    # Sets tick intervals to block size. Default 32 x 32.\n    plt.xticks(np.arange(0, rgb_image_array.shape[0] + 1, block_size))\n    plt.yticks(np.arange(0, rgb_image_array.shape[1] + 1, block_size))\n\n    # Add grid overlay.\n    plt.grid(which=\"both\", color=\"#CCCCCC\", linestyle=\":\")\n\n    plt.show()\n\n    return rgb_image\n\n\ndef labelled_rgb_image(\n    image: NDArray[Shape[\"*, *, 3\"], Float],  # noqa: F722\n    mask: NDArray[Shape[\"*, *\"], Int],  # noqa: F722\n    bounds: BoundingBox,\n    src_crs: CRS,\n    path: Union[str, Path],\n    name: str,\n    classes: Union[List[str], Tuple[str, ...]],\n    cmap_style: Optional[Union[str, ListedColormap]] = None,\n    new_crs: Optional[CRS] = WGS84,\n    block_size: int = 32,\n    alpha: float = 0.5,\n    show: bool = True,\n    save: bool = True,\n    figdim: Tuple[Union[int, float], Union[int, float]] = (8.02, 10.32),\n) -> str:\n    \"\"\"Produces a layered image of an RGB image, and it's associated label mask heat map alpha blended on top.\n\n    Args:\n        image (np.ndarray[int]): Array representing the image of shape (height x width x bands).\n        mask (np.ndarray[int]): Ground truth mask. Should be of shape (height x width) matching ``image``.\n        bounds (BoundingBox): Object describing a geospatial bounding box.\n            Must contain ``minx``, ``maxx``, ``miny`` and ``maxy`` parameters.\n        src_crs (CRS): Source co-ordinate reference system (CRS).\n        path (str): Path to where to save created figure.\n        name (str): Name of figure. Will be used for title and in the filename.\n        classes (list[str]): Optional; List of all possible class labels.\n        cmap_style (str or ListedColormap): Optional; Name or object for colour map style.\n        new_crs (CRS): Optional; The co-ordinate reference system (CRS) to transform to.\n        block_size (int): Optional; Size of block image subdivision in pixels.\n        alpha (float): Optional; Fraction determining alpha blending of label mask.\n        show (bool): Optional; ``True`` for show figure when plotted. ``False`` if not.\n        save (bool): Optional; ``True`` to save figure to file. ``False`` if not.\n        figdim (tuple): Optional; Figure (height, width) in inches.\n\n    Returns:\n        str: Path to figure save location.\n    \"\"\"\n    # Checks that the mask and image shapes will align.\n    assert mask.shape == image.shape[:2]\n\n    assert new_crs is not None\n\n    # Gets the extent of the image in pixel, lattitude and longitude dimensions.\n    extent, lat_extent, lon_extent = dec_extent_to_deg(\n        mask.shape,\n        bounds=bounds,\n        src_crs=src_crs,\n        spacing=block_size,\n        new_crs=new_crs,\n    )\n\n    # Initialises a figure.\n    fig, ax1 = plt.subplots()\n\n    # Create RGB image.\n    ax1.imshow(image, extent=extent)\n\n    # Creates a cmap from query.\n    cmap = get_mlp_cmap(cmap_style, len(classes))\n\n    # Plots heatmap onto figure.\n    heatmap = ax1.imshow(\n        mask, cmap=cmap, vmin=-0.5, vmax=len(classes) - 0.5, extent=extent, alpha=alpha  # type: ignore[arg-type]\n    )\n\n    # Sets tick intervals to standard 32x32 block size.\n    ax1.set_xticks(np.arange(0, mask.shape[0] + 1, block_size))\n    ax1.set_yticks(np.arange(0, mask.shape[1] + 1, block_size))\n\n    # Creates a secondary x and y-axis to hold lat-lon.\n    ax2 = ax1.twiny().twinx()\n\n    # Plots an invisible line across the diagonal of the image to create the secondary axis for lat-lon.\n    ax2.plot(\n        lon_extent,\n        lat_extent,\n        \" \",\n        clip_box=Bbox.from_extents(\n            lon_extent[0], lat_extent[0], lon_extent[-1], lat_extent[-1]\n        ),\n    )\n\n    # Set ticks for lat-lon.\n    ax2.set_xticks(lon_extent)\n    ax2.set_yticks(lat_extent)\n\n    print(f\"{lat_extent=}\")\n    print(f\"{lon_extent=}\")\n\n    # Sets the limits of the secondary axis, so they should align with the primary.\n    ax2.set_xlim(left=lon_extent[0], right=lon_extent[-1])\n    ax2.set_ylim(top=lat_extent[-1], bottom=lat_extent[0])\n\n    # Converts the decimal lat-lon into degrees, minutes, seconds to label the axis.\n    lat_labels = utils.dec2deg(lat_extent, axis=\"lat\")\n    lon_labels = utils.dec2deg(lon_extent, axis=\"lon\")\n\n    # Sets the secondary axis tick labels.\n    ax2.set_xticklabels(lon_labels, fontsize=11)\n    ax2.set_yticklabels(lat_labels, fontsize=10, rotation=-30, ha=\"left\")\n\n    # Add grid overlay.\n    ax1.grid(which=\"both\", color=\"#CCCCCC\", linestyle=\":\")\n\n    # Plots colour bar onto figure.\n    clb = plt.colorbar(\n        heatmap, ticks=np.arange(0, len(classes)), shrink=0.9, aspect=75, drawedges=True\n    )\n\n    # Sets colour bar ticks to class labels.\n    clb.ax.set_yticklabels(classes, fontsize=11)\n\n    # Bodge to get a figure title by using the colour bar title.\n    clb.ax.set_title(f\"{name}\\nLand Cover\", loc=\"left\", fontsize=15)\n\n    # Set axis labels.\n    ax1.set_xlabel(\"(x) - Pixel Position\", fontsize=14)\n    ax1.set_ylabel(\"(y) - Pixel Position\", fontsize=14)\n    ax2.set_ylabel(\"Latitude\", fontsize=14, rotation=270, labelpad=12)\n    ax2.set_title(\"Longitude\")  # Bodge\n\n    # Manual trial and error fig size which fixes aspect ratio issue.\n    fig.set_figheight(figdim[0])\n    fig.set_figwidth(figdim[1])\n\n    # Display figure.\n    if show:\n        plt.show()\n\n    # Path and file name of figure.\n    fn = f\"{path}/{name}_RGBHM.png\"\n\n    # If true, save file to fn.\n    if save:\n        # Checks if file already exists. Deletes if true.\n        utils.exist_delete_check(fn)\n\n        # Save figure to fn.\n        fig.savefig(fn)\n\n    # Close figure.\n    plt.close()\n\n    return fn\n\n\ndef make_gif(\n    dates: Sequence[str],\n    images: NDArray[Shape[\"*, *, *, 3\"], Any],  # noqa: F722\n    masks: NDArray[Shape[\"*, *, *\"], Any],  # noqa: F722\n    bounds: BoundingBox,\n    src_crs: CRS,\n    classes: Union[List[str], Tuple[str, ...]],\n    gif_name: str,\n    path: Union[str, Path],\n    cmap_style: Optional[Union[str, ListedColormap]] = None,\n    fps: float = 1.0,\n    new_crs: Optional[CRS] = WGS84,\n    alpha: float = 0.5,\n    figdim: Tuple[Union[int, float], Union[int, float]] = (8.02, 10.32),\n) -> None:\n    \"\"\"Wrapper to :func:`labelled_rgb_image` to make a GIF for a patch out of scenes.\n\n    Args:\n        dates (Sequence[str]): Dates of scenes to be used as the frames in the GIF.\n        images (NDArray[Shape[*, *, *, 3], Any]): All the frames of imagery to make the GIF from.\n            Leading dimension must be the same length as ``dates`` and ``masks``.\n        masks (NDArray[Shape[*, *, *, 3], Any]): The masks for each frame of the GIF.\n            Leading dimension must be the same length as ``dates`` and ``image``.\n        bounds (BoundingBox): The bounding box (in the ``src_crs`` CRS) of the patch the GIF will be of.\n        src_crs (CRS): Source co-ordinate reference system (CRS).\n        classes (list[str]): List of all possible class labels.\n        gif_name (str): Path to and name of GIF to be made.\n        path (Union[Path, str]): Path to where to save frames of the GIF.\n        cmap_style (str or ListedColormap): Optional; Name or object for colour map style.\n        fps (float): Optional; Frames per second of GIF.\n        new_crs (CRS): Optional; The co-ordinate reference system (CRS) to transform to.\n        alpha (float): Optional; Fraction determining alpha blending of label mask.\n        figdim (tuple): Optional; Figure (height, width) in inches.\n\n    Returns:\n        None\n    \"\"\"\n    # Initialise progress bar.\n    with alive_bar(len(dates), bar=\"blocks\") as bar:\n\n        # List to hold filenames and paths of images created.\n        frames = []\n        for i in range(len(dates)):\n            # Update progress bar with current scene.\n            bar.text(\"SCENE ON %s\" % dates[i])\n\n            # Create a frame of the GIF for a scene of the patch.\n            frame = labelled_rgb_image(\n                images[i],\n                masks[i],\n                bounds,\n                src_crs,\n                path,\n                name=f\"{i}\",\n                classes=classes,\n                cmap_style=cmap_style,\n                new_crs=new_crs,\n                alpha=alpha,\n                save=True,\n                show=False,\n                figdim=figdim,\n            )\n\n            # Read in frame just created and add to list of frames.\n            frames.append(imageio.imread(frame))\n\n            # Update bar with step completion.\n            bar()\n\n    # Checks GIF doesn't already exist. Deletes if it does.\n    utils.exist_delete_check(gif_name)\n\n    # Create a 'unknown' bar to 'spin' while the GIF is created.\n    with alive_bar(unknown=\"waves\") as bar:\n        # Add current operation to spinner bar.\n        bar.text(\"MAKING PATCH GIF\")\n\n        # Create GIF.\n        imageio.mimwrite(gif_name, frames, format=\".gif\", fps=fps)  # type: ignore\n\n\ndef prediction_plot(\n    sample: Dict[str, Any],\n    sample_id: str,\n    classes: Dict[int, str],\n    src_crs: CRS,\n    new_crs: CRS = WGS84,\n    cmap_style: Optional[Union[str, ListedColormap]] = None,\n    exp_id: Optional[str] = None,\n    fig_dim: Optional[Tuple[Union[int, float], Union[int, float]]] = None,\n    block_size: int = 32,\n    show: bool = True,\n    save: bool = True,\n    fn_prefix: Optional[str] = None,\n) -> None:\n    \"\"\"\n    Produces a figure containing subplots of the predicted label mask, the ground truth label mask\n    and a reference RGB image of the same patch.\n\n    Args:\n        sample (dict[str, Any]): Dictionary holding the `image`, ground truth (`mask`) and predicted (`pred`) masks\n            and the bounding box for this sample.\n        sample_id (str): ID for the sample.\n        classes (dict[str]): Dictionary mapping class labels to class names.\n        src_crs (CRS): Existing co-ordinate system of the image.\n        new_crs(CRS): Optional; Co-ordinate system to convert image to and use for labelling.\n        exp_id (str): Optional; Unique ID for the experiment run that predictions and labels come from.\n        block_size (int): Optional; Size of block image sub-division in pixels.\n        cmap_style (str, ListedColormap): Optional; Name or object for colour map style.\n        show (bool): Optional; True for show figure when plotted. False if not.\n        save (bool): Optional; True to save figure to file. False if not.\n        fig_dim (Tuple[float, float]): Optional; Figure (height, width) in inches.\n        fn_prefix (str): Optional; Common filename prefix (including path to file) for all plots of this type\n            from this experiment. Appended with the sample ID to give the filename to save the plot to.\n\n    Returns:\n        None\n    \"\"\"\n    # Stacks together the R, G, & B bands to form an array of the RGB image.\n    rgb_image = sample[\"image\"]\n    z = sample[\"pred\"]\n    y = sample[\"mask\"]\n    bounds = sample[\"bounds\"]\n\n    extent, lat_extent, lon_extent = dec_extent_to_deg(\n        y.shape, bounds, src_crs, new_crs=new_crs, spacing=block_size\n    )\n\n    centre = utils.transform_coordinates(\n        *utils.get_centre_loc(bounds), src_crs=src_crs, new_crs=new_crs\n    )\n\n    # Initialises a figure.\n    fig = plt.figure(figsize=fig_dim)\n\n    gs = GridSpec(nrows=2, ncols=2, figure=fig)\n\n    axes: NDArray[Shape[\"3\"], Any] = np.array(\n        [\n            fig.add_subplot(gs[0, 0]),\n            fig.add_subplot(gs[0, 1]),\n            fig.add_subplot(gs[1, :]),\n        ]\n    )\n\n    cmap = get_mlp_cmap(cmap_style, len(classes))\n\n    # Plots heatmap onto figure.\n    z_heatmap = axes[0].imshow(z, cmap=cmap, vmin=-0.5, vmax=len(classes) - 0.5)\n    _ = axes[1].imshow(y, cmap=cmap, vmin=-0.5, vmax=len(classes) - 0.5)\n\n    # Create RGB image.\n    axes[2].imshow(rgb_image, extent=extent)\n\n    # Sets tick intervals to standard 32x32 block size.\n    axes[0].set_xticks(np.arange(0, z.shape[0] + 1, block_size))\n    axes[0].set_yticks(np.arange(0, z.shape[1] + 1, block_size))\n\n    axes[1].set_xticks(np.arange(0, y.shape[0] + 1, block_size))\n    axes[1].set_yticks(np.arange(0, y.shape[1] + 1, block_size))\n\n    axes[2].set_xticks(np.arange(0, rgb_image.shape[0] + 1, block_size))\n    axes[2].set_yticks(np.arange(0, rgb_image.shape[1] + 1, block_size))\n\n    # Add grid overlay.\n    axes[0].grid(which=\"both\", color=\"#CCCCCC\", linestyle=\":\")\n    axes[1].grid(which=\"both\", color=\"#CCCCCC\", linestyle=\":\")\n    axes[2].grid(which=\"both\", color=\"#CCCCCC\", linestyle=\":\")\n\n    # Converts the decimal lat-lon into degrees, minutes, seconds to label the axis.\n    lat_labels = utils.dec2deg(lat_extent, axis=\"lat\")\n    lon_labels = utils.dec2deg(lon_extent, axis=\"lon\")\n\n    # Sets the secondary axis tick labels.\n    axes[2].set_xticklabels(lon_labels, fontsize=9, rotation=30)\n    axes[2].set_yticklabels(lat_labels, fontsize=9)\n\n    # Plots colour bar onto figure.\n    clb = fig.colorbar(\n        z_heatmap,\n        ax=axes.ravel().tolist(),\n        location=\"top\",\n        ticks=np.arange(0, len(classes)),\n        aspect=75,\n        drawedges=True,\n    )\n\n    # Sets colour bar ticks to class labels.\n    clb.ax.set_xticklabels(classes.values(), fontsize=9)\n\n    # Set figure title and subplot titles.\n    fig.suptitle(\n        f\"{sample_id}: {utils.lat_lon_to_loc(lat=str(centre[1]), lon=str(centre[0]))}\",\n        fontsize=15,\n    )\n    axes[0].set_title(\"Predicted\", fontsize=13)\n    axes[1].set_title(\"Ground Truth\", fontsize=13)\n    axes[2].set_title(\"Reference Imagery\", fontsize=13)\n\n    # Set axis labels.\n    axes[0].set_xlabel(\"(x) - Pixel Position\", fontsize=10)\n    axes[0].set_ylabel(\"(y) - Pixel Position\", fontsize=10)\n    axes[1].set_xlabel(\"(x) - Pixel Position\", fontsize=10)\n    axes[1].set_ylabel(\"(y) - Pixel Position\", fontsize=10)\n    axes[2].set_xlabel(\"Longitude\", fontsize=10)\n    axes[2].set_ylabel(\"Latitude\", fontsize=10)\n\n    # Display figure.\n    if show:\n        plt.show()\n\n    if fn_prefix is None:\n        path = universal_path(CONFIG[\"dir\"][\"results\"])\n        fn_prefix = str(path / f\"{exp_id}_{utils.timestamp_now()}_Mask\")\n\n    # Path and file name of figure.\n    fn = f\"{fn_prefix}_{sample_id}.png\"\n\n    # If true, save file to fn.\n    if save:\n        # Checks if file already exists. Deletes if true.\n        utils.exist_delete_check(fn)\n\n        # Save figure to fn.\n        fig.savefig(fn)\n\n    # Close figure.\n    plt.close()\n\n\ndef seg_plot(\n    z: Union[List[int], NDArray[Any, Any]],\n    y: Union[List[int], NDArray[Any, Any]],\n    ids: List[str],\n    bounds: Union[Sequence[Any], NDArray[Any, Any]],\n    mode: str,\n    classes: Dict[int, str],\n    colours: Dict[int, str],\n    fn_prefix: str,\n    frac: float = 0.05,\n    fig_dim: Optional[Tuple[Union[int, float], Union[int, float]]] = (9.3, 10.5),\n) -> None:\n    \"\"\"Custom function for pre-processing the outputs from image segmentation testing for data visualisation.\n\n    Args:\n        z (list[float]): Predicted segmentation masks by the network.\n        y (list[float]): Corresponding ground truth masks.\n        ids (list[str]): Corresponding patch IDs for the test data supplied to the network.\n        bounds (list[BoundingBox] or np.ndarray[BoundingBox]): Array of objects describing a geospatial bounding box.\n            Must contain `minx`, `maxx`, `miny` and `maxy` parameters.\n        mode (str): Mode samples are from. Must be 'train', 'val' or 'test'.\n        classes (dict): Dictionary mapping class labels to class names.\n        colours (dict): Dictionary mapping class labels to colours.\n        fn_prefix (str): Common filename prefix (including path to file) for all plots of this type\n            from this experiment to use.\n        frac (float): Optional; Fraction of patch samples to plot.\n        fig_dim (tuple[float, float]): Optional; Figure (height, width) in inches.\n\n    Returns:\n        None\n    \"\"\"\n    # TODO: This is a very naughty way of avoiding a circular import.\n    # Need to reorganise package to avoid need for this.\n    from minerva.datasets import make_dataset\n\n    if not isinstance(z, np.ndarray):\n        z = np.array(z)\n\n    if not isinstance(y, np.ndarray):\n        y = np.array(y)\n\n    z = np.reshape(z, (z.shape[0] * z.shape[1], z.shape[2], z.shape[3]))\n    y = np.reshape(y, (y.shape[0] * y.shape[1], y.shape[2], y.shape[3]))\n    flat_ids: NDArray[Any, Any] = np.array(ids).flatten()\n\n    print(\"\\nRE-CONSTRUCTING DATASET\")\n    dataset, _ = make_dataset(CONFIG[\"dir\"][\"data\"], CONFIG[\"dataset_params\"][mode])\n\n    # Create a new projection system in lat-lon.\n    crs = dataset.crs\n\n    print(\"\\nPRODUCING PREDICTED MASKS\")\n\n    # Limits number of masks to produce to a fractional number of total and no more than `_MAX_SAMPLES`.\n    n_samples = int(frac * len(flat_ids))\n    if n_samples > _MAX_SAMPLES:\n        n_samples = _MAX_SAMPLES\n\n    # Initialises a progress bar for the epoch.\n    with alive_bar(n_samples, bar=\"blocks\") as bar:\n\n        # Plots the predicted versus ground truth labels for all test patches supplied.\n        for i in random.sample(range(len(flat_ids)), n_samples):\n            image = stack_rgb(dataset[bounds[i]][\"image\"].numpy())\n            sample = {\"image\": image, \"pred\": z[i], \"mask\": y[i], \"bounds\": bounds[i]}\n\n            prediction_plot(\n                sample,\n                flat_ids[i],\n                classes=classes,\n                src_crs=crs,\n                exp_id=CONFIG[\"model_name\"],\n                show=False,\n                fn_prefix=fn_prefix,\n                fig_dim=fig_dim,\n                cmap_style=ListedColormap(colours.values(), N=len(colours)),  # type: ignore\n            )\n\n            bar()\n\n\ndef plot_subpopulations(\n    class_dist: List[Tuple[int, int]],\n    class_names: Dict[int, str],\n    cmap_dict: Dict[int, str],\n    filename: Optional[Union[str, Path]] = None,\n    save: bool = True,\n    show: bool = False,\n) -> None:\n    \"\"\"Creates a pie chart of the distribution of the classes within the data.\n\n    Args:\n        class_dist (list[tuple[int, int]]): Modal distribution of classes in the dataset provided.\n        class_names (dict): Optional; Dictionary mapping class labels to class names.\n        cmap_dict (dict): Optional; Dictionary mapping class labels to class colours.\n        filename (str): Optional; Name of file to save plot to.\n        show (bool): Optional; Whether to show plot.\n        save (bool): Optional; Whether to save plot to file.\n\n    Returns:\n        None\n    \"\"\"\n    # List to hold the name and percentage distribution of each class in the data as str.\n    class_data = []\n\n    # List to hold the total counts of each class.\n    counts = []\n\n    # List to hold colours of classes in the correct order.\n    colours = []\n\n    # Finds total number of samples to normalise data.\n    n_samples = 0\n    for mode in class_dist:\n        n_samples += mode[1]\n\n    # For each class, find the percentage of data that is that class and the total counts for that class.\n    for label in class_dist:\n        # Sets percentage label to <0.01% for classes matching that equality.\n        if (label[1] * 100.0 / n_samples) > 0.01:\n            class_data.append(\n                \"{} \\n{:.2f}%\".format(\n                    class_names[label[0]], (label[1] * 100.0 / n_samples)\n                )\n            )\n        else:\n            class_data.append(\"{} \\n<0.01%\".format(class_names[label[0]]))\n        counts.append(label[1])\n        colours.append(cmap_dict[label[0]])\n\n    # Locks figure size.\n    plt.figure(figsize=(6, 5))\n\n    # Plot a pie chart of the data distribution amongst the classes.\n    patches, _ = plt.pie(\n        counts, colors=colours, explode=[i * 0.05 for i in range(len(class_data))]\n    )\n\n    # Adds legend.\n    plt.legend(\n        patches, class_data, loc=\"center left\", bbox_to_anchor=(1, 0.5), frameon=False\n    )\n\n    # Shows and/or saves plot.\n    if show:\n        plt.show()\n    if save:\n        plt.savefig(filename)\n        plt.close()\n\n\ndef plot_history(\n    metrics: Dict[str, Any],\n    filename: Optional[Union[str, Path]] = None,\n    save: bool = True,\n    show: bool = False,\n) -> None:\n    \"\"\"Plots model history based on metrics supplied.\n\n    Args:\n        metrics (dict): Dictionary containing the names and results of the metrics by which model was assessed.\n        filename (str): Optional; Name of file to save plot to.\n        show (bool): Optional; Whether to show plot.\n        save (bool): Optional; Whether to save plot to file.\n\n    Returns:\n        None\n    \"\"\"\n    # Initialise figure.\n    ax = plt.figure().gca()\n\n    # Plots each metric in metrics, appending their artist handles.\n    handles = []\n    labels = []\n    for key in metrics:\n        # Checks that the length of x matches y and is greater than 1 so can be plotted.\n        if len(metrics[key][\"x\"]) == len(metrics[key][\"y\"]) >= 1.0:\n\n            # Plot metric.\n            handles.append(ax.plot(metrics[key][\"x\"], metrics[key][\"y\"])[0])\n            labels.append(key)\n\n    # Creates legend from plot artist handles and names of metrics.\n    ax.legend(handles=handles, labels=labels)\n\n    # Forces x-axis ticks to be integers.\n    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n\n    # Adds a grid overlay with green dashed lines.\n    ax.grid(color=\"green\", linestyle=\"--\", linewidth=0.5)  # For some funky gridlines\n\n    # Adds axis labels.\n    ax.set_xlabel(\"Epoch\")\n    ax.set_ylabel(\"Loss/Accuracy\")\n\n    # Shows and/or saves plot.\n    if show:\n        plt.show()\n    if save:\n        plt.savefig(filename)\n        plt.close()\n\n\ndef make_confusion_matrix(\n    pred: Union[List[int], NDArray[Any, Int]],\n    labels: Union[List[int], NDArray[Any, Int]],\n    classes: Dict[int, str],\n    filename: Optional[Union[str, Path]] = None,\n    cmap_style: str = \"Blues\",\n    show: bool = True,\n    save: bool = False,\n) -> None:\n    \"\"\"Creates a heat-map of the confusion matrix of the given model.\n\n    Args:\n        pred(list[int]): Predictions made by model on test images.\n        labels (list[int]): Accompanying ground truth labels for testing images.\n        classes (dict): Dictionary mapping class labels to class names.\n        filename (str): Optional; Name of file to save plot to.\n        cmap_style (str): Colourmap style to use in the confusion matrix.\n        show (bool): Optional; Whether to show plot.\n        save (bool): Optional; Whether to save plot to file.\n\n    Returns:\n        None\n    \"\"\"\n    _pred, _labels, new_classes = utils.check_test_empty(pred, labels, classes)\n\n    # Creates the confusion matrix based on these predictions and the corresponding ground truth labels.\n    cm_norm: Any = None\n    try:\n        cm = tf.math.confusion_matrix(\n            labels=_labels, predictions=_pred, dtype=np.uint16  # type: ignore\n        ).numpy()  # type: ignore\n\n        # Normalises confusion matrix.\n        cm_norm = np.around(\n            cm.astype(np.float16) / cm.sum(axis=1)[:, np.newaxis], decimals=2\n        )\n\n    except RuntimeWarning as err:  # pragma: no cover\n        print(\"\\n\", err)\n        print(\"At least one class had no ground truth or no predicted labels!\")\n\n    np.nan_to_num(cm_norm, copy=False)\n\n    # Extract class names from dict in numeric order to ensure labels match matrix.\n    class_names = [new_classes[key] for key in range(len(new_classes.keys()))]\n\n    # Converts confusion matrix to Pandas.DataFrame.\n    cm_df = pd.DataFrame(cm_norm, index=class_names, columns=class_names)\n\n    if DATA_CONFIG is not None:\n        figsize = DATA_CONFIG[\"fig_sizes\"][\"CM\"]\n    else:  # pragma: no cover\n        figsize = None\n\n    # Plots figure.\n    plt.figure(figsize=figsize)\n\n    cmap = get_mlp_cmap(cmap_style)\n    sns.heatmap(\n        cm_df,\n        annot=True,\n        square=True,\n        cmap=cmap,\n        vmin=0.0,\n        vmax=1.0,\n    )\n    plt.ylabel(\"Ground Truth\")\n    plt.xlabel(\"Predicted\")\n\n    # Shows and/or saves plot.\n    if show:\n        plt.show()\n    if save:\n        plt.savefig(filename)\n        plt.close()\n\n\ndef make_roc_curves(\n    probs: ArrayLike,\n    labels: Union[Sequence[int], NDArray[Any, Int]],\n    class_names: Dict[int, str],\n    colours: Dict[int, str],\n    micro: bool = True,\n    macro: bool = True,\n    filename: Optional[str] = None,\n    show: bool = False,\n    save: bool = True,\n) -> None:\n    \"\"\"Plots ROC curves for each class, the micro and macro average ROC curves and accompanying AUCs.\n\n    Adapted from Scikit-learn's example at:\n    https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n\n    Args:\n        probs (list or np.ndarray): Array of probabilistic predicted classes from model where each sample\n            should have a list of the predicted probability for each class.\n        labels (list or np.ndarray): List of corresponding ground truth labels.\n        class_names (dict): Dictionary mapping class labels to class names.\n        colours (dict): Dictionary mapping class labels to colours.\n        micro (bool): Optional; Whether to compute and plot the micro average ROC curves.\n        macro (bool): Optional; Whether to compute and plot the macro average ROC curves.\n        filename (str): Optional; Name of file to save plot to.\n        save (bool): Optional; Whether to save the plots to file.\n        show (bool): Optional; Whether to show the plots.\n\n    Returns:\n        None\n    \"\"\"\n    # Gets the class labels as a list from the class_names dict.\n    class_labels = [key for key in class_names.keys()]\n\n    # Reshapes the probabilities to be (n_samples, n_classes).\n    probs = np.reshape(probs, (len(labels), len(class_labels)))\n\n    # Computes all class, micro and macro average ROC curves and AUCs.\n    fpr, tpr, roc_auc = utils.compute_roc_curves(\n        probs, labels, class_labels, micro=micro, macro=macro\n    )\n\n    # Plot all ROC curves\n    print(\"\\nPlotting ROC Curves\")\n    plt.figure()\n\n    if micro:\n        # Plot micro average ROC curves.\n        plt.plot(\n            fpr[\"micro\"],\n            tpr[\"micro\"],\n            label=\"Micro-average (AUC = {:.2f})\".format(roc_auc[\"micro\"]),\n            color=\"deeppink\",\n            linestyle=\"dotted\",\n        )\n\n    if macro:\n        # Plot macro average ROC curves.\n        plt.plot(\n            fpr[\"macro\"],\n            tpr[\"macro\"],\n            label=\"Macro-average (AUC = {:.2f})\".format(roc_auc[\"macro\"]),\n            color=\"navy\",\n            linestyle=\"dotted\",\n        )\n\n    # Plot all class ROC curves.\n    for key in class_labels:\n        plt.plot(\n            fpr[key],\n            tpr[key],\n            color=colours[key],\n            label=f\"{class_names[key]} \" + \"(AUC = {:.2f})\".format(roc_auc[key]),\n        )\n\n    # Plot random classifier diagonal.\n    plt.plot([0, 1], [0, 1], \"k--\")\n\n    # Set limits.\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n\n    # Set axis labels.\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n\n    # Position legend in lower right corner of figure where no classifiers should exist.\n    plt.legend(loc=\"lower right\")\n\n    # Shows and/or saves plot.\n    if show:\n        plt.show()\n    if save:\n        plt.savefig(filename)\n        print(\"ROC Curves plot SAVED\")\n        plt.close()\n\n\ndef plot_embedding(\n    embeddings: Any,\n    bounds: Union[Sequence[Any], NDArray[Any, Any]],\n    mode: str,\n    title: Optional[str] = None,\n    show: bool = False,\n    save: bool = True,\n    filename: Optional[Union[Path, str]] = None,\n) -> None:\n    \"\"\"Using TSNE Clustering, visualises the embeddings from a model.\n\n    Args:\n        embeddings (Any): Embeddings from a model.\n        bounds (Union[Sequence[Any], NDArray[Any, Any]]): Array of objects describing a geospatial bounding box.\n            Must contain `minx`, `maxx`, `miny` and `maxy` parameters.\n        mode (str): Mode samples are from. Must be 'train', 'val' or 'test'.\n        title (Optional[str], optional): Title of plot.\n        show (bool): Optional; Whether to show plot.\n        save (bool): Optional; Whether to save plot to file.\n        filename (str): Optional; Name of file to save plot to.\n\n    Returns:\n        None\n    \"\"\"\n\n    x = utils.tsne_cluster(embeddings)\n\n    # TODO: This is a very naughty way of avoiding a circular import.\n    # Need to reorganise package to avoid need for this.\n    from minerva.datasets import make_dataset\n\n    print(\"\\nRE-CONSTRUCTING DATASET\")\n    dataset, _ = make_dataset(CONFIG[\"dir\"][\"data\"], CONFIG[\"dataset_params\"][mode])\n\n    images = []\n    targets = []\n\n    # Initialises a progress bar for the epoch.\n    with alive_bar(len(x), bar=\"blocks\") as bar:\n\n        # Plots the predicted versus ground truth labels for all test patches supplied.\n        for i in range(len(x)):\n            sample = dataset[bounds[i]]\n            images.append(stack_rgb(sample[\"image\"].numpy()))\n            targets.append(\n                [\n                    int(stats.mode(mask.flatten(), keepdims=False).mode)\n                    for mask in sample[\"mask\"].numpy()\n                ]\n            )\n\n            bar()\n\n    x_min, x_max = np.min(x, 0), np.max(x, 0)\n    x = (x - x_min) / (x_max - x_min)\n\n    plt.figure(figsize=(10, 10))\n    ax = plt.subplot(111)\n\n    for i in range(len(x)):\n        plt.text(\n            x[i, 0],\n            x[i, 1],\n            str(targets[i]),\n            color=plt.cm.Set1(targets[i][0] / 10.0),  # type: ignore\n            fontdict={\"weight\": \"bold\", \"size\": 9},\n        )\n\n    if hasattr(offsetbox, \"AnnotationBbox\"):\n        # only print thumbnails with matplotlib > 1.0\n        shown_images: NDArray[Any, Any] = np.array([[1.0, 1.0]])  # just something big\n\n        for i in range(len(images)):\n            dist = np.sum((x[i] - shown_images) ** 2, 1)\n            if np.min(dist) < 4e-3:\n                # don’t show points that are too close\n                continue\n\n            shown_images = np.r_[shown_images, [x[i]]]\n            imagebox = offsetbox.AnnotationBbox(\n                offsetbox.OffsetImage(images[i], cmap=plt.cm.gray_r), x[i]  # type: ignore\n            )\n\n            ax.add_artist(imagebox)\n\n    plt.xticks([]), plt.yticks([])  # type: ignore\n\n    if title is not None:\n        plt.title(title)\n\n    # Shows and/or saves plot.\n    if show:\n        plt.show()\n    if save:\n        if filename is None:  # pragma: no cover\n            filename = \"tsne_cluster_vis.png\"\n        os.makedirs(Path(filename).parent, exist_ok=True)\n        plt.savefig(filename)\n        print(\"TSNE cluster visualisation SAVED\")\n        plt.close()\n\n\ndef format_plot_names(\n    model_name: str, timestamp: str, path: Union[Sequence[str], str, Path]\n) -> Dict[str, str]:\n    \"\"\"Creates unique filenames of plots in a standardised format.\n\n    Args:\n        model_name (str): Name of model. e.g. MLP-MkVI.\n        timestamp (str): Time and date to be used to identify experiment.\n        path (Union[list[str], str, Path]): Path to the directory for storing plots as a list of strings for each level.\n\n    Returns:\n        filenames (dict): Formatted filenames for plots.\n    \"\"\"\n\n    def standard_format(plot_type: str, *sub_dir) -> str:\n        \"\"\"Creates a unique filename for a plot in a standardised format.\n\n        Args:\n            plot_type (str): Plot type to use in filename.\n            sub_dir (str): Additional subdirectories to add to path to filename.\n\n        Returns:\n            String of path to filename of the form \"{model_name}_{timestamp}_{plot_type}.{file_ext}\"\n        \"\"\"\n        filename = f\"{model_name}_{timestamp}_{plot_type}\"\n        return str(universal_path(path) / universal_path(sub_dir) / filename)\n\n    filenames = {\n        \"History\": standard_format(\"MH\") + \".png\",\n        \"Pred\": standard_format(\"TP\") + \".png\",\n        \"CM\": standard_format(\"CM\") + \".png\",\n        \"ROC\": standard_format(\"ROC\" + \".png\"),\n        \"Mask\": standard_format(\"Mask\", \"Masks\"),\n        \"PvT\": standard_format(\"PvT\", \"PvTs\"),\n        \"TSNE\": standard_format(\"TSNE\") + \".png\",\n    }\n\n    return filenames\n\n\ndef plot_results(\n    plots: Dict[str, bool],\n    z: Optional[Union[List[int], NDArray[Any, Int]]] = None,\n    y: Optional[Union[List[int], NDArray[Any, Int]]] = None,\n    metrics: Optional[Dict[str, Any]] = None,\n    ids: Optional[List[str]] = None,\n    mode: str = \"test\",\n    bounds: Optional[NDArray[Any, Any]] = None,\n    probs: Optional[Union[List[float], NDArray[Any, Float]]] = None,\n    embeddings: Optional[NDArray[Any, Any]] = None,\n    class_names: Optional[Dict[int, str]] = None,\n    colours: Optional[Dict[int, str]] = None,\n    save: bool = True,\n    show: bool = False,\n    model_name: Optional[str] = None,\n    timestamp: Optional[str] = None,\n    results_dir: Optional[Union[Sequence[str], str, Path]] = None,\n) -> None:\n    \"\"\"Orchestrates the creation of various plots from the results of a model fitting.\n\n    Args:\n        plots (dict): Dictionary defining which plots to make.\n        z (list[list[int]] or np.ndarray[np.ndarray[int]]): List of predicted label masks.\n        y (list[list[int]] or np.ndarray[np.ndarray[int]]): List of corresponding ground truth label masks.\n        metrics (dict): Optional; Dictionary containing a log of various metrics used to assess\n            the performance of a model.\n        ids (list[str]): Optional; List of IDs defining the origin of samples to the model.\n            Maybe either patch IDs or scene tags.\n        mode (str): Optional; Mode samples are from. Must be 'train', 'val' or 'test'.\n        bounds (np.ndarray[BoundingBox]): Optional; Array of objects describing a geospatial bounding box for\n            each sample. Must contain `minx`, `maxx`, `miny` and `maxy` parameters.\n        probs (list or np.ndarray): Optional; Array of probabilistic predicted classes from model where each sample\n            should have a list of the predicted probability for each class.\n        embeddings (NDArray[Any, Any]): Embeddings from the model to visualise with TSNE clustering.\n        class_names (dict): Optional; Dictionary mapping class labels to class names.\n        colours (dict): Optional; Dictionary mapping class labels to colours.\n        save (bool): Optional; Whether to save the plots to file.\n        show (bool): Optional; Whether to show the plots.\n        model_name (str): Optional; Name of model. e.g. MLP-MkVI.\n        timestamp (str): Optional; Time and date to be used to identify experiment.\n            If not specified, the current date-time is used.\n        results_dir (Union[list[str], str, Path]): Optional; Path to the directory for storing plots.\n\n    Notes:\n        save = True, show = False regardless of input for plots made for each sample such as PvT or Mask plots.\n\n    Returns:\n        None\n    \"\"\"\n    if not show:\n        # Ensures that there is no attempt to display figures incase no display is present.\n        try:\n            mlp.use(\"agg\")\n        except ImportError:  # pragma: no cover\n            pass\n\n    flat_z = None\n    flat_y = None\n\n    if z is not None:\n        flat_z = utils.batch_flatten(z)\n\n    if y is not None:\n        flat_y = utils.batch_flatten(y)\n\n    if timestamp is None:\n        timestamp = utils.timestamp_now(fmt=\"%d-%m-%Y_%H%M\")\n\n    if model_name is None:\n        model_name = CONFIG[\"model_name\"]\n    assert model_name is not None\n\n    if results_dir is None:\n        results_dir = CONFIG[\"dir\"][\"results\"]\n        assert isinstance(results_dir, (Sequence, str, Path))\n\n    filenames = format_plot_names(model_name, timestamp, results_dir)\n\n    try:\n        os.mkdir(universal_path(results_dir))\n    except FileExistsError as err:\n        print(err)\n\n    if plots.get(\"History\", False):\n        assert metrics is not None\n\n        print(\"\\nPLOTTING MODEL HISTORY\")\n        plot_history(metrics, filename=filenames[\"History\"], save=save, show=show)\n\n    if plots.get(\"CM\", False):\n        assert class_names is not None\n        assert flat_y is not None\n        assert flat_z is not None\n\n        print(\"\\nPLOTTING CONFUSION MATRIX\")\n        make_confusion_matrix(\n            labels=flat_y,\n            pred=flat_z,\n            classes=class_names,\n            filename=filenames[\"CM\"],\n            save=save,\n            show=show,\n        )\n\n    if plots.get(\"Pred\", False):\n        assert class_names is not None\n        assert colours is not None\n        assert flat_z is not None\n\n        print(\"\\nPLOTTING CLASS DISTRIBUTION OF PREDICTIONS\")\n        plot_subpopulations(\n            utils.find_modes(flat_z),\n            class_names=class_names,\n            cmap_dict=colours,\n            filename=filenames[\"Pred\"],\n            save=save,\n            show=show,\n        )\n\n    if plots.get(\"ROC\", False):\n        assert class_names is not None\n        assert colours is not None\n        assert probs is not None\n        assert flat_y is not None\n\n        print(\"\\nPLOTTING ROC CURVES\")\n        make_roc_curves(\n            probs,\n            flat_y,\n            class_names=class_names,\n            colours=colours,\n            filename=filenames[\"ROC\"],\n            micro=plots[\"micro\"],\n            macro=plots[\"macro\"],\n            save=save,\n            show=show,\n        )\n\n    if plots.get(\"Mask\", False):\n        assert class_names is not None\n        assert colours is not None\n        assert z is not None\n        assert y is not None\n        assert ids is not None\n        assert bounds is not None\n        assert mode is not None\n\n        figsize = None\n        if DATA_CONFIG is not None:\n            figsize = DATA_CONFIG[\"fig_sizes\"][\"Mask\"]\n\n        flat_bbox = utils.batch_flatten(bounds)\n        os.makedirs(universal_path(results_dir) / \"Masks\", exist_ok=True)\n        seg_plot(\n            z,\n            y,\n            ids,\n            flat_bbox,\n            mode,\n            fn_prefix=filenames[\"Mask\"],\n            classes=class_names,\n            colours=colours,\n            fig_dim=figsize,\n        )\n\n    if plots.get(\"TSNE\", False):\n        assert embeddings is not None\n        assert bounds is not None\n        assert mode is not None\n\n        print(\"\\nPERFORMING TSNE CLUSTERING\")\n        plot_embedding(\n            embeddings,\n            bounds,\n            mode,\n            show=show,\n            save=save,\n            filename=filenames[\"TSNE\"],\n        )\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "5b642649555d0160e7c6a962b59e988d11989edf23e448b90d346260ceaa54e6"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/__init__.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 1090,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\":mod:`minerva` is a package designed to facilitate the fitting and visualation of models for geo-spatial research.\"\"\"\n\n__version__ = \"0.19.0\"\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 1090,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\":mod:`minerva` is a package designed to facilitate the fitting and visualation of models for geo-spatial research.\"\"\"\n\n__version__ = \"0.19.0\"\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "3acf6e386aa4b039dcea0d81d2184501b672ea4c40bea1524a64b1e9db10e747"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/MinervaPipe.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 3216,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Script to handle the pre-training of model and its subsequent downstream task fine-tuning.\"\"\"\n\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\nimport subprocess\nimport sys\nfrom typing import Any, Dict\n\nimport yaml\n\n\n# =====================================================================================================================\n#                                                      MAIN\n# =====================================================================================================================\ndef main(config_path: str):\n\n    with open(config_path) as f:\n        config: Dict[str, Any] = yaml.safe_load(f)\n\n    for key in config.keys():\n        print(\n            f\"\\nExecuting {key} experiment + =====================================================================\"\n        )\n\n        try:\n            exit_code = subprocess.Popen(  # nosec B602\n                f\"python MinervaExp.py -c {config[key]}\",\n                shell=True,\n            ).wait()\n\n            if exit_code != 0:\n                raise SystemExit()\n        except KeyboardInterrupt as err:\n            print(f\"{err}: Skipping to next experiment...\")\n\n        except SystemExit as err:\n            print(err)\n            print(f\"Error in {key} experiment -> ABORT\")\n            sys.exit(exit_code)  # type: ignore\n\n        print(\n            f\"\\n{key} experiment COMPLETE + =====================================================================\"\n        )\n\n    print(\"\\nPipeline COMPLETE\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"config_path\", type=str)\n    args = parser.parse_args()\n\n    main(config_path=args.config_path)\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 3216,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Script to handle the pre-training of model and its subsequent downstream task fine-tuning.\"\"\"\n\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\nimport subprocess\nimport sys\nfrom typing import Any, Dict\n\nimport yaml\n\n\n# =====================================================================================================================\n#                                                      MAIN\n# =====================================================================================================================\ndef main(config_path: str):\n\n    with open(config_path) as f:\n        config: Dict[str, Any] = yaml.safe_load(f)\n\n    for key in config.keys():\n        print(\n            f\"\\nExecuting {key} experiment + =====================================================================\"\n        )\n\n        try:\n            exit_code = subprocess.Popen(  # nosec B602\n                f\"python MinervaExp.py -c {config[key]}\",\n                shell=True,\n            ).wait()\n\n            if exit_code != 0:\n                raise SystemExit()\n        except KeyboardInterrupt as err:\n            print(f\"{err}: Skipping to next experiment...\")\n\n        except SystemExit as err:\n            print(err)\n            print(f\"Error in {key} experiment -> ABORT\")\n            sys.exit(exit_code)  # type: ignore\n\n        print(\n            f\"\\n{key} experiment COMPLETE + =====================================================================\"\n        )\n\n    print(\"\\nPipeline COMPLETE\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"config_path\", type=str)\n    args = parser.parse_args()\n\n    main(config_path=args.config_path)\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "2f03d46d38b9606cb3c23486c40853cb982200fbc45c69be5817b6e21f6398fd"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/ManifestMake.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 2489,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Script to create manifests of data for use in Minerva pre-processing to reduce computation time.\"\"\"\n# TODO: Re-engineer for use with torchvision style datasets.\n# TODO: Consider use of parquet format rather than csv.\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nfrom minerva.datasets import make_manifest\nfrom minerva.utils import CONFIG, universal_path, utils\n\n\n# =====================================================================================================================\n#                                                      MAIN\n# =====================================================================================================================\ndef main():\n    manifest = make_manifest()\n\n    print(manifest)\n\n    output_dir = universal_path(CONFIG[\"dir\"][\"cache\"])\n\n    fn = output_dir / f\"{utils.get_dataset_name()}_Manifest.csv\"\n\n    print(f\"MANIFEST TO FILE -----> {fn}\")\n    manifest.to_csv(fn)\n\n\nif __name__ == \"__main__\":\n    main()\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 2489,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Script to create manifests of data for use in Minerva pre-processing to reduce computation time.\"\"\"\n# TODO: Re-engineer for use with torchvision style datasets.\n# TODO: Consider use of parquet format rather than csv.\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nfrom minerva.datasets import make_manifest\nfrom minerva.utils import CONFIG, universal_path, utils\n\n\n# =====================================================================================================================\n#                                                      MAIN\n# =====================================================================================================================\ndef main():\n    manifest = make_manifest()\n\n    print(manifest)\n\n    output_dir = universal_path(CONFIG[\"dir\"][\"cache\"])\n\n    fn = output_dir / f\"{utils.get_dataset_name()}_Manifest.csv\"\n\n    print(f\"MANIFEST TO FILE -----> {fn}\")\n    manifest.to_csv(fn)\n\n\nif __name__ == \"__main__\":\n    main()\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "25e91c02bf2d75552ad79c23363aabbb8782bf1f8fa289f6b729eb0b15815460"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/pytorchtools.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 4831,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# MIT License\n#\n# Copyright (c) 2018 Bjarte Mehus Sunde\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\"\"\"Module containing :class:`EarlyStopping` to track when the training of a model should stop.\n\nSource: https://github.com/Bjarten/early-stopping-pytorch\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Bjarte Mehus Sunde\"\n__license__ = \"MIT\"\n__copyright__ = \"Copyright (C) 2018 Bjarte Mehus Sunde\"\n\n# =====================================================================================================================\n#                                                    IMPORTS\n# =====================================================================================================================\nfrom pathlib import Path\nfrom typing import Callable, Optional, Union\n\nimport numpy as np\nimport torch\nfrom torch.nn.modules import Module\n\n\n# =====================================================================================================================\n#                                                    CLASSES\n# =====================================================================================================================\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience: int = 7,\n        verbose: bool = False,\n        delta: float = 0.0,\n        path: Union[str, Path] = \"checkpoint.pt\",\n        trace_func: Callable[..., None] = print,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience: int = patience\n        self.verbose: bool = verbose\n        self.counter: int = 0\n        self.best_score: Optional[float] = None\n        self.early_stop: bool = False\n        self.val_loss_min: float = np.Inf\n        self.delta: float = delta\n        self.path: Union[str, Path] = path\n        self.trace_func: Callable[..., None] = trace_func\n\n    def __call__(self, val_loss: float, model: Module) -> None:\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(\n                f\"EarlyStopping counter: {self.counter} out of {self.patience}\"\n            )\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model: Module) -> None:\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 4831,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# MIT License\n#\n# Copyright (c) 2018 Bjarte Mehus Sunde\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\"\"\"Module containing :class:`EarlyStopping` to track when the training of a model should stop.\n\nSource: https://github.com/Bjarten/early-stopping-pytorch\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Bjarte Mehus Sunde\"\n__license__ = \"MIT\"\n__copyright__ = \"Copyright (C) 2018 Bjarte Mehus Sunde\"\n\n# =====================================================================================================================\n#                                                    IMPORTS\n# =====================================================================================================================\nfrom pathlib import Path\nfrom typing import Callable, Optional, Union\n\nimport numpy as np\nimport torch\nfrom torch.nn.modules import Module\n\n\n# =====================================================================================================================\n#                                                    CLASSES\n# =====================================================================================================================\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience: int = 7,\n        verbose: bool = False,\n        delta: float = 0.0,\n        path: Union[str, Path] = \"checkpoint.pt\",\n        trace_func: Callable[..., None] = print,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience: int = patience\n        self.verbose: bool = verbose\n        self.counter: int = 0\n        self.best_score: Optional[float] = None\n        self.early_stop: bool = False\n        self.val_loss_min: float = np.Inf\n        self.delta: float = delta\n        self.path: Union[str, Path] = path\n        self.trace_func: Callable[..., None] = trace_func\n\n    def __call__(self, val_loss: float, model: Module) -> None:\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(\n                f\"EarlyStopping counter: {self.counter} out of {self.patience}\"\n            )\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model: Module) -> None:\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "c885a7fe8ab51b6a15e4351e90f4e8362d8bcbd4ff2e79fe05915d05ed4e8d39"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/TorchWeightDownloader.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 2280,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Loads :mod:`torch` weights from Torch Hub into cache.\n\nAttributes:\n    resnets (List[str]): List of tags for ``pytorch`` resnet weights to download.\n\"\"\"\n\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nfrom typing import Optional\n\nfrom torchvision.models._api import WeightsEnum\n\nfrom minerva.models import get_torch_weights\n\nresnets = [\n    \"ResNet101_Weights.IMAGENET1K_V1\",\n    \"ResNet152_Weights.IMAGENET1K_V1\",\n    \"ResNet18_Weights.IMAGENET1K_V1\",\n    \"ResNet34_Weights.IMAGENET1K_V1\",\n    \"ResNet50_Weights.IMAGENET1K_V1\",\n]\n\n\ndef main() -> None:\n    for resnet in resnets:\n        weights: Optional[WeightsEnum] = get_torch_weights(resnet)\n        assert weights\n        _ = weights.get_state_dict(True)\n\n\nif __name__ == \"__main__\":\n    main()\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 2280,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Loads :mod:`torch` weights from Torch Hub into cache.\n\nAttributes:\n    resnets (List[str]): List of tags for ``pytorch`` resnet weights to download.\n\"\"\"\n\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nfrom typing import Optional\n\nfrom torchvision.models._api import WeightsEnum\n\nfrom minerva.models import get_torch_weights\n\nresnets = [\n    \"ResNet101_Weights.IMAGENET1K_V1\",\n    \"ResNet152_Weights.IMAGENET1K_V1\",\n    \"ResNet18_Weights.IMAGENET1K_V1\",\n    \"ResNet34_Weights.IMAGENET1K_V1\",\n    \"ResNet50_Weights.IMAGENET1K_V1\",\n]\n\n\ndef main() -> None:\n    for resnet in resnets:\n        weights: Optional[WeightsEnum] = get_torch_weights(resnet)\n        assert weights\n        _ = weights.get_state_dict(True)\n\n\nif __name__ == \"__main__\":\n    main()\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "6078f2ef8b340404cd5c61b7cbce3d56b795d1df67acf6a7c8073cd6f8dbaafd"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/MinervaClusterVis.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 2997,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Adaptation of ``MinervaExp.py`` for cluster visualisation of a model.\n\nDesigned for use in SLURM clusters and with distributed computing support.\n\nSome code derived from Barlow Twins implementation of distributed computing:\nhttps://github.com/facebookresearch/barlowtwins\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\n\nfrom minerva.trainer import Trainer\nfrom minerva.utils import CONFIG, runner\n\n\n# =====================================================================================================================\n#                                                      MAIN\n# =====================================================================================================================\ndef main(gpu: int, args) -> None:\n\n    trainer = Trainer(gpu=gpu, rank=args.rank, world_size=args.world_size, **CONFIG)\n\n    trainer.tsne_cluster()\n\n    if gpu == 0:\n        trainer.close()\n\n\nif __name__ == \"__main__\":\n    # ---+ CLI +--------------------------------------------------------------+\n    parser = argparse.ArgumentParser(parents=[runner.GENERIC_PARSER], add_help=False)\n\n    # ------------ ADD EXTRA ARGS FOR THE PARSER HERE ------------------------+\n\n    # Export args from CLI.\n    cli_args = parser.parse_args()\n\n    # Configure the arguments and environment variables.\n    runner.config_args(cli_args)\n\n    # Run the specified main with distributed computing and the arguments provided.\n    runner.distributed_run(main, cli_args)\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 2997,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Adaptation of ``MinervaExp.py`` for cluster visualisation of a model.\n\nDesigned for use in SLURM clusters and with distributed computing support.\n\nSome code derived from Barlow Twins implementation of distributed computing:\nhttps://github.com/facebookresearch/barlowtwins\n\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\n\nfrom minerva.trainer import Trainer\nfrom minerva.utils import CONFIG, runner\n\n\n# =====================================================================================================================\n#                                                      MAIN\n# =====================================================================================================================\ndef main(gpu: int, args) -> None:\n\n    trainer = Trainer(gpu=gpu, rank=args.rank, world_size=args.world_size, **CONFIG)\n\n    trainer.tsne_cluster()\n\n    if gpu == 0:\n        trainer.close()\n\n\nif __name__ == \"__main__\":\n    # ---+ CLI +--------------------------------------------------------------+\n    parser = argparse.ArgumentParser(parents=[runner.GENERIC_PARSER], add_help=False)\n\n    # ------------ ADD EXTRA ARGS FOR THE PARSER HERE ------------------------+\n\n    # Export args from CLI.\n    cli_args = parser.parse_args()\n\n    # Configure the arguments and environment variables.\n    runner.config_args(cli_args)\n\n    # Run the specified main with distributed computing and the arguments provided.\n    runner.distributed_run(main, cli_args)\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "d40675dba8f50511f93004e395d59ebf3ceba78943093f5194adf021bef814fa"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/metrics.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 13800,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Module to calculate the metrics of a model's fitting.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"MinervaMetrics\",\n    \"SPMetrics\",\n    \"SSLMetrics\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport abc\nfrom abc import ABC\nfrom typing import Any, Dict, List, Tuple\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass MinervaMetrics(ABC):\n    \"\"\"Abstract class for metric logging within the :mod:`minerva` framework.\n\n    Attributes:\n        n_batches (Dict[str, int]): Dictionary of the number of batches in each mode of fitting.\n        batch_size (int): Batch size.\n        data_size (Tuple[int, int, int]): Shape of the input data in C x H x W.\n        metrics (Dict[str, Any]): Dictionary to hold the metrics to assess the model with for each mode of fitting.\n        model_type (str): Type of the model.\n\n    Args:\n        n_batches (Dict[str, int]): Dictionary of the number of batches in each mode of fitting.\n        batch_size (int): Batch size.\n        data_size (Tuple[int, int, int]): Shape of the input data in C x H x W.\n\n    \"\"\"\n\n    __metaclass__ = abc.ABCMeta\n\n    metric_types: List[str] = []\n    special_metric_types: List[str] = []\n\n    def __init__(\n        self,\n        n_batches: Dict[str, int],\n        batch_size: int,\n        data_size: Tuple[int, int, int],\n        **params,\n    ) -> None:\n        super(MinervaMetrics, self).__init__()\n\n        self.n_batches = n_batches\n        self.batch_size = batch_size\n        self.data_size = data_size\n\n        self.model_type = params.get(\"model_type\", \"scene_classifier\")\n        self.sample_pairs = params.get(\"sample_pairs\", False)\n\n        self.modes = params.get(\"modes\", [\"train\", \"val\", \"test\"])\n\n        if self.sample_pairs:\n            self.metric_types += self.special_metric_types\n\n        # Creates a dict to hold the loss and accuracy results from training, validation and testing.\n        self.metrics: Dict[str, Any] = {}\n        for mode in self.modes:\n            for metric in self.metric_types:\n                self.metrics[f\"{mode}_{metric}\"] = {\"x\": [], \"y\": []}\n\n    def __call__(self, mode: str, logs: Dict[str, Any]) -> None:\n        self.calc_metrics(mode, logs)\n\n    @abc.abstractmethod\n    def calc_metrics(self, mode: str, logs: Dict[str, Any]) -> None:\n        \"\"\"Updates metrics with epoch results.\n\n        Args:\n            mode (str): Mode of model fitting.\n            logs (Dict[str, Any]): Logs of the results from the epoch of fitting to calculate metrics from.\n        \"\"\"\n        pass  # pragma: no cover\n\n    @abc.abstractmethod\n    def log_epoch_number(self, mode: str, epoch_no: int) -> None:\n        \"\"\"Logs the epoch number to ``metrics``.\n\n        Args:\n            mode (str): Mode of model fitting.\n            epoch_no (int): Epoch number to log.\n        \"\"\"\n        pass  # pragma: no cover\n\n    @property\n    def get_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get the ``metrics`` dictionary.\n\n        Returns:\n            Dict[str, Any]: Metrics dictionary.\n        \"\"\"\n        return self.metrics\n\n    def get_sub_metrics(\n        self, pattern: Tuple[str, ...] = (\"train\", \"val\")\n    ) -> Dict[str, Any]:\n        \"\"\"Gets a subset of the metrics dictionary with keys containing strings in the pattern.\n\n        Useful for getting the train and validation metrics for plotting for example.\n\n        Args:\n            pattern (Tuple[str, ...]): Optional; Strings to pattern match the metric keys to be returned.\n                Defaults to (\"train\", \"val\").\n\n        Returns:\n            Dict[str, Any]: Subset of ``metrics`` with keys that contained strings in ``pattern``.\n        \"\"\"\n        sub_metrics = {}\n        for key in self.metrics.keys():\n            if key.split(\"_\")[0] in pattern:\n                sub_metrics[key] = self.metrics[key]\n\n        return sub_metrics\n\n    @abc.abstractmethod\n    def print_epoch_results(self, mode: str, epoch_no: int) -> None:\n        \"\"\"Prints the results from an epoch to ``stdout``.\n\n        Args:\n            mode (str): Mode of fitting to print results from.\n            epoch_no (int): Epoch number to print results from.\n        \"\"\"\n        pass  # pragma: no cover\n\n\nclass SPMetrics(MinervaMetrics):\n    \"\"\"Metric logging for supervised models.\n\n    Attributes:\n        n_batches (Dict[str, int]): Dictionary of the number of batches in each mode of fitting.\n        batch_size (int): Batch size.\n        data_size (Tuple[int, int, int]): Shape of the input data in C x H x W.\n        metrics (Dict[str, Any]): Dictionary to hold the metrics to assess the model with for each mode of fitting.\n        model_type (str): Type of the model.\n\n    Args:\n        n_batches (Dict[str, int]): Dictionary of the number of batches in each mode of fitting.\n        batch_size (int): Batch size.\n        data_size (Tuple[int, int, int]): Shape of the input data in C x H x W.\n        model_type (str): Optional; Type of the model.\n    \"\"\"\n\n    metric_types: List[str] = [\"loss\", \"acc\", \"miou\"]\n\n    def __init__(\n        self,\n        n_batches: Dict[str, int],\n        batch_size: int,\n        data_size: Tuple[int, int, int],\n        model_type: str = \"segmentation\",\n        **params,\n    ) -> None:\n        super(SPMetrics, self).__init__(\n            n_batches, batch_size, data_size, model_type=model_type\n        )\n\n    def calc_metrics(self, mode: str, logs: Dict[str, Any]) -> None:\n        \"\"\"Updates metrics with epoch results.\n\n        Args:\n            mode (str): Mode of model fitting.\n            logs (Dict[str, Any]): Logs of the results from the epoch of fitting to calculate metrics from.\n        \"\"\"\n        self.metrics[f\"{mode}_loss\"][\"y\"].append(\n            logs[\"total_loss\"] / self.n_batches[mode]\n        )\n\n        if self.model_type == \"segmentation\":\n            self.metrics[f\"{mode}_acc\"][\"y\"].append(\n                logs[\"total_correct\"]\n                / (\n                    self.n_batches[mode]\n                    * self.batch_size\n                    * self.data_size[1]\n                    * self.data_size[2]\n                )\n            )\n            if logs.get(\"total_miou\") is not None:\n                self.metrics[f\"{mode}_miou\"][\"y\"].append(\n                    logs[\"total_miou\"] / (self.n_batches[mode] * self.batch_size)\n                )\n\n        else:\n            self.metrics[f\"{mode}_acc\"][\"y\"].append(\n                logs[\"total_correct\"] / (self.n_batches[mode] * self.batch_size)\n            )\n\n    def log_epoch_number(self, mode: str, epoch_no: int) -> None:\n        \"\"\"Logs the epoch number to ``metrics``.\n\n        Args:\n            mode (str): Mode of model fitting.\n            epoch_no (int): Epoch number to log.\n        \"\"\"\n        self.metrics[f\"{mode}_loss\"][\"x\"].append(epoch_no + 1)\n        self.metrics[f\"{mode}_acc\"][\"x\"].append(epoch_no + 1)\n        self.metrics[f\"{mode}_miou\"][\"x\"].append(epoch_no + 1)\n\n    def print_epoch_results(self, mode: str, epoch_no: int) -> None:\n        \"\"\"Prints the results from an epoch to ``stdout``.\n\n        Args:\n            mode (str): Mode of fitting to print results from.\n            epoch_no (int): Epoch number to print results from.\n        \"\"\"\n        msg = \"{} | Loss: {} | Accuracy: {}%\".format(\n            mode,\n            self.metrics[f\"{mode}_loss\"][\"y\"][epoch_no],\n            self.metrics[f\"{mode}_acc\"][\"y\"][epoch_no] * 100.0,\n        )\n\n        if self.model_type == \"segmentation\":\n            msg += \" | mIoU: {}\".format(self.metrics[f\"{mode}_miou\"][\"y\"][epoch_no])\n\n        msg += \"\\n\"\n        print(msg)\n\n\nclass SSLMetrics(MinervaMetrics):\n    \"\"\"Metric logging for self-supervised models.\n\n    Attributes:\n        n_batches (Dict[str, int]): Dictionary of the number of batches in each mode of fitting.\n        batch_size (int): Batch size.\n        data_size (Tuple[int, int, int]): Shape of the input data in C x H x W.\n        metrics (Dict[str, Any]): Dictionary to hold the metrics to assess the model with for each mode of fitting.\n        model_type (str): Type of the model.\n\n    Args:\n        n_batches (Dict[str, int]): Dictionary of the number of batches in each mode of fitting.\n        batch_size (int): Batch size.\n        data_size (Tuple[int, int, int]): Shape of the input data in C x H x W.\n        model_type (str): Optional; Type of the model.\n    \"\"\"\n\n    metric_types = [\"loss\", \"acc\", \"top5_acc\"]\n    special_metric_types = [\"collapse_level\", \"euc_dist\"]\n\n    def __init__(\n        self,\n        n_batches: Dict[str, int],\n        batch_size: int,\n        data_size: Tuple[int, int, int],\n        model_type: str = \"segmentation\",\n        sample_pairs: bool = False,\n        **params,\n    ) -> None:\n        super(SSLMetrics, self).__init__(\n            n_batches,\n            batch_size,\n            data_size,\n            model_type=model_type,\n            sample_pairs=sample_pairs,\n        )\n\n    def calc_metrics(self, mode: str, logs) -> None:\n        \"\"\"Updates metrics with epoch results.\n\n        Args:\n            mode (str): Mode of model fitting.\n            logs (Dict[str, Any]): Logs of the results from the epoch of fitting to calculate metrics from.\n        \"\"\"\n        self.metrics[f\"{mode}_loss\"][\"y\"].append(\n            logs[\"total_loss\"] / self.n_batches[mode]\n        )\n\n        if self.model_type == \"segmentation\":\n            self.metrics[f\"{mode}_acc\"][\"y\"].append(\n                logs[\"total_correct\"]\n                / (\n                    self.n_batches[mode]\n                    * self.batch_size\n                    * self.data_size[1]\n                    * self.data_size[2]\n                )\n            )\n            self.metrics[f\"{mode}_top5_acc\"][\"y\"].append(\n                logs[\"total_top5\"]\n                / (\n                    self.n_batches[mode]\n                    * self.batch_size\n                    * self.data_size[1]\n                    * self.data_size[2]\n                )\n            )\n\n        else:\n            self.metrics[f\"{mode}_acc\"][\"y\"].append(\n                logs[\"total_correct\"] / (self.n_batches[mode] * self.batch_size)\n            )\n            self.metrics[f\"{mode}_top5_acc\"][\"y\"].append(\n                logs[\"total_top5\"] / (self.n_batches[mode] * self.batch_size)\n            )\n\n        if self.sample_pairs and mode == \"train\":\n            self.metrics[f\"{mode}_collapse_level\"][\"y\"].append(logs[\"collapse_level\"])\n            self.metrics[f\"{mode}_euc_dist\"][\"y\"].append(\n                logs[\"euc_dist\"] / self.n_batches[mode]\n            )\n\n    def log_epoch_number(self, mode: str, epoch_no: int) -> None:\n        \"\"\"Logs the epoch number to ``metrics``.\n\n        Args:\n            mode (str): Mode of model fitting.\n            epoch_no (int): Epoch number to log.\n        \"\"\"\n        self.metrics[f\"{mode}_loss\"][\"x\"].append(epoch_no + 1)\n        self.metrics[f\"{mode}_acc\"][\"x\"].append(epoch_no + 1)\n        self.metrics[f\"{mode}_top5_acc\"][\"x\"].append(epoch_no + 1)\n\n        if self.sample_pairs and mode == \"train\":\n            self.metrics[f\"{mode}_collapse_level\"][\"x\"].append(epoch_no + 1)\n            self.metrics[f\"{mode}_euc_dist\"][\"x\"].append(epoch_no + 1)\n\n    def print_epoch_results(self, mode: str, epoch_no: int) -> None:\n        \"\"\"Prints the results from an epoch to ``stdout``.\n\n        Args:\n            mode (str): Mode of fitting to print results from.\n            epoch_no (int): Epoch number to print results from.\n        \"\"\"\n        msg = \"{} | Loss: {} | Accuracy: {}% | Top5 Accuracy: {}% \".format(\n            mode,\n            self.metrics[f\"{mode}_loss\"][\"y\"][epoch_no],\n            self.metrics[f\"{mode}_acc\"][\"y\"][epoch_no] * 100.0,\n            self.metrics[f\"{mode}_top5_acc\"][\"y\"][epoch_no] * 100.0,\n        )\n\n        if self.sample_pairs and mode == \"train\":\n            msg += \"\\n\"\n\n            msg += \"| Collapse Level: {}%\".format(\n                self.metrics[f\"{mode}_collapse_level\"][\"y\"][epoch_no] * 100.0\n            )\n            msg += \"| Avg. Euclidean Distance: {}\".format(\n                self.metrics[f\"{mode}_euc_dist\"][\"y\"][epoch_no]\n            )\n\n        msg += \"\\n\"\n        print(msg)\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 13800,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Module to calculate the metrics of a model's fitting.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"MinervaMetrics\",\n    \"SPMetrics\",\n    \"SSLMetrics\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport abc\nfrom abc import ABC\nfrom typing import Any, Dict, List, Tuple\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass MinervaMetrics(ABC):\n    \"\"\"Abstract class for metric logging within the :mod:`minerva` framework.\n\n    Attributes:\n        n_batches (Dict[str, int]): Dictionary of the number of batches in each mode of fitting.\n        batch_size (int): Batch size.\n        data_size (Tuple[int, int, int]): Shape of the input data in C x H x W.\n        metrics (Dict[str, Any]): Dictionary to hold the metrics to assess the model with for each mode of fitting.\n        model_type (str): Type of the model.\n\n    Args:\n        n_batches (Dict[str, int]): Dictionary of the number of batches in each mode of fitting.\n        batch_size (int): Batch size.\n        data_size (Tuple[int, int, int]): Shape of the input data in C x H x W.\n\n    \"\"\"\n\n    __metaclass__ = abc.ABCMeta\n\n    metric_types: List[str] = []\n    special_metric_types: List[str] = []\n\n    def __init__(\n        self,\n        n_batches: Dict[str, int],\n        batch_size: int,\n        data_size: Tuple[int, int, int],\n        **params,\n    ) -> None:\n        super(MinervaMetrics, self).__init__()\n\n        self.n_batches = n_batches\n        self.batch_size = batch_size\n        self.data_size = data_size\n\n        self.model_type = params.get(\"model_type\", \"scene_classifier\")\n        self.sample_pairs = params.get(\"sample_pairs\", False)\n\n        self.modes = params.get(\"modes\", [\"train\", \"val\", \"test\"])\n\n        if self.sample_pairs:\n            self.metric_types += self.special_metric_types\n\n        # Creates a dict to hold the loss and accuracy results from training, validation and testing.\n        self.metrics: Dict[str, Any] = {}\n        for mode in self.modes:\n            for metric in self.metric_types:\n                self.metrics[f\"{mode}_{metric}\"] = {\"x\": [], \"y\": []}\n\n    def __call__(self, mode: str, logs: Dict[str, Any]) -> None:\n        self.calc_metrics(mode, logs)\n\n    @abc.abstractmethod\n    def calc_metrics(self, mode: str, logs: Dict[str, Any]) -> None:\n        \"\"\"Updates metrics with epoch results.\n\n        Args:\n            mode (str): Mode of model fitting.\n            logs (Dict[str, Any]): Logs of the results from the epoch of fitting to calculate metrics from.\n        \"\"\"\n        pass  # pragma: no cover\n\n    @abc.abstractmethod\n    def log_epoch_number(self, mode: str, epoch_no: int) -> None:\n        \"\"\"Logs the epoch number to ``metrics``.\n\n        Args:\n            mode (str): Mode of model fitting.\n            epoch_no (int): Epoch number to log.\n        \"\"\"\n        pass  # pragma: no cover\n\n    @property\n    def get_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get the ``metrics`` dictionary.\n\n        Returns:\n            Dict[str, Any]: Metrics dictionary.\n        \"\"\"\n        return self.metrics\n\n    def get_sub_metrics(\n        self, pattern: Tuple[str, ...] = (\"train\", \"val\")\n    ) -> Dict[str, Any]:\n        \"\"\"Gets a subset of the metrics dictionary with keys containing strings in the pattern.\n\n        Useful for getting the train and validation metrics for plotting for example.\n\n        Args:\n            pattern (Tuple[str, ...]): Optional; Strings to pattern match the metric keys to be returned.\n                Defaults to (\"train\", \"val\").\n\n        Returns:\n            Dict[str, Any]: Subset of ``metrics`` with keys that contained strings in ``pattern``.\n        \"\"\"\n        sub_metrics = {}\n        for key in self.metrics.keys():\n            if key.split(\"_\")[0] in pattern:\n                sub_metrics[key] = self.metrics[key]\n\n        return sub_metrics\n\n    @abc.abstractmethod\n    def print_epoch_results(self, mode: str, epoch_no: int) -> None:\n        \"\"\"Prints the results from an epoch to ``stdout``.\n\n        Args:\n            mode (str): Mode of fitting to print results from.\n            epoch_no (int): Epoch number to print results from.\n        \"\"\"\n        pass  # pragma: no cover\n\n\nclass SPMetrics(MinervaMetrics):\n    \"\"\"Metric logging for supervised models.\n\n    Attributes:\n        n_batches (Dict[str, int]): Dictionary of the number of batches in each mode of fitting.\n        batch_size (int): Batch size.\n        data_size (Tuple[int, int, int]): Shape of the input data in C x H x W.\n        metrics (Dict[str, Any]): Dictionary to hold the metrics to assess the model with for each mode of fitting.\n        model_type (str): Type of the model.\n\n    Args:\n        n_batches (Dict[str, int]): Dictionary of the number of batches in each mode of fitting.\n        batch_size (int): Batch size.\n        data_size (Tuple[int, int, int]): Shape of the input data in C x H x W.\n        model_type (str): Optional; Type of the model.\n    \"\"\"\n\n    metric_types: List[str] = [\"loss\", \"acc\", \"miou\"]\n\n    def __init__(\n        self,\n        n_batches: Dict[str, int],\n        batch_size: int,\n        data_size: Tuple[int, int, int],\n        model_type: str = \"segmentation\",\n        **params,\n    ) -> None:\n        super(SPMetrics, self).__init__(\n            n_batches, batch_size, data_size, model_type=model_type\n        )\n\n    def calc_metrics(self, mode: str, logs: Dict[str, Any]) -> None:\n        \"\"\"Updates metrics with epoch results.\n\n        Args:\n            mode (str): Mode of model fitting.\n            logs (Dict[str, Any]): Logs of the results from the epoch of fitting to calculate metrics from.\n        \"\"\"\n        self.metrics[f\"{mode}_loss\"][\"y\"].append(\n            logs[\"total_loss\"] / self.n_batches[mode]\n        )\n\n        if self.model_type == \"segmentation\":\n            self.metrics[f\"{mode}_acc\"][\"y\"].append(\n                logs[\"total_correct\"]\n                / (\n                    self.n_batches[mode]\n                    * self.batch_size\n                    * self.data_size[1]\n                    * self.data_size[2]\n                )\n            )\n            if logs.get(\"total_miou\") is not None:\n                self.metrics[f\"{mode}_miou\"][\"y\"].append(\n                    logs[\"total_miou\"] / (self.n_batches[mode] * self.batch_size)\n                )\n\n        else:\n            self.metrics[f\"{mode}_acc\"][\"y\"].append(\n                logs[\"total_correct\"] / (self.n_batches[mode] * self.batch_size)\n            )\n\n    def log_epoch_number(self, mode: str, epoch_no: int) -> None:\n        \"\"\"Logs the epoch number to ``metrics``.\n\n        Args:\n            mode (str): Mode of model fitting.\n            epoch_no (int): Epoch number to log.\n        \"\"\"\n        self.metrics[f\"{mode}_loss\"][\"x\"].append(epoch_no + 1)\n        self.metrics[f\"{mode}_acc\"][\"x\"].append(epoch_no + 1)\n        self.metrics[f\"{mode}_miou\"][\"x\"].append(epoch_no + 1)\n\n    def print_epoch_results(self, mode: str, epoch_no: int) -> None:\n        \"\"\"Prints the results from an epoch to ``stdout``.\n\n        Args:\n            mode (str): Mode of fitting to print results from.\n            epoch_no (int): Epoch number to print results from.\n        \"\"\"\n        msg = \"{} | Loss: {} | Accuracy: {}%\".format(\n            mode,\n            self.metrics[f\"{mode}_loss\"][\"y\"][epoch_no],\n            self.metrics[f\"{mode}_acc\"][\"y\"][epoch_no] * 100.0,\n        )\n\n        if self.model_type == \"segmentation\":\n            msg += \" | mIoU: {}\".format(self.metrics[f\"{mode}_miou\"][\"y\"][epoch_no])\n\n        msg += \"\\n\"\n        print(msg)\n\n\nclass SSLMetrics(MinervaMetrics):\n    \"\"\"Metric logging for self-supervised models.\n\n    Attributes:\n        n_batches (Dict[str, int]): Dictionary of the number of batches in each mode of fitting.\n        batch_size (int): Batch size.\n        data_size (Tuple[int, int, int]): Shape of the input data in C x H x W.\n        metrics (Dict[str, Any]): Dictionary to hold the metrics to assess the model with for each mode of fitting.\n        model_type (str): Type of the model.\n\n    Args:\n        n_batches (Dict[str, int]): Dictionary of the number of batches in each mode of fitting.\n        batch_size (int): Batch size.\n        data_size (Tuple[int, int, int]): Shape of the input data in C x H x W.\n        model_type (str): Optional; Type of the model.\n    \"\"\"\n\n    metric_types = [\"loss\", \"acc\", \"top5_acc\"]\n    special_metric_types = [\"collapse_level\", \"euc_dist\"]\n\n    def __init__(\n        self,\n        n_batches: Dict[str, int],\n        batch_size: int,\n        data_size: Tuple[int, int, int],\n        model_type: str = \"segmentation\",\n        sample_pairs: bool = False,\n        **params,\n    ) -> None:\n        super(SSLMetrics, self).__init__(\n            n_batches,\n            batch_size,\n            data_size,\n            model_type=model_type,\n            sample_pairs=sample_pairs,\n        )\n\n    def calc_metrics(self, mode: str, logs) -> None:\n        \"\"\"Updates metrics with epoch results.\n\n        Args:\n            mode (str): Mode of model fitting.\n            logs (Dict[str, Any]): Logs of the results from the epoch of fitting to calculate metrics from.\n        \"\"\"\n        self.metrics[f\"{mode}_loss\"][\"y\"].append(\n            logs[\"total_loss\"] / self.n_batches[mode]\n        )\n\n        if self.model_type == \"segmentation\":\n            self.metrics[f\"{mode}_acc\"][\"y\"].append(\n                logs[\"total_correct\"]\n                / (\n                    self.n_batches[mode]\n                    * self.batch_size\n                    * self.data_size[1]\n                    * self.data_size[2]\n                )\n            )\n            self.metrics[f\"{mode}_top5_acc\"][\"y\"].append(\n                logs[\"total_top5\"]\n                / (\n                    self.n_batches[mode]\n                    * self.batch_size\n                    * self.data_size[1]\n                    * self.data_size[2]\n                )\n            )\n\n        else:\n            self.metrics[f\"{mode}_acc\"][\"y\"].append(\n                logs[\"total_correct\"] / (self.n_batches[mode] * self.batch_size)\n            )\n            self.metrics[f\"{mode}_top5_acc\"][\"y\"].append(\n                logs[\"total_top5\"] / (self.n_batches[mode] * self.batch_size)\n            )\n\n        if self.sample_pairs and mode == \"train\":\n            self.metrics[f\"{mode}_collapse_level\"][\"y\"].append(logs[\"collapse_level\"])\n            self.metrics[f\"{mode}_euc_dist\"][\"y\"].append(\n                logs[\"euc_dist\"] / self.n_batches[mode]\n            )\n\n    def log_epoch_number(self, mode: str, epoch_no: int) -> None:\n        \"\"\"Logs the epoch number to ``metrics``.\n\n        Args:\n            mode (str): Mode of model fitting.\n            epoch_no (int): Epoch number to log.\n        \"\"\"\n        self.metrics[f\"{mode}_loss\"][\"x\"].append(epoch_no + 1)\n        self.metrics[f\"{mode}_acc\"][\"x\"].append(epoch_no + 1)\n        self.metrics[f\"{mode}_top5_acc\"][\"x\"].append(epoch_no + 1)\n\n        if self.sample_pairs and mode == \"train\":\n            self.metrics[f\"{mode}_collapse_level\"][\"x\"].append(epoch_no + 1)\n            self.metrics[f\"{mode}_euc_dist\"][\"x\"].append(epoch_no + 1)\n\n    def print_epoch_results(self, mode: str, epoch_no: int) -> None:\n        \"\"\"Prints the results from an epoch to ``stdout``.\n\n        Args:\n            mode (str): Mode of fitting to print results from.\n            epoch_no (int): Epoch number to print results from.\n        \"\"\"\n        msg = \"{} | Loss: {} | Accuracy: {}% | Top5 Accuracy: {}% \".format(\n            mode,\n            self.metrics[f\"{mode}_loss\"][\"y\"][epoch_no],\n            self.metrics[f\"{mode}_acc\"][\"y\"][epoch_no] * 100.0,\n            self.metrics[f\"{mode}_top5_acc\"][\"y\"][epoch_no] * 100.0,\n        )\n\n        if self.sample_pairs and mode == \"train\":\n            msg += \"\\n\"\n\n            msg += \"| Collapse Level: {}%\".format(\n                self.metrics[f\"{mode}_collapse_level\"][\"y\"][epoch_no] * 100.0\n            )\n            msg += \"| Avg. Euclidean Distance: {}\".format(\n                self.metrics[f\"{mode}_euc_dist\"][\"y\"][epoch_no]\n            )\n\n        msg += \"\\n\"\n        print(msg)\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "861a94a60bb8a224ea40078dcba96f9723c98e445039e16242b581dbacc4ca41"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/RunTensorBoard.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 3317,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Script to run the TensorBoard logs from experiments.\"\"\"\n\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\nfrom typing import List, Optional, Union\n\nfrom minerva.utils import utils\n\n\n# =====================================================================================================================\n#                                                      MAIN\n# =====================================================================================================================\ndef main(\n    path: Optional[Union[str, List[str]]] = None,\n    env_name: str = \"env2\",\n    exp_name: Optional[str] = None,\n    host_num: int = 6006,\n) -> None:\n    assert exp_name is not None\n\n    if isinstance(path, list):\n        if len(path) == 1:\n            path = path[0]\n\n    utils.run_tensorboard(exp_name, path=path, env_name=env_name, host_num=host_num)\n\n\nif __name__ == \"__main__\":\n    CLI = argparse.ArgumentParser()\n    CLI.add_argument(\n        \"--path\",  # name on the CLI - drop the `--` for positional/required parameters\n        nargs=\"*\",  # 0 or more values expected => creates a list\n        type=str,\n        default=None,  # default if nothing is provided\n    )\n    CLI.add_argument(\n        \"--env_name\",\n        nargs=\"1\",\n        type=str,  # any type/callable can be used here\n        default=None,\n    )\n    CLI.add_argument(\n        \"--exp_name\",\n        nargs=\"1\",\n        type=str,  # any type/callable can be used here\n        default=None,\n    )\n    CLI.add_argument(\n        \"--host_num\",\n        nargs=\"1\",\n        type=int,  # any type/callable can be used here\n        default=None,\n    )\n\n    args = CLI.parse_args()\n    main(\n        path=args.path,\n        env_name=args.env_name,\n        exp_name=args.exp_name,\n        host_num=args.host_num,\n    )\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 3317,
                    "snippet": {
                      "text": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n#\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n\"\"\"Script to run the TensorBoard logs from experiments.\"\"\"\n\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\nfrom typing import List, Optional, Union\n\nfrom minerva.utils import utils\n\n\n# =====================================================================================================================\n#                                                      MAIN\n# =====================================================================================================================\ndef main(\n    path: Optional[Union[str, List[str]]] = None,\n    env_name: str = \"env2\",\n    exp_name: Optional[str] = None,\n    host_num: int = 6006,\n) -> None:\n    assert exp_name is not None\n\n    if isinstance(path, list):\n        if len(path) == 1:\n            path = path[0]\n\n    utils.run_tensorboard(exp_name, path=path, env_name=env_name, host_num=host_num)\n\n\nif __name__ == \"__main__\":\n    CLI = argparse.ArgumentParser()\n    CLI.add_argument(\n        \"--path\",  # name on the CLI - drop the `--` for positional/required parameters\n        nargs=\"*\",  # 0 or more values expected => creates a list\n        type=str,\n        default=None,  # default if nothing is provided\n    )\n    CLI.add_argument(\n        \"--env_name\",\n        nargs=\"1\",\n        type=str,  # any type/callable can be used here\n        default=None,\n    )\n    CLI.add_argument(\n        \"--exp_name\",\n        nargs=\"1\",\n        type=str,  # any type/callable can be used here\n        default=None,\n    )\n    CLI.add_argument(\n        \"--host_num\",\n        nargs=\"1\",\n        type=int,  # any type/callable can be used here\n        default=None,\n    )\n\n    args = CLI.parse_args()\n    main(\n        path=args.path,\n        env_name=args.env_name,\n        exp_name=args.exp_name,\n        host_num=args.host_num,\n    )\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "e7e9e0203231a24f2a3d07f69580270f890615b8f9ca678e14db8bb6d1fabc13"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/optimisers.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 6191,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# MIT License\n#\n# Copyright (c) 2018 Noah Golmant\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\"\"\"Custom PyTorch optimisers.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Noah Golmant\"\n__license__ = \"MIT License\"\n__copyright__ = \"Copyright (c) 2018 Noah Golmant\"\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nfrom typing import Any, Callable, Dict, Iterable, Optional, Union\n\nimport torch\nfrom torch.optim.optimizer import Optimizer\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass LARS(Optimizer):\n    r\"\"\"Implements layer-wise adaptive rate scaling for SGD.\n\n    Source: https://github.com/noahgolmant/pytorch-lars/blob/master/lars.py\n\n    Args:\n        params (iterable or dict): Iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float): base learning rate (\\gamma_0)\n        momentum (float, optional): momentum factor (default: 0) (\"m\")\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n            (\"\\beta\")\n        eta (float, optional): LARS coefficient\n        max_epoch: maximum training epoch to determine polynomial LR decay.\n\n    Based on Algorithm 1 of the following paper by You, Gitman, and Ginsburg.\n    Large Batch Training of Convolutional Networks: https://arxiv.org/abs/1708.03888\n\n    Example:\n        >>> optimizer = LARS(model.parameters(), lr=0.1, eta=1e-3)\n        >>> optimizer.zero_grad()\n        >>> loss_fn(model(input), target).backward()\n        >>> optimizer.step()\n    \"\"\"\n\n    def __init__(\n        self,\n        params: Union[Iterable[Any], Dict[Any, Any]],\n        lr: float,\n        momentum: float = 0.9,\n        weight_decay: float = 0.0005,\n        eta: float = 0.001,\n        max_epoch: int = 200,\n    ):\n        if lr < 0.0:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if momentum < 0.0:\n            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n        if weight_decay < 0.0:\n            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n        if eta < 0.0:\n            raise ValueError(\"Invalid LARS coefficient value: {}\".format(eta))\n\n        self.epoch = 0\n        defaults = dict(\n            lr=lr,\n            momentum=momentum,\n            weight_decay=weight_decay,\n            eta=eta,\n            max_epoch=max_epoch,\n        )\n        super(LARS, self).__init__(params, defaults)\n\n    def step(  # type: ignore[override]\n        self, epoch: Optional[int] = None, closure: Optional[Callable[..., Any]] = None\n    ):\n        \"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n            epoch (int, optioanl): Current epoch to calculate polynomial LR decay schedule.\n                   if None, uses self.epoch and increments it.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        if epoch is None:\n            epoch = self.epoch\n            self.epoch += 1\n\n        for group in self.param_groups:\n            weight_decay = group[\"weight_decay\"]\n            momentum = group[\"momentum\"]\n            eta = group[\"eta\"]\n            lr = group[\"lr\"]\n            max_epoch = group[\"max_epoch\"]\n\n            for p in group[\"params\"]:\n                if p.grad is None:\n                    continue\n\n                param_state = self.state[p]\n                d_p = p.grad.data\n\n                weight_norm = torch.linalg.norm(p.data)\n                grad_norm = torch.linalg.norm(d_p)\n\n                # Global LR computed on polynomial decay schedule\n                decay = (1 - float(epoch) / max_epoch) ** 2\n                global_lr = lr * decay\n\n                # Compute local learning rate for this layer\n                local_lr = eta * weight_norm / (grad_norm + weight_decay * weight_norm)\n\n                # Update the momentum term\n                actual_lr = local_lr * global_lr\n\n                if \"momentum_buffer\" not in param_state:\n                    buf = param_state[\"momentum_buffer\"] = torch.zeros_like(p.data)  # type: ignore[attr-defined]\n                else:\n                    buf = param_state[\"momentum_buffer\"]\n                buf.mul_(momentum).add_(d_p + weight_decay * p.data, alpha=actual_lr)\n                p.data.add_(-buf)\n\n        return loss\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 6191,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# MIT License\n#\n# Copyright (c) 2018 Noah Golmant\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\"\"\"Custom PyTorch optimisers.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Noah Golmant\"\n__license__ = \"MIT License\"\n__copyright__ = \"Copyright (c) 2018 Noah Golmant\"\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nfrom typing import Any, Callable, Dict, Iterable, Optional, Union\n\nimport torch\nfrom torch.optim.optimizer import Optimizer\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass LARS(Optimizer):\n    r\"\"\"Implements layer-wise adaptive rate scaling for SGD.\n\n    Source: https://github.com/noahgolmant/pytorch-lars/blob/master/lars.py\n\n    Args:\n        params (iterable or dict): Iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float): base learning rate (\\gamma_0)\n        momentum (float, optional): momentum factor (default: 0) (\"m\")\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n            (\"\\beta\")\n        eta (float, optional): LARS coefficient\n        max_epoch: maximum training epoch to determine polynomial LR decay.\n\n    Based on Algorithm 1 of the following paper by You, Gitman, and Ginsburg.\n    Large Batch Training of Convolutional Networks: https://arxiv.org/abs/1708.03888\n\n    Example:\n        >>> optimizer = LARS(model.parameters(), lr=0.1, eta=1e-3)\n        >>> optimizer.zero_grad()\n        >>> loss_fn(model(input), target).backward()\n        >>> optimizer.step()\n    \"\"\"\n\n    def __init__(\n        self,\n        params: Union[Iterable[Any], Dict[Any, Any]],\n        lr: float,\n        momentum: float = 0.9,\n        weight_decay: float = 0.0005,\n        eta: float = 0.001,\n        max_epoch: int = 200,\n    ):\n        if lr < 0.0:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if momentum < 0.0:\n            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n        if weight_decay < 0.0:\n            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n        if eta < 0.0:\n            raise ValueError(\"Invalid LARS coefficient value: {}\".format(eta))\n\n        self.epoch = 0\n        defaults = dict(\n            lr=lr,\n            momentum=momentum,\n            weight_decay=weight_decay,\n            eta=eta,\n            max_epoch=max_epoch,\n        )\n        super(LARS, self).__init__(params, defaults)\n\n    def step(  # type: ignore[override]\n        self, epoch: Optional[int] = None, closure: Optional[Callable[..., Any]] = None\n    ):\n        \"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n            epoch (int, optioanl): Current epoch to calculate polynomial LR decay schedule.\n                   if None, uses self.epoch and increments it.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        if epoch is None:\n            epoch = self.epoch\n            self.epoch += 1\n\n        for group in self.param_groups:\n            weight_decay = group[\"weight_decay\"]\n            momentum = group[\"momentum\"]\n            eta = group[\"eta\"]\n            lr = group[\"lr\"]\n            max_epoch = group[\"max_epoch\"]\n\n            for p in group[\"params\"]:\n                if p.grad is None:\n                    continue\n\n                param_state = self.state[p]\n                d_p = p.grad.data\n\n                weight_norm = torch.linalg.norm(p.data)\n                grad_norm = torch.linalg.norm(d_p)\n\n                # Global LR computed on polynomial decay schedule\n                decay = (1 - float(epoch) / max_epoch) ** 2\n                global_lr = lr * decay\n\n                # Compute local learning rate for this layer\n                local_lr = eta * weight_norm / (grad_norm + weight_decay * weight_norm)\n\n                # Update the momentum term\n                actual_lr = local_lr * global_lr\n\n                if \"momentum_buffer\" not in param_state:\n                    buf = param_state[\"momentum_buffer\"] = torch.zeros_like(p.data)  # type: ignore[attr-defined]\n                else:\n                    buf = param_state[\"momentum_buffer\"]\n                buf.mul_(momentum).add_(d_p + weight_decay * p.data, alpha=actual_lr)\n                p.data.add_(-buf)\n\n        return loss\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "fbf324bfdafc5041d58ed6a30e2e488db0f0115a1a9f074dd5cfb0d7a98583ca"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/models/siamese.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 18496,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n#\n\"\"\"Module containing Siamese models.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"MinervaSiamese\",\n    \"SimCLR18\",\n    \"SimCLR34\",\n    \"SimCLR50\",\n    \"SimSiam18\",\n    \"SimSiam34\",\n    \"SimSiam50\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport abc\nfrom typing import Any, Dict, Optional, Sequence, Tuple\n\nimport numpy as np\nimport torch\nimport torch.nn.modules as nn\nfrom torch import Tensor\nfrom torch.nn.modules import Module\n\nfrom .core import MinervaBackbone, MinervaModel, get_model\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass MinervaSiamese(MinervaBackbone):\n    \"\"\"Abstract class for Siamese models.\n\n    Attributes:\n        backbone (MinervaModel):\n        proj_head (Module):\n    \"\"\"\n\n    __metaclass__ = abc.ABCMeta\n\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n\n        self.backbone: MinervaModel\n        self.proj_head: Module\n\n    def forward(self, x: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]:\n        \"\"\"Performs a forward pass of the network by using the forward methods of the backbone and\n        feeding its output into the projection heads.\n\n        Can be called directly as a method (e.g. model.forward()) or when data is parsed to model (e.g. model()).\n\n        Args:\n            x (Tensor): Pair of batches of input data to the network.\n\n        Returns:\n            Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]: Tuple of:\n                * Ouput feature vectors concated together.\n                * Output feature vector A.\n                * Output feature vector B.\n                * Detached embedding, A, from the backbone.\n                * Detached embedding, B, from the backbone.\n        \"\"\"\n        return self.forward_pair(x)\n\n    def forward_pair(self, x: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]:\n        \"\"\"Performs a forward pass of the network by using the forward methods of the backbone and\n        feeding its output into the projection heads.\n\n        Args:\n            x (Tensor): Pair of batches of input data to the network.\n\n        Returns:\n            Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]: Tuple of:\n                * Ouput feature vectors concated together.\n                * Output feature vector A.\n                * Output feature vector B.\n                * Embedding, A, from the backbone.\n                * Embedding, B, from the backbone.\n        \"\"\"\n        g_a, f_a = self.forward_single(x[0])\n        g_b, f_b = self.forward_single(x[1])\n\n        g = torch.cat([g_a, g_b], dim=0)  # type: ignore[attr-defined]\n\n        assert isinstance(g, Tensor)\n\n        return g, g_a, g_b, f_a, f_b\n\n    @abc.abstractmethod\n    def forward_single(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n        \"\"\"Performs a forward pass of a single head of the network by using the forward methods of the backbone\n        and feeding its output into the projection heads.\n\n        Args:\n            x (Tensor): (Unpaired) Batch of input data to the network.\n\n        Returns:\n            Tuple[Tensor, Tensor]: Tuple of the feature vector outputted from the projection head and the detached\n            embedding vector from the backbone.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass _SimCLR(MinervaSiamese):\n    \"\"\"Base SimCLR class to be subclassed by SimCLR variants.\n\n    Subclasses :class:`MinervaSiamse`.\n\n    Attributes:\n        backbone (Module): Backbone of SimCLR that takes the imagery input and\n            extracts learned representations.\n        proj_head (Module): Projection head that takes the learned representations from the backbone encoder.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        backbone_name (str): Optional; Name of the backbone within this module to use.\n        backbone_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        backbone_name: str = \"ResNet18\",\n        backbone_kwargs: Optional[Dict[str, Any]] = None,\n    ) -> None:\n\n        super(_SimCLR, self).__init__(criterion=criterion, input_size=input_size)\n\n        self.backbone: MinervaModel = get_model(backbone_name)(\n            input_size=input_size, encoder=True, **backbone_kwargs  # type: ignore[arg-type]\n        )\n\n        self.backbone.determine_output_dim()\n\n        backbone_out_shape = self.backbone.output_shape\n        assert isinstance(backbone_out_shape, Sequence)\n\n        self.proj_head = nn.Sequential(\n            nn.Linear(np.prod(backbone_out_shape), 512, bias=False),  # type: ignore[arg-type]\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, feature_dim, bias=False),\n        )\n\n    def forward_single(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n        \"\"\"Performs a forward pass of a single head of the network by using the forward methods of the backbone\n        and feeding its output into the projection heads.\n\n        Args:\n            x (Tensor): (Unpaired) Batch of input data to the network.\n\n        Returns:\n            Tuple[Tensor, Tensor]: Tuple of the feature vector outputted from the projection head and the detached\n            embedding vector from the backbone.\n        \"\"\"\n        f: Tensor = torch.flatten(self.backbone(x)[0], start_dim=1)\n        g: Tensor = self.proj_head(f)\n\n        return g, f\n\n    def step(self, x: Tensor, *args, train: bool = False) -> Tuple[Tensor, Tensor]:\n        \"\"\"Overwrites :class:`MinervaModel` to account for paired logits.\n\n        Raises:\n            NotImplementedError: If ``self.optimiser`` is None.\n\n        Args:\n            x (Tensor): Batch of input data to network.\n            train (bool): Sets whether this shall be a training step or not. True for training step which will then\n                clear the optimiser, and perform a backward pass of the network then update the optimiser.\n                If False for a validation or testing step, these actions are not taken.\n\n        Returns:\n            Tuple[Tensor, Tensor]: Loss computed by the loss function and a :class:`Tensor`\n            with both projection's logits.\n        \"\"\"\n\n        if self.optimiser is None:\n            raise NotImplementedError(\"Optimiser has not been set!\")\n\n        assert self.criterion\n\n        # Resets the optimiser's gradients if this is a training step.\n        if train:\n            self.optimiser.zero_grad()\n\n        # Forward pass.\n        z, z_a, z_b, _, _ = self.forward(x)\n\n        # Compute Loss.\n        loss: Tensor = self.criterion(z_a, z_b)  # type: ignore[arg-type]\n\n        # Performs a backward pass if this is a training step.\n        if train:\n            loss.backward()\n            self.optimiser.step()\n\n        return loss, z\n\n\nclass SimCLR18(_SimCLR):\n    \"\"\"SimCLR network using a ResNet18 backbone.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        resnet_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        **resnet_kwargs,\n    ) -> None:\n\n        super(SimCLR18, self).__init__(\n            criterion=criterion,\n            input_size=input_size,\n            feature_dim=feature_dim,\n            backbone_name=\"ResNet18\",\n            backbone_kwargs=resnet_kwargs,\n        )\n\n\nclass SimCLR34(_SimCLR):\n    \"\"\"SimCLR network using a ResNet32 backbone.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        resnet_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        **resnet_kwargs,\n    ) -> None:\n\n        super(SimCLR34, self).__init__(\n            criterion=criterion,\n            input_size=input_size,\n            feature_dim=feature_dim,\n            backbone_name=\"ResNet34\",\n            backbone_kwargs=resnet_kwargs,\n        )\n\n\nclass SimCLR50(_SimCLR):\n    \"\"\"SimCLR network using a ResNet50 backbone.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        resnet_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        **resnet_kwargs,\n    ) -> None:\n\n        super(SimCLR50, self).__init__(\n            criterion=criterion,\n            input_size=input_size,\n            feature_dim=feature_dim,\n            backbone_name=\"ResNet50\",\n            backbone_kwargs=resnet_kwargs,\n        )\n\n\nclass _SimSiam(MinervaSiamese):\n    \"\"\"Base SimSiam class to be subclassed by SimSiam variants.\n\n    Subclasses :class:`MinervaSiamese`.\n\n    Attributes:\n        backbone (Module): Backbone of SimSiam that takes the imagery input and\n            extracts learned representations.\n        proj_head (Module): Projection head that takes the learned representations from the backbone encoder.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        backbone_name (str): Optional; Name of the backbone within this module to use.\n        backbone_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 2048,\n        pred_dim: int = 512,\n        backbone_name: str = \"ResNet18\",\n        backbone_kwargs: Optional[Dict[str, Any]] = None,\n    ) -> None:\n\n        super(_SimSiam, self).__init__(criterion=criterion, input_size=input_size)\n\n        self.backbone: MinervaModel = get_model(backbone_name)(\n            input_size=input_size, encoder=True, **backbone_kwargs  # type: ignore[arg-type]\n        )\n\n        self.backbone.determine_output_dim()\n\n        backbone_out_shape = self.backbone.output_shape\n        assert isinstance(backbone_out_shape, Sequence)\n\n        prev_dim = np.prod(backbone_out_shape)\n\n        self.proj_head = nn.Sequential(  # type: ignore[arg-type]\n            nn.Linear(prev_dim, prev_dim, bias=False),  # type: ignore[arg-type]\n            nn.BatchNorm1d(prev_dim),  # type: ignore[arg-type]\n            nn.ReLU(inplace=True),  # first layer\n            nn.Linear(prev_dim, prev_dim, bias=False),  # type: ignore[arg-type]\n            nn.BatchNorm1d(prev_dim),  # type: ignore[arg-type]\n            nn.ReLU(inplace=True),  # second layer\n            nn.Linear(prev_dim, feature_dim, bias=False),  # type: ignore[arg-type]\n            nn.BatchNorm1d(feature_dim, affine=False),\n        )  # output layer\n        # self.proj_head[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n\n        # Build a 2-layer predictor.\n        self.predictor = nn.Sequential(\n            nn.Linear(feature_dim, pred_dim, bias=False),\n            nn.BatchNorm1d(pred_dim),\n            nn.ReLU(inplace=True),  # hidden layer\n            nn.Linear(pred_dim, feature_dim),\n        )  # output layer\n\n    def forward_single(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n        \"\"\"Performs a forward pass of a single head of :class:`_SimSiam` by using the forward methods of the backbone\n        and feeding its output into the projection heads.\n\n        Args:\n            x (Tensor): (Unpaired) Batch of input data to the network.\n\n        Returns:\n            Tuple[Tensor, Tensor]: Tuple of the feature vector outputted from the projection head and the detached\n            embedding vector from the backbone.\n        \"\"\"\n        z: Tensor = self.proj_head(torch.flatten(self.backbone(x)[0], start_dim=1))  # type: ignore[attr-defined]\n\n        p: Tensor = self.predictor(z)\n\n        return p, z.detach()\n\n    def step(self, x: Tensor, *args, train: bool = False) -> Tuple[Tensor, Tensor]:\n        \"\"\"Overwrites :class:`MinervaModel` to account for paired logits.\n\n        Raises:\n            NotImplementedError: If ``self.optimiser`` is None.\n\n        Args:\n            x (Tensor): Batch of input data to network.\n            train (bool): Sets whether this shall be a training step or not. True for training step which will then\n                clear the optimiser, and perform a backward pass of the network then update the optimiser.\n                If False for a validation or testing step, these actions are not taken.\n\n        Returns:\n            Tuple[Tensor, Tensor]: Loss computed by the loss function and a :class:`Tensor`\n            with both projection's logits.\n        \"\"\"\n\n        if self.optimiser is None:\n            raise NotImplementedError(\"Optimiser has not been set!\")\n\n        assert self.criterion\n\n        # Resets the optimiser's gradients if this is a training step.\n        if train:\n            self.optimiser.zero_grad()\n\n        # Forward pass.\n        p, p_a, p_b, z_a, z_b = self.forward(x)\n\n        # Compute Loss.\n        loss: Tensor = 0.5 * (self.criterion(z_a, p_b) + self.criterion(z_b, p_a))  # type: ignore[arg-type]\n\n        # Performs a backward pass if this is a training step.\n        if train:\n            loss.backward()\n            self.optimiser.step()\n\n        return loss, p\n\n\nclass SimSiam18(_SimSiam):\n    \"\"\"SimSiam network using a ResNet18 backbone.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        resnet_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        **resnet_kwargs,\n    ) -> None:\n\n        super(SimSiam18, self).__init__(\n            criterion=criterion,\n            input_size=input_size,\n            feature_dim=feature_dim,\n            backbone_name=\"ResNet18\",\n            backbone_kwargs=resnet_kwargs,\n        )\n\n\nclass SimSiam34(_SimSiam):\n    \"\"\"SimSiam network using a ResNet32 backbone.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        resnet_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        **resnet_kwargs,\n    ) -> None:\n\n        super(SimSiam34, self).__init__(\n            criterion=criterion,\n            input_size=input_size,\n            feature_dim=feature_dim,\n            backbone_name=\"ResNet34\",\n            backbone_kwargs=resnet_kwargs,\n        )\n\n\nclass SimSiam50(_SimSiam):\n    \"\"\"SimSiam network using a ResNet50 backbone.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        resnet_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        **resnet_kwargs,\n    ) -> None:\n\n        super(SimSiam50, self).__init__(\n            criterion=criterion,\n            input_size=input_size,\n            feature_dim=feature_dim,\n            backbone_name=\"ResNet50\",\n            backbone_kwargs=resnet_kwargs,\n        )\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 18496,
                    "snippet": {
                      "text": "# -*- coding: utf-8 -*-\n# Copyright (C) 2023 Harry Baker\n\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n\n# You should have received a copy of the GNU General Public License\n# along with this program in LICENSE.txt. If not,\n# see <https://www.gnu.org/licenses/>.\n\n# @org: University of Southampton\n# Created under a project funded by the Ordnance Survey Ltd.\n#\n\"\"\"Module containing Siamese models.\"\"\"\n# =====================================================================================================================\n#                                                    METADATA\n# =====================================================================================================================\n__author__ = \"Harry Baker\"\n__contact__ = \"hjb1d20@soton.ac.uk\"\n__license__ = \"GNU GPLv3\"\n__copyright__ = \"Copyright (C) 2023 Harry Baker\"\n__all__ = [\n    \"MinervaSiamese\",\n    \"SimCLR18\",\n    \"SimCLR34\",\n    \"SimCLR50\",\n    \"SimSiam18\",\n    \"SimSiam34\",\n    \"SimSiam50\",\n]\n\n# =====================================================================================================================\n#                                                     IMPORTS\n# =====================================================================================================================\nimport abc\nfrom typing import Any, Dict, Optional, Sequence, Tuple\n\nimport numpy as np\nimport torch\nimport torch.nn.modules as nn\nfrom torch import Tensor\nfrom torch.nn.modules import Module\n\nfrom .core import MinervaBackbone, MinervaModel, get_model\n\n\n# =====================================================================================================================\n#                                                     CLASSES\n# =====================================================================================================================\nclass MinervaSiamese(MinervaBackbone):\n    \"\"\"Abstract class for Siamese models.\n\n    Attributes:\n        backbone (MinervaModel):\n        proj_head (Module):\n    \"\"\"\n\n    __metaclass__ = abc.ABCMeta\n\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n\n        self.backbone: MinervaModel\n        self.proj_head: Module\n\n    def forward(self, x: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]:\n        \"\"\"Performs a forward pass of the network by using the forward methods of the backbone and\n        feeding its output into the projection heads.\n\n        Can be called directly as a method (e.g. model.forward()) or when data is parsed to model (e.g. model()).\n\n        Args:\n            x (Tensor): Pair of batches of input data to the network.\n\n        Returns:\n            Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]: Tuple of:\n                * Ouput feature vectors concated together.\n                * Output feature vector A.\n                * Output feature vector B.\n                * Detached embedding, A, from the backbone.\n                * Detached embedding, B, from the backbone.\n        \"\"\"\n        return self.forward_pair(x)\n\n    def forward_pair(self, x: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]:\n        \"\"\"Performs a forward pass of the network by using the forward methods of the backbone and\n        feeding its output into the projection heads.\n\n        Args:\n            x (Tensor): Pair of batches of input data to the network.\n\n        Returns:\n            Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]: Tuple of:\n                * Ouput feature vectors concated together.\n                * Output feature vector A.\n                * Output feature vector B.\n                * Embedding, A, from the backbone.\n                * Embedding, B, from the backbone.\n        \"\"\"\n        g_a, f_a = self.forward_single(x[0])\n        g_b, f_b = self.forward_single(x[1])\n\n        g = torch.cat([g_a, g_b], dim=0)  # type: ignore[attr-defined]\n\n        assert isinstance(g, Tensor)\n\n        return g, g_a, g_b, f_a, f_b\n\n    @abc.abstractmethod\n    def forward_single(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n        \"\"\"Performs a forward pass of a single head of the network by using the forward methods of the backbone\n        and feeding its output into the projection heads.\n\n        Args:\n            x (Tensor): (Unpaired) Batch of input data to the network.\n\n        Returns:\n            Tuple[Tensor, Tensor]: Tuple of the feature vector outputted from the projection head and the detached\n            embedding vector from the backbone.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass _SimCLR(MinervaSiamese):\n    \"\"\"Base SimCLR class to be subclassed by SimCLR variants.\n\n    Subclasses :class:`MinervaSiamse`.\n\n    Attributes:\n        backbone (Module): Backbone of SimCLR that takes the imagery input and\n            extracts learned representations.\n        proj_head (Module): Projection head that takes the learned representations from the backbone encoder.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        backbone_name (str): Optional; Name of the backbone within this module to use.\n        backbone_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        backbone_name: str = \"ResNet18\",\n        backbone_kwargs: Optional[Dict[str, Any]] = None,\n    ) -> None:\n\n        super(_SimCLR, self).__init__(criterion=criterion, input_size=input_size)\n\n        self.backbone: MinervaModel = get_model(backbone_name)(\n            input_size=input_size, encoder=True, **backbone_kwargs  # type: ignore[arg-type]\n        )\n\n        self.backbone.determine_output_dim()\n\n        backbone_out_shape = self.backbone.output_shape\n        assert isinstance(backbone_out_shape, Sequence)\n\n        self.proj_head = nn.Sequential(\n            nn.Linear(np.prod(backbone_out_shape), 512, bias=False),  # type: ignore[arg-type]\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, feature_dim, bias=False),\n        )\n\n    def forward_single(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n        \"\"\"Performs a forward pass of a single head of the network by using the forward methods of the backbone\n        and feeding its output into the projection heads.\n\n        Args:\n            x (Tensor): (Unpaired) Batch of input data to the network.\n\n        Returns:\n            Tuple[Tensor, Tensor]: Tuple of the feature vector outputted from the projection head and the detached\n            embedding vector from the backbone.\n        \"\"\"\n        f: Tensor = torch.flatten(self.backbone(x)[0], start_dim=1)\n        g: Tensor = self.proj_head(f)\n\n        return g, f\n\n    def step(self, x: Tensor, *args, train: bool = False) -> Tuple[Tensor, Tensor]:\n        \"\"\"Overwrites :class:`MinervaModel` to account for paired logits.\n\n        Raises:\n            NotImplementedError: If ``self.optimiser`` is None.\n\n        Args:\n            x (Tensor): Batch of input data to network.\n            train (bool): Sets whether this shall be a training step or not. True for training step which will then\n                clear the optimiser, and perform a backward pass of the network then update the optimiser.\n                If False for a validation or testing step, these actions are not taken.\n\n        Returns:\n            Tuple[Tensor, Tensor]: Loss computed by the loss function and a :class:`Tensor`\n            with both projection's logits.\n        \"\"\"\n\n        if self.optimiser is None:\n            raise NotImplementedError(\"Optimiser has not been set!\")\n\n        assert self.criterion\n\n        # Resets the optimiser's gradients if this is a training step.\n        if train:\n            self.optimiser.zero_grad()\n\n        # Forward pass.\n        z, z_a, z_b, _, _ = self.forward(x)\n\n        # Compute Loss.\n        loss: Tensor = self.criterion(z_a, z_b)  # type: ignore[arg-type]\n\n        # Performs a backward pass if this is a training step.\n        if train:\n            loss.backward()\n            self.optimiser.step()\n\n        return loss, z\n\n\nclass SimCLR18(_SimCLR):\n    \"\"\"SimCLR network using a ResNet18 backbone.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        resnet_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        **resnet_kwargs,\n    ) -> None:\n\n        super(SimCLR18, self).__init__(\n            criterion=criterion,\n            input_size=input_size,\n            feature_dim=feature_dim,\n            backbone_name=\"ResNet18\",\n            backbone_kwargs=resnet_kwargs,\n        )\n\n\nclass SimCLR34(_SimCLR):\n    \"\"\"SimCLR network using a ResNet32 backbone.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        resnet_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        **resnet_kwargs,\n    ) -> None:\n\n        super(SimCLR34, self).__init__(\n            criterion=criterion,\n            input_size=input_size,\n            feature_dim=feature_dim,\n            backbone_name=\"ResNet34\",\n            backbone_kwargs=resnet_kwargs,\n        )\n\n\nclass SimCLR50(_SimCLR):\n    \"\"\"SimCLR network using a ResNet50 backbone.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        resnet_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        **resnet_kwargs,\n    ) -> None:\n\n        super(SimCLR50, self).__init__(\n            criterion=criterion,\n            input_size=input_size,\n            feature_dim=feature_dim,\n            backbone_name=\"ResNet50\",\n            backbone_kwargs=resnet_kwargs,\n        )\n\n\nclass _SimSiam(MinervaSiamese):\n    \"\"\"Base SimSiam class to be subclassed by SimSiam variants.\n\n    Subclasses :class:`MinervaSiamese`.\n\n    Attributes:\n        backbone (Module): Backbone of SimSiam that takes the imagery input and\n            extracts learned representations.\n        proj_head (Module): Projection head that takes the learned representations from the backbone encoder.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        backbone_name (str): Optional; Name of the backbone within this module to use.\n        backbone_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 2048,\n        pred_dim: int = 512,\n        backbone_name: str = \"ResNet18\",\n        backbone_kwargs: Optional[Dict[str, Any]] = None,\n    ) -> None:\n\n        super(_SimSiam, self).__init__(criterion=criterion, input_size=input_size)\n\n        self.backbone: MinervaModel = get_model(backbone_name)(\n            input_size=input_size, encoder=True, **backbone_kwargs  # type: ignore[arg-type]\n        )\n\n        self.backbone.determine_output_dim()\n\n        backbone_out_shape = self.backbone.output_shape\n        assert isinstance(backbone_out_shape, Sequence)\n\n        prev_dim = np.prod(backbone_out_shape)\n\n        self.proj_head = nn.Sequential(  # type: ignore[arg-type]\n            nn.Linear(prev_dim, prev_dim, bias=False),  # type: ignore[arg-type]\n            nn.BatchNorm1d(prev_dim),  # type: ignore[arg-type]\n            nn.ReLU(inplace=True),  # first layer\n            nn.Linear(prev_dim, prev_dim, bias=False),  # type: ignore[arg-type]\n            nn.BatchNorm1d(prev_dim),  # type: ignore[arg-type]\n            nn.ReLU(inplace=True),  # second layer\n            nn.Linear(prev_dim, feature_dim, bias=False),  # type: ignore[arg-type]\n            nn.BatchNorm1d(feature_dim, affine=False),\n        )  # output layer\n        # self.proj_head[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n\n        # Build a 2-layer predictor.\n        self.predictor = nn.Sequential(\n            nn.Linear(feature_dim, pred_dim, bias=False),\n            nn.BatchNorm1d(pred_dim),\n            nn.ReLU(inplace=True),  # hidden layer\n            nn.Linear(pred_dim, feature_dim),\n        )  # output layer\n\n    def forward_single(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n        \"\"\"Performs a forward pass of a single head of :class:`_SimSiam` by using the forward methods of the backbone\n        and feeding its output into the projection heads.\n\n        Args:\n            x (Tensor): (Unpaired) Batch of input data to the network.\n\n        Returns:\n            Tuple[Tensor, Tensor]: Tuple of the feature vector outputted from the projection head and the detached\n            embedding vector from the backbone.\n        \"\"\"\n        z: Tensor = self.proj_head(torch.flatten(self.backbone(x)[0], start_dim=1))  # type: ignore[attr-defined]\n\n        p: Tensor = self.predictor(z)\n\n        return p, z.detach()\n\n    def step(self, x: Tensor, *args, train: bool = False) -> Tuple[Tensor, Tensor]:\n        \"\"\"Overwrites :class:`MinervaModel` to account for paired logits.\n\n        Raises:\n            NotImplementedError: If ``self.optimiser`` is None.\n\n        Args:\n            x (Tensor): Batch of input data to network.\n            train (bool): Sets whether this shall be a training step or not. True for training step which will then\n                clear the optimiser, and perform a backward pass of the network then update the optimiser.\n                If False for a validation or testing step, these actions are not taken.\n\n        Returns:\n            Tuple[Tensor, Tensor]: Loss computed by the loss function and a :class:`Tensor`\n            with both projection's logits.\n        \"\"\"\n\n        if self.optimiser is None:\n            raise NotImplementedError(\"Optimiser has not been set!\")\n\n        assert self.criterion\n\n        # Resets the optimiser's gradients if this is a training step.\n        if train:\n            self.optimiser.zero_grad()\n\n        # Forward pass.\n        p, p_a, p_b, z_a, z_b = self.forward(x)\n\n        # Compute Loss.\n        loss: Tensor = 0.5 * (self.criterion(z_a, p_b) + self.criterion(z_b, p_a))  # type: ignore[arg-type]\n\n        # Performs a backward pass if this is a training step.\n        if train:\n            loss.backward()\n            self.optimiser.step()\n\n        return loss, p\n\n\nclass SimSiam18(_SimSiam):\n    \"\"\"SimSiam network using a ResNet18 backbone.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        resnet_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        **resnet_kwargs,\n    ) -> None:\n\n        super(SimSiam18, self).__init__(\n            criterion=criterion,\n            input_size=input_size,\n            feature_dim=feature_dim,\n            backbone_name=\"ResNet18\",\n            backbone_kwargs=resnet_kwargs,\n        )\n\n\nclass SimSiam34(_SimSiam):\n    \"\"\"SimSiam network using a ResNet32 backbone.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        resnet_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        **resnet_kwargs,\n    ) -> None:\n\n        super(SimSiam34, self).__init__(\n            criterion=criterion,\n            input_size=input_size,\n            feature_dim=feature_dim,\n            backbone_name=\"ResNet34\",\n            backbone_kwargs=resnet_kwargs,\n        )\n\n\nclass SimSiam50(_SimSiam):\n    \"\"\"SimSiam network using a ResNet50 backbone.\n\n    Args:\n        criterion: PyTorch loss function model will use.\n        input_size (tuple[int] or list[int]): Optional; Defines the shape of the input data in\n            order of number of channels, image width, image height.\n        resnet_kwargs (dict): Optional; Keyword arguments for the backbone packed up into a dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        criterion: Any,\n        input_size: Tuple[int, int, int] = (4, 256, 256),\n        feature_dim: int = 128,\n        **resnet_kwargs,\n    ) -> None:\n\n        super(SimSiam50, self).__init__(\n            criterion=criterion,\n            input_size=input_size,\n            feature_dim=feature_dim,\n            backbone_name=\"ResNet50\",\n            backbone_kwargs=resnet_kwargs,\n        )\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "e625ecf049f1356d6c89c01ce4bd7154eab9554e6b75e4c60c10f00aeb89c924"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyInterpreterInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No Python interpreter configured for the project",
              "markdown": "No Python interpreter configured for the project"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "setup.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 69,
                    "snippet": {
                      "text": "from setuptools import setup\n\nif __name__ == \"__main__\":\n    setup()\n"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 1,
                    "startColumn": 1,
                    "charOffset": 0,
                    "charLength": 69,
                    "snippet": {
                      "text": "from setuptools import setup\n\nif __name__ == \"__main__\":\n    setup()\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "91faef10cb6a1d10e9579ea24f938156b8c7e7abeb250435ce2ec6d0526d8c81"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No module named 'os'",
              "markdown": "No module named 'os'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "docs/conf.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 13,
                    "startColumn": 8,
                    "charOffset": 560,
                    "charLength": 2,
                    "snippet": {
                      "text": "os"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 11,
                    "startColumn": 1,
                    "charOffset": 471,
                    "charLength": 103,
                    "snippet": {
                      "text": "# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "316e6b7531815857d29399fbf8ab50d01110d28d6b3e863f984ae4ab7d044d6e"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No module named 'sys'",
              "markdown": "No module named 'sys'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "docs/conf.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 14,
                    "startColumn": 8,
                    "charOffset": 570,
                    "charLength": 3,
                    "snippet": {
                      "text": "sys"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 12,
                    "startColumn": 1,
                    "charOffset": 551,
                    "charLength": 74,
                    "snippet": {
                      "text": "#\nimport os\nimport sys\n\nsys.path.insert(0, os.path.abspath(\"../minerva/\"))"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "eac9ea9eb0bf298df126602988ea3fb2fb0a33a52b32d4f4128fcaea18e03b51"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No module named 'argparse'",
              "markdown": "No module named 'argparse'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/Torch_to_ONNX.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 35,
                    "startColumn": 8,
                    "charOffset": 1643,
                    "charLength": 8,
                    "snippet": {
                      "text": "argparse"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 33,
                    "startColumn": 1,
                    "charOffset": 1454,
                    "charLength": 234,
                    "snippet": {
                      "text": "#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\n\nfrom minerva.trainer import Trainer"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "9245a7990d0a4392a671161cfb4c69583681bb07bf8e0669e6a245c3486899ae"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "Unresolved reference 'int'",
              "markdown": "Unresolved reference 'int'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/Torch_to_ONNX.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 44,
                    "startColumn": 15,
                    "charOffset": 2062,
                    "charLength": 3,
                    "snippet": {
                      "text": "int"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 42,
                    "startColumn": 1,
                    "charOffset": 1868,
                    "charLength": 237,
                    "snippet": {
                      "text": "#                                                      MAIN\n# =====================================================================================================================\ndef main(gpu: int, args) -> None:\n\n    trainer = Trainer("
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "10ffd3c257ccea6eb931ae03386ca531dbd81ed13ee3eeecc35a720a9acdf881"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "Unresolved reference 'print'",
              "markdown": "Unresolved reference 'print'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/Torch_to_ONNX.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 54,
                    "startColumn": 5,
                    "charOffset": 2344,
                    "charLength": 5,
                    "snippet": {
                      "text": "print"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 52,
                    "startColumn": 1,
                    "charOffset": 2284,
                    "charLength": 126,
                    "snippet": {
                      "text": "    trainer.save_model(fn=weights_path, format=\"onnx\")\n\n    print(f\"Model saved to --> {weights_path}.onnx\")\n\n    if gpu == 0:"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "8cbf4a24db6a1a4c7d1501fc1d350190fa9ae116a807199ae8179f223d06b3d7"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No module named 'argparse'",
              "markdown": "No module named 'argparse'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/MinervaExp.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 43,
                    "startColumn": 8,
                    "charOffset": 1993,
                    "charLength": 8,
                    "snippet": {
                      "text": "argparse"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 41,
                    "startColumn": 1,
                    "charOffset": 1804,
                    "charLength": 217,
                    "snippet": {
                      "text": "#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\n\nimport argcomplete"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "350778c5604c8b4b6bdc2064f26f93a948533919460bfb4db21ee00ab51b1fd6"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No module named 'argcomplete'",
              "markdown": "No module named 'argcomplete'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/MinervaExp.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 45,
                    "startColumn": 8,
                    "charOffset": 2010,
                    "charLength": 11,
                    "snippet": {
                      "text": "argcomplete"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 43,
                    "startColumn": 1,
                    "charOffset": 1986,
                    "charLength": 72,
                    "snippet": {
                      "text": "import argparse\n\nimport argcomplete\n\nfrom minerva.trainer import Trainer"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "f1baa01fdaf05bbc9c56da263d9a719790cf6d9562755f95520dd168162148f2"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "Unresolved reference 'int'",
              "markdown": "Unresolved reference 'int'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/bin/MinervaExp.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 54,
                    "startColumn": 15,
                    "charOffset": 2416,
                    "charLength": 3,
                    "snippet": {
                      "text": "int"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 52,
                    "startColumn": 1,
                    "charOffset": 2222,
                    "charLength": 253,
                    "snippet": {
                      "text": "#                                                      MAIN\n# =====================================================================================================================\ndef main(gpu: int, args) -> None:\n    trainer = Trainer(\n        gpu=gpu,"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "cf4fbffa168a37ee5a7c5d1cd046a5132bd22f81e4f9ec8d5d4e5cc3340e0bca"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "Unresolved reference 'typing'",
              "markdown": "Unresolved reference 'typing'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/modelio.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 36,
                    "startColumn": 6,
                    "charOffset": 1670,
                    "charLength": 6,
                    "snippet": {
                      "text": "typing"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 34,
                    "startColumn": 1,
                    "charOffset": 1483,
                    "charLength": 254,
                    "snippet": {
                      "text": "#                                                     IMPORTS\n# =====================================================================================================================\nfrom typing import Any, Dict, Sequence, Tuple, Union\n\nimport numpy as np"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "06c7763a0666882dd24e7472e213c81e683de8067d22b98fea30703d8c6b5a29"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "Unresolved reference 'Any'",
              "markdown": "Unresolved reference 'Any'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/modelio.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 36,
                    "startColumn": 20,
                    "charOffset": 1684,
                    "charLength": 3,
                    "snippet": {
                      "text": "Any"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 34,
                    "startColumn": 1,
                    "charOffset": 1483,
                    "charLength": 254,
                    "snippet": {
                      "text": "#                                                     IMPORTS\n# =====================================================================================================================\nfrom typing import Any, Dict, Sequence, Tuple, Union\n\nimport numpy as np"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "f1c7fb15d8f7b1fff48d440e420b6beea45237fa32d389c9d74a27654a0e7b2d"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No module named 'argparse'",
              "markdown": "No module named 'argparse'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/utils/__init__.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 48,
                    "startColumn": 8,
                    "charOffset": 2161,
                    "charLength": 8,
                    "snippet": {
                      "text": "argparse"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 46,
                    "startColumn": 1,
                    "charOffset": 1972,
                    "charLength": 232,
                    "snippet": {
                      "text": "#                                                     IMPORTS\n# =====================================================================================================================\nimport argparse\nimport os\nfrom pathlib import Path"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "913887397b05831ea96d724773cb29fda260c46216843dd164ad57b28eebaac2"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "No module named 'os'",
              "markdown": "No module named 'os'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/utils/__init__.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 49,
                    "startColumn": 8,
                    "charOffset": 2177,
                    "charLength": 2,
                    "snippet": {
                      "text": "os"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 47,
                    "startColumn": 1,
                    "charOffset": 2034,
                    "charLength": 198,
                    "snippet": {
                      "text": "# =====================================================================================================================\nimport argparse\nimport os\nfrom pathlib import Path\nfrom typing import Optional"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "b3e1f85e7bfbda61c2e8a05b5f25b6c1d000ba73ef66a4f8b6c2ab6ffbece162"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "Unresolved reference 'Dict'",
              "markdown": "Unresolved reference 'Dict'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/modelio.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 36,
                    "startColumn": 25,
                    "charOffset": 1689,
                    "charLength": 4,
                    "snippet": {
                      "text": "Dict"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 34,
                    "startColumn": 1,
                    "charOffset": 1483,
                    "charLength": 254,
                    "snippet": {
                      "text": "#                                                     IMPORTS\n# =====================================================================================================================\nfrom typing import Any, Dict, Sequence, Tuple, Union\n\nimport numpy as np"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "5d816300e23f3485ee60f298b9abdf8468e38985a40797b041d27f471b1ebc39"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "Unresolved reference 'Sequence'",
              "markdown": "Unresolved reference 'Sequence'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/modelio.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 36,
                    "startColumn": 31,
                    "charOffset": 1695,
                    "charLength": 8,
                    "snippet": {
                      "text": "Sequence"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 34,
                    "startColumn": 1,
                    "charOffset": 1483,
                    "charLength": 254,
                    "snippet": {
                      "text": "#                                                     IMPORTS\n# =====================================================================================================================\nfrom typing import Any, Dict, Sequence, Tuple, Union\n\nimport numpy as np"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "78831670c3c9da7dcd90cea726325ad8bfebba13a46d3d97d06eb19e8bffdaba"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "Unresolved reference 'pathlib'",
              "markdown": "Unresolved reference 'pathlib'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/utils/__init__.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 50,
                    "startColumn": 6,
                    "charOffset": 2185,
                    "charLength": 7,
                    "snippet": {
                      "text": "pathlib"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 48,
                    "startColumn": 1,
                    "charOffset": 2154,
                    "charLength": 79,
                    "snippet": {
                      "text": "import argparse\nimport os\nfrom pathlib import Path\nfrom typing import Optional\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "b52911088d7fe140998764d3416bfea2520a6c7b3fd28fdac0f2b9b3092251da"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          },
          {
            "ruleId": "PyUnresolvedReferencesInspection",
            "kind": "fail",
            "level": "error",
            "message": {
              "text": "Unresolved reference 'Path'",
              "markdown": "Unresolved reference 'Path'"
            },
            "locations": [
              {
                "physicalLocation": {
                  "artifactLocation": {
                    "uri": "minerva/utils/__init__.py",
                    "uriBaseId": "SRCROOT"
                  },
                  "region": {
                    "startLine": 50,
                    "startColumn": 21,
                    "charOffset": 2200,
                    "charLength": 4,
                    "snippet": {
                      "text": "Path"
                    },
                    "sourceLanguage": "Python"
                  },
                  "contextRegion": {
                    "startLine": 48,
                    "startColumn": 1,
                    "charOffset": 2154,
                    "charLength": 79,
                    "snippet": {
                      "text": "import argparse\nimport os\nfrom pathlib import Path\nfrom typing import Optional\n"
                    }
                  }
                },
                "logicalLocations": [
                  {
                    "fullyQualifiedName": "project",
                    "kind": "module"
                  }
                ]
              }
            ],
            "partialFingerprints": {
              "equalIndicator/v1": "e8d9041897bf6e01b42341eb50489d0fedb4e220fbcbb8c22059433e7adc2791"
            },
            "properties": {
              "ideaSeverity": "ERROR"
            }
          }
        ],
        "configProfile": "absent",
        "deviceId": "200820300000000-aeb8-7dfb-2319-e05a933d2f21"
      }
    }
  ]
}
