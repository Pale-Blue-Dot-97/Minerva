---
#       *       *    __  ________   ____________ _    _____
#   *        *      /  |/  /  _/ | / / ____/ __ \ |  / /   |  *           *
#       *          / /|_/ // //  |/ / __/ / /_/ / | / / /| |     *
#   *       *     / /  / // // /|  / /___/ _, _/| |/ / ___ |               *
#    *           /_/  /_/___/_/ |_/_____/_/ |_| |___/_/  |_|     *   *
#
#               EXAMPLE MASTER CONFIG FILE FOR AN AUTOENCODER
#
# === PATHS ===================================================================
data_root: tests/fixtures/data
results_dir: tests/tmp/results
cache_dir: tests/tmp/cache

# === HYPERPARAMETERS =========================================================
# ---+ Model Specification +---------------------------------------------------
# Name of model. Substring before hyphen is model class.
model_name: MinervaPSP-test

# Type of model. Can be mlp, scene classifier, segmentation, ssl or siamese.
model_type: segmentation

# ---+ Sizing +----------------------------------------------------------------
batch_size: 2                          # Number of samples in each batch.
input_size: [4, 256, 256]              # patch_size plus leading channel dim.
patch_size: '${to_patch_size: ${input_size}}'  # 2D tuple or float.
n_classes: 10                          # Number of classes in dataset.

# ---+ Experiment Execution +--------------------------------------------------
max_epochs: 2                          # Maximum number of training epochs.
elim: false                            # Eliminates empty classes from schema.
balance: false                         # Balances dataset classes.
pre_train: false                       # Activate pre-training mode.
fine_tune: false                       # Activate fine-tuning mode.
torch_compile: false                   # Wrap model in `torch.compile`.

# ---+ Loss and Optimisers +---------------------------------------------------
loss_func: AuxCELoss                   # Name of the loss function to use.
lr: 1.0E-3                             # Learning rate of optimiser.
optim_func: SGD                        # Name of the optimiser function.

# ---+ Model Parameters +------------------------------------------------------
model_params:
    _target_: minerva.models.MinervaPSP
    input_size: ${input_size}
    n_classes: ${n_classes}
    encoder: true
    segmentation_on: true
    classification_on: true
    upsampling: 8
    aux_params:
        classes: ${n_classes}

# ---+ Optimiser Parameters +--------------------------------------------------
optimiser:
    _target_: torch.optim.${optim_func}
    lr: ${lr}

# ---+ Loss Function Parameters +----------------------------------------------
loss_params:
    _target_: minerva.loss.${loss_func}

# ---+ Dataloader Parameters +-------------------------------------------------
loader_params:
    num_workers: 0
    pin_memory: true

# === WANDB LOGGING ===========================================================
wandb_log: true              # Activates wandb logging.
project: pytest              # Define the project name for wandb.
wandb_dir: /test/tmp/wandb   # Directory to store wandb logs locally.

# === MODEL IO & LOGGING ======================================================
# ---+ Minerva Inbuilt Logging Functions +-------------------------------------

record_int: true     # Store integer results in memory.
record_float: false  # Store floating point results too. Beware memory overload!

# ---+ Collator +--------------------------------------------------------------
collator: torchgeo.datasets.stack_samples

# === TASKS ===================================================================
tasks:
    fit-train:
        _target_: minerva.tasks.StandardEpoch
        train: true
        record_float: true

        data_config: '${oc.create:${cfg_load: minerva/inbuilt_cfgs/dataset/DFC2020.yaml}}'  # yamllint disable-line rule:line-length

        # ---+ Dataset Parameters +--------------------------------------------
        dataset_params:
            sampler:
                _target_: torch.utils.data.RandomSampler
                num_samples: 32

            transforms:
                RandomResizedCrop:
                    _target_: kornia.augmentation.RandomResizedCrop
                    p: 1.0
                    size: ${patch_size}
                    cropping_mode: resample
                    keepdim: true
                RandomHorizontalFlip:
                    _target_: kornia.augmentation.RandomHorizontalFlip
                    p: 0.2
                    keepdim: true

            image:
                transforms:
                    normalise:
                        _target_: minerva.transforms.Normalise
                        norm_value: 4095
                    RandomApply:
                        p: 0.25
                        jitter:
                            _target_: minerva.transforms.DetachedColorJitter
                            brightness: 0.2
                            contrast: 0.1
                            saturation: 0.1
                            hue: 0.15
                    gaussian_blur:
                        _target_: kornia.augmentation.RandomGaussianBlur
                        kernel_size: 9
                        p: 0.2
                        sigma: [0.01, 0.2]
                        keepdim: true
                    gaussian_noise:
                        _target_: kornia.augmentation.RandomGaussianNoise
                        p: 0.2
                        std: 0.05
                        keepdim: true
                    random_erasing:
                        _target_: kornia.augmentation.RandomErasing
                        p: 0.2
                        keepdim: true

                _target_: minerva.datasets.DFC2020
                root: DFC/DFC2020
                split: test
                use_s2hr: true
                labels: true
            mask:
                transforms:
                    MaskResize:
                        _target_: minerva.transforms.MaskResize
                        size: 64
                        interpolation: NEAREST

    test-test:
        _target_: minerva.tasks.StandardEpoch
        train: false
        record_float: true

        data_config: '${oc.create:${cfg_load: minerva/inbuilt_cfgs/dataset/DFC2020.yaml}}'  # yamllint disable-line rule:line-length

        # ---+ Dataset Parameters +--------------------------------------------
        dataset_params:
            sampler:
                _target_: torch.utils.data.RandomSampler
                num_samples: 16

            image:
                transforms:
                    Normalise:
                        _target_: minerva.transforms.Normalise
                        norm_value: 4095

                _target_: minerva.datasets.DFC2020
                root: DFC/DFC2020
                split: test
                use_s2hr: true
                labels: true

            mask:
                transforms:
                    MaskResize:
                        _target_: minerva.transforms.MaskResize
                        size: 64
                        interpolation: NEAREST

# === PLOTTING OPTIONS ========================================================
plots:
    History: true   # Plot of the training and validation metrics over epochs.
    CM: true        # Confusion matrix.
    Pred: true      # Pie chart of the distribution of the predicted classes.
    ROC: true      # Receiver Operator Characteristics for each class.
    micro: false    # Include micro averaging in ROC plot.
    macro: false    # Include macro averaging in ROC plot.
    Mask: true      # Plot predicted masks against ground truth and imagery.

# === MISCELLANEOUS OPTIONS ===================================================
# ---+ Early Stopping +--------------------------------------------------------
stopping:
    patience: 2    # No. of val epochs with increasing loss before stopping.
    verbose: true  # Verbosity of early stopping prints to stdout.

# ---+ Verbosity and Saving +--------------------------------------------------
verbose: true           # Verbosity of Trainer print statements to stdout.
save: true              # Saves created figures to file.
show: false             # Shows created figures in a pop-up window.
p_dist: false           # Shows the distribution of classes to stdout.
plot_last_epoch: true  # Plot the results of the last training and val epochs.

# opt to ask at runtime; auto or True to automatically do so; or False,
# None etc to not
save_model: false

# ---+ Other +-----------------------------------------------------------------
# opt to ask at runtime; auto or True to automatically do so; or False,
# None etc to not
run_tensorboard: false
calc_norm: false
