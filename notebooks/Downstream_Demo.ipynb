{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import RandomSampler, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchgeo.datasets.utils import stack_samples\n",
    "import numpy as np\n",
    "\n",
    "from minerva.loss import AuxCELoss\n",
    "from minerva.datasets import DFC2020\n",
    "from minerva.models import MinervaPSP\n",
    "from minerva.transforms import Normalise, MinervaCompose\n",
    "from minerva.utils.utils import get_cuda_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (4, 256, 256)\n",
    "feature_dim = 512\n",
    "n_classes = 10\n",
    "batch_size = 8\n",
    "encoder_name = \"resnet50\"\n",
    "encoder_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_path = Path(input(\"Path to the pre-trained backbone weights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_cuda_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(input(\"Path to the root directory containing all the data\"))\n",
    "\n",
    "train_root = root / \"DFC2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DFC2020(str(train_root), split=\"test\", use_s2hr=True, labels=True, transforms=MinervaCompose({\"image\": Normalise(4095)}))\n",
    "#val_dataset = DFC2020(str(train_root), split=\"val\", use_s2hr=True, labels=True, transforms=MinervaCompose({\"image\": Normalise(4095)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_dataset, num_samples=256)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, collate_fn=stack_samples, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model = MinervaPSP(\n",
    "    AuxCELoss(),\n",
    "    patch_size,\n",
    "    n_classes=1,\n",
    "    encoder_name=encoder_name,\n",
    "    encoder_depth=encoder_depth,\n",
    "    psp_out_channels=feature_dim,\n",
    "    #freeze_backbone=True\n",
    ")\n",
    "\n",
    "pretrain_model.load_state_dict(torch.load(pre_train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model.model.make_segmentation_head(n_classes, upsampling=32, activation=torch.nn.PReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model.model.make_classification_head({\"classes\": n_classes, \"activation\": torch.nn.PReLU})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_opt = Adam(pretrain_model.parameters(), lr=1e-3)\n",
    "pretrain_model.set_optimiser(pretrain_opt)\n",
    "pretrain_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = MinervaPSP(\n",
    "    AuxCELoss(),\n",
    "    patch_size,\n",
    "    n_classes=n_classes,\n",
    "    encoder_name=encoder_name,\n",
    "    encoder_depth=encoder_depth,\n",
    "    psp_out_channels=feature_dim,\n",
    "    upsampling=32,\n",
    "    aux_params={\"classes\": n_classes, \"activation\": torch.nn.PReLU},\n",
    "    classification_on=True,\n",
    "    activation=torch.nn.PReLU,\n",
    ")\n",
    "\n",
    "baseline_opt = Adam(baseline_model.parameters(), lr=1e-3)\n",
    "baseline_model.set_optimiser(baseline_opt)\n",
    "baseline_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "from kornia.color import bgr_to_rgb\n",
    "from matplotlib.colors import ListedColormap\n",
    "from minerva.utils.visutils import get_mlp_cmap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cmap_style = ListedColormap(train_dataset.colours.values(), N=n_classes)\n",
    "cmap = get_mlp_cmap(cmap_style, n_classes)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    pretrain_losses = []\n",
    "    pretrain_accs = []\n",
    "    baseline_losses = []\n",
    "    baseline_accs = []\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        images = batch[\"image\"].to(device).float()\n",
    "        masks = batch[\"mask\"].to(device).long()\n",
    "\n",
    "        # Uses MinervaModel.step.\n",
    "        for name, model, losses, accs in ((\"pretrain\", pretrain_model, pretrain_losses, pretrain_accs), (\"baseline\", baseline_model, baseline_losses, baseline_accs)):\n",
    "            loss, pred = model.step(images, masks, train=True)\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "            accs.append((torch.argmax(pred[0], 1) == masks).sum().item())\n",
    "            \n",
    "            print(name)\n",
    "            fig, axs = plt.subplots(3, pred[0].shape[0], figsize=(10, 4))\n",
    "            for i in range(pred[0].shape[0]):\n",
    "                axs[0, i].imshow(images[i].cpu().numpy()[:3].transpose(1, 2, 0))\n",
    "                axs[1, i].imshow(\n",
    "                    masks[i].cpu().numpy(), cmap=cmap, vmin=0, vmax=n_classes\n",
    "                )\n",
    "                axs[2, i].imshow(\n",
    "                    pred[0][i].detach().argmax(dim=0).cpu().numpy(),\n",
    "                    cmap=cmap,\n",
    "                    vmin=0,\n",
    "                    vmax=n_classes,\n",
    "                )\n",
    "            plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "            plt.show()\n",
    "\n",
    "    for name, losses, accs in ((\"pretrain\", pretrain_losses, pretrain_accs), (\"baseline\", baseline_losses, baseline_accs)):\n",
    "        print(\n",
    "            f\"Train {epoch} ({name} model)| Loss: {np.mean(losses)}| Accuracy: {np.mean(accs) * 100.0 / (batch_size * patch_size[1] * patch_size[2])}%\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
