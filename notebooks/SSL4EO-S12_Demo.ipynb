{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSL4EO-S12 SimConvNet Demo\n",
    "\n",
    "This notebook is a small demo of using a small amount of SSL4EO-S12 and NAIP imagery with Chesapeake Land Cover data to train a `minerva` `SimConv` model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torchgeo.datasets import stack_samples, EuroSAT100, EuroSAT\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.crs import CRS\n",
    "from segmentation_models_pytorch import PSPNet\n",
    "from kornia.color import bgr_to_rgb\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minerva.models import SimConv, MinervaWrapper, ResNet18\n",
    "from minerva.loss import SegBarlowTwinsLoss\n",
    "from minerva.utils.utils import get_cuda_device, calc_norm_euc_dist\n",
    "from minerva.datasets import NonGeoSSL4EOS12Sentinel2, PairedNonGeoDataset, DFC2020, stack_sample_pairs\n",
    "from minerva.transforms import ClassTransform, Normalise, MinervaCompose, make_transformations\n",
    "from minerva.utils.visutils import get_mlp_cmap\n",
    "from minerva.utils.utils import find_modes, eliminate_classes, find_empty_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_cuda_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(input(\"Path to the root directory containing all the data\"))\n",
    "\n",
    "train_root = root / \"SSL4EO-S12/ssl4eo-s12_100patches/s2a\"\n",
    "val_root = root / \"DFC2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_root)\n",
    "print(val_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (4, 120, 120)\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalisation_factor = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_params = {\n",
    "    \"Normalise\": {\n",
    "        \"module\": \"minerva.transforms\",\n",
    "        \"norm_value\": normalisation_factor,\n",
    "    },\n",
    "    \"RandomApply\": {\n",
    "        \"p\": 0.2,\n",
    "        \"DetachedColorJitter\": {\n",
    "            \"module\": \"minerva.transforms\",\n",
    "            \"brightness\": 0.2,\n",
    "            \"contrast\": 0.1,\n",
    "            \"saturation\": 0.1,\n",
    "            \"hue\": 0.15,\n",
    "        },\n",
    "    },\n",
    "    \"RandomResizedCrop\": {\n",
    "        \"module\": \"kornia.augmentation\",\n",
    "        \"p\": 0.2,\n",
    "        \"size\": patch_size[1:3],\n",
    "        \"cropping_mode\": \"resample\",\n",
    "        \"keepdim\": True,\n",
    "    },\n",
    "    \"RandomHorizontalFlip\": {\n",
    "        \"module\": \"kornia.augmentation\",\n",
    "        \"p\": 0.2,\n",
    "        \"keepdim\": True,\n",
    "    },\n",
    "    \"RandomGaussianBlur\": {\n",
    "        \"module\": \"kornia.augmentation\",\n",
    "        \"kernel_size\": 9,\n",
    "        \"p\": 0.2,\n",
    "        \"sigma\": [0.01, 0.2],\n",
    "        \"keepdim\": True,\n",
    "    },\n",
    "    \"RandomGaussianNoise\": {\n",
    "        \"module\": \"kornia.augmentation\",\n",
    "        \"p\": 0.2,\n",
    "        \"std\": 0.05,\n",
    "        \"keepdim\": True,\n",
    "    },\n",
    "    \"RandomErasing\": {\n",
    "        \"module\": \"kornia.augmentation\",\n",
    "        \"p\": 0.2,\n",
    "        \"keepdim\": True,\n",
    "    },\n",
    "}\n",
    "transformations = make_transformations({\"image\": transform_params})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making Train Dataset\")\n",
    "train_dataset = PairedNonGeoDataset(NonGeoSSL4EOS12Sentinel2(str(train_root), bands=[\"B2\", \"B3\", \"B4\", \"B8\"], transforms=transformations), size=patch_size[1:3], max_r=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomSampler(train_dataset, num_samples=256)\n",
    "dataloader = DataLoader(train_dataset, sampler=sampler, collate_fn=stack_sample_pairs, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pair = next(iter(dataloader))\n",
    "\n",
    "for j, batch in enumerate(batch_pair):\n",
    "    images = batch[\"image\"]\n",
    "    for i, image in enumerate(images):\n",
    "        x = torch.from_numpy(np.array(image)).float()\n",
    "\n",
    "        bins = torch.linspace(0, 10000 / normalisation_factor, 128)\n",
    "        hist = [torch.histogram(c, bins=bins) for c in x]\n",
    "        \n",
    "        plt.figure(figsize=(3, 3))\n",
    "\n",
    "        plt.plot(hist[0].bin_edges[:-1], hist[0].hist, color=\"b\")\n",
    "        plt.plot(hist[1].bin_edges[:-1], hist[1].hist, color=\"g\")\n",
    "        plt.plot(hist[2].bin_edges[:-1], hist[2].hist, color=\"r\")\n",
    "        plt.plot(hist[3].bin_edges[:-1], hist[3].hist, color=\"orange\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pair = next(iter(dataloader))\n",
    "\n",
    "# Setup the figure.\n",
    "fig, ax = plt.subplots(nrows=batch_size, ncols=2, figsize=(2, batch_size))\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "for j, batch in enumerate(batch_pair):\n",
    "    images = batch[\"image\"]\n",
    "    for i, image in enumerate(images):\n",
    "            image = bgr_to_rgb(image[0:3, :, :]).permute(1, 2, 0)\n",
    "            \n",
    "            ax[i, j].imshow(image)\n",
    "            ax[i, j].axes.get_xaxis().set_visible(False)\n",
    "            ax[i, j].axes.get_yaxis().set_visible(False)\n",
    "            #ax[i, j].set_title(f\"Sample {i}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making Validation Dataset\")\n",
    "val_dataset = DFC2020(val_root, split=\"val\", use_s2hr=True, labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = [sample[\"mask\"] for sample in val_dataset]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dist = find_modes(val_labels, plot=False)\n",
    "\n",
    "# Finds the empty classes and returns modified classes, a dict to convert between the old and new systems\n",
    "# and new colours.\n",
    "new_classes, forwards, new_colours = eliminate_classes(find_empty_classes(class_dist), val_dataset.classes, val_dataset.colours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_transform = ClassTransform(forwards)\n",
    "val_dataset.transforms = MinervaCompose({\"image\": Normalise(4095), \"mask\": class_transform})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valsampler = RandomSampler(val_dataset, num_samples=120)\n",
    "valdataloader = DataLoader(val_dataset, sampler=valsampler, collate_fn=stack_samples, batch_size=batch_size, num_workers=2)\n",
    "valdata = list(valdataloader)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in enumerate(valdata[\"image\"]):\n",
    "    \n",
    "    x = torch.from_numpy(np.array(image)).float()\n",
    "\n",
    "    bins = torch.linspace(0, 1, 128)\n",
    "    hist = [torch.histogram(c, bins=bins) for c in x]\n",
    "\n",
    "    plt.figure(figsize=(3, 3))\n",
    "\n",
    "    plt.plot(hist[0].bin_edges[:-1], hist[0].hist, color=\"b\")\n",
    "    plt.plot(hist[1].bin_edges[:-1], hist[1].hist, color=\"g\")\n",
    "    plt.plot(hist[2].bin_edges[:-1], hist[2].hist, color=\"r\")\n",
    "    plt.plot(hist[3].bin_edges[:-1], hist[3].hist, color=\"orange\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_root = root / \"EuroSat100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = EuroSAT100(str(test_root), split=\"test\", bands=[\"B04\", \"B03\", \"B02\", \"B08\"], download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions for the SimConvNet and the downstream PSPNet.\n",
    "crit = SegBarlowTwinsLoss()\n",
    "xentropy = CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "# Criterions are normally parsed to models at init in minerva.\n",
    "model = SimConv(crit, input_size=patch_size, feature_dim=512, projection_dim=128).to(\n",
    "    device\n",
    ")\n",
    "opt = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Optimisers need to be set to a model in minerva before training.\n",
    "model.set_optimiser(opt)\n",
    "model.determine_output_dim(sample_pairs=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50  # Number of epoches to conduct.\n",
    "f_val = 10  # Frequency of downstream validation in number of training epoches.\n",
    "n_classes = len(new_classes)\n",
    "cmap_style = ListedColormap(new_colours.values(), N=len(new_colours))\n",
    "cmap = get_mlp_cmap(cmap_style, len(new_classes))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    losses = []\n",
    "    euc_dists = []\n",
    "    collapse_levels = []\n",
    "    avg_loss = 0.0\n",
    "    avg_std = 0.0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        x_i_batch, x_j_batch = (\n",
    "            batch[0][\"image\"].to(device).float(),\n",
    "            batch[1][\"image\"].to(device).float(),\n",
    "        )\n",
    "\n",
    "        x_batch = torch.stack([x_i_batch, x_j_batch])\n",
    "\n",
    "        # Uses MinervaModel.step.\n",
    "        loss, pred = model.step(x_batch, train=True)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        z = pred.flatten(1, -1)\n",
    "\n",
    "        z_a, z_b = torch.split(z, int(0.5 * len(z)), 0)\n",
    "\n",
    "        euc_dist = calc_norm_euc_dist(z_a.detach().cpu(), z_b.detach().cpu())\n",
    "        euc_dists.append(euc_dist / len(z_a))\n",
    "\n",
    "        output = torch.nn.functional.normalize(z_a, dim=1)\n",
    "\n",
    "        std = torch.std(output, 0).mean()\n",
    "\n",
    "        # use moving averages to track the loss and standard deviation\n",
    "        w = 0.9\n",
    "        avg_loss = w * avg_loss + (1 - w) * loss.item()\n",
    "        avg_std = w * avg_std + (1 - w) * std.item()\n",
    "\n",
    "        # the level of collapse is large if the standard deviation of the l2\n",
    "        # normalized output is much smaller than 1 / sqrt(dim)\n",
    "        collapse_level = 1 - avg_std / np.sqrt(len(output))\n",
    "\n",
    "        collapse_levels.append(collapse_level)\n",
    "\n",
    "    print(\n",
    "        f\"Train {epoch}| Loss: {np.mean(losses)}| Euc_dist: {np.mean(euc_dists)} | Collapse Level: {np.mean(collapse_levels) * 100.0}%\"\n",
    "    )\n",
    "\n",
    "    if epoch % f_val == 0:\n",
    "        # Extract encoder from the model and freeze its weights.\n",
    "        encoder = model.backbone\n",
    "        encoder = encoder.requires_grad_(False)\n",
    "\n",
    "        # Construct a new PSPNet.\n",
    "        psp = MinervaWrapper(\n",
    "            PSPNet,\n",
    "            input_size=patch_size,\n",
    "            criterion=xentropy,\n",
    "            n_classes=n_classes,\n",
    "            encoder_name=\"resnet18\",\n",
    "            classes=n_classes,\n",
    "            in_channels=4,\n",
    "        ).to(device)\n",
    "\n",
    "        # Replace its encoder and decoder with our pre-trained encoder (which is a PSP encoder-decoder).\n",
    "        psp.decoder = encoder.decoder\n",
    "        psp.encoder = encoder.encoder\n",
    "\n",
    "        # Set up the optimiser for the PSP.\n",
    "        psp_opt = Adam(psp.parameters(), lr=0.001)\n",
    "        psp.set_optimiser(psp_opt)\n",
    "\n",
    "        opt_losses = []\n",
    "\n",
    "        # Train downstream PSP.\n",
    "        for sample in valdataloader:\n",
    "            x = sample[\"image\"].to(device).float()\n",
    "            y = sample[\"mask\"].to(device).long()  # .squeeze(1)\n",
    "\n",
    "            opt_loss, z = psp.step(x, y, train=True)\n",
    "            opt_losses.append(opt_loss.item())\n",
    "\n",
    "        # Use the pre-selected batch of data for visualisation of the PSP's results.\n",
    "        image = valdata[\"image\"].to(device).float()\n",
    "        target = valdata[\"mask\"].to(device).long()  # .squeeze(1)\n",
    "        final_loss, pred = psp.step(image, target, train=False)\n",
    "        opt_losses.append(final_loss.item())\n",
    "\n",
    "        print(f\"Val {epoch}| Loss: {np.mean(opt_losses)}\")\n",
    "\n",
    "        fig, axs = plt.subplots(3, pred.shape[0], figsize=(10, 4))\n",
    "        for i in range(pred.shape[0]):\n",
    "            axs[0, i].imshow(image[i].cpu().numpy()[:3].transpose(1, 2, 0))\n",
    "            axs[1, i].imshow(\n",
    "                target[i].cpu().numpy(), cmap=cmap, vmin=0, vmax=len(new_classes)\n",
    "            )\n",
    "            axs[2, i].imshow(\n",
    "                pred[i].detach().argmax(dim=0).cpu().numpy(),\n",
    "                cmap=cmap,\n",
    "                vmin=0,\n",
    "                vmax=len(new_classes),\n",
    "            )\n",
    "        plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minerva.transforms import SelectChannels\n",
    "from torchgeo.datasets import BigEarthNet\n",
    "\n",
    "big_root = root / \"BigEarthNet\"\n",
    "\n",
    "bigearthnet_transforms = MinervaCompose({\"image\": [SelectChannels([1, 2, 3, 7]), Normalise(2048)]})\n",
    "\n",
    "bigearthnet_dataset = BigEarthNet(root=big_root, split=\"val\", bands=\"s2\", download=False, transforms=bigearthnet_transforms)\n",
    "\n",
    "bigearthnet_sampler = RandomSampler(bigearthnet_dataset, num_samples=512)\n",
    "bigearthnet_dataloader = DataLoader(bigearthnet_dataset, batch_size=8, sampler=bigearthnet_sampler, collate_fn=stack_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(bigearthnet_dataloader))\n",
    "\n",
    "# Setup the figure.\n",
    "fig, ax = plt.subplots(nrows=1, ncols=batch_size, figsize=(batch_size, 1))\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "for i, image in enumerate(batch[\"image\"]):\n",
    "        image = bgr_to_rgb(image[0:3, :, :]).permute(1, 2, 0)\n",
    "        \n",
    "        ax[i].imshow(image)\n",
    "        ax[i].axes.get_xaxis().set_visible(False)\n",
    "        ax[i].axes.get_yaxis().set_visible(False)\n",
    "        #ax[i, j].set_title(f\"Sample {i}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in enumerate(next(iter(bigearthnet_dataloader))[\"image\"]):\n",
    "    x = torch.from_numpy(np.array(image)).float()\n",
    "\n",
    "    bins = torch.linspace(0, 1, 128)\n",
    "    hist = [torch.histogram(c, bins=bins) for c in x]\n",
    "    \n",
    "    plt.figure(figsize=(3, 3))\n",
    "\n",
    "    plt.plot(hist[0].bin_edges[:-1], hist[0].hist, color=\"b\")\n",
    "    plt.plot(hist[1].bin_edges[:-1], hist[1].hist, color=\"g\")\n",
    "    plt.plot(hist[2].bin_edges[:-1], hist[2].hist, color=\"r\")\n",
    "    plt.plot(hist[3].bin_edges[:-1], hist[3].hist, color=\"orange\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minerva.models import FlexiSceneClassifier\n",
    "from torch.nn import BCELoss\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "bigearthnet_model = FlexiSceneClassifier(\n",
    "    criterion=BCELoss(),\n",
    "    input_size=patch_size,\n",
    "    n_classes=19,\n",
    "    fc_dim=512,\n",
    "    encoder_on=True,\n",
    "    filter_dim=-1,\n",
    "    freeze_backbone=False,\n",
    "    clamp_outputs=True,\n",
    "    backbone_args={\n",
    "        \"module\": \"minerva.models\",\n",
    "        \"name\": \"MinervaPSP\",\n",
    "        \"input_size\": patch_size,\n",
    "        \"n_classes\": 19,\n",
    "        \"encoder_name\": \"resnet18\",\n",
    "        \"encoder_weights\": \"imagenet\",\n",
    "        \"psp_out_channels\": 512,\n",
    "        \"segmentation_on\": False,\n",
    "        \"classification_on\": False,\n",
    "        \"encoder\": False,\n",
    "    }\n",
    ").to(device)\n",
    "\n",
    "bigearthnet_model.train()\n",
    "\n",
    "optimiser = Adam(bigearthnet_model.parameters(), lr=1.0e-2)\n",
    "bigearthnet_model.set_optimiser(optimiser)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    bigearthnet_losses = []\n",
    "    for batch in bigearthnet_dataloader:\n",
    "        images = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].to(device, dtype=torch.float)\n",
    "\n",
    "        bigearthnet_model.optimiser.zero_grad()\n",
    "        \n",
    "        z = bigearthnet_model(images)\n",
    "        \n",
    "        z = z.clamp(0, 1)\n",
    "        loss = bigearthnet_model.criterion(z, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        bigearthnet_model.optimiser.step()\n",
    "        \n",
    "        bigearthnet_losses.append(loss.item())\n",
    "\n",
    "    print(f\"{epoch}: {np.mean(bigearthnet_losses)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_root = root / \"EuroSAT_MS\"\n",
    "fine_tune_dataset = EuroSAT(fine_tune_root, split=\"train\", bands=[\"B04\", \"B03\", \"B02\", \"B08\"])\n",
    "fine_tune_sampler = RandomSampler(fine_tune_dataset, num_samples=512)\n",
    "fine_tune_dataloader = DataLoader(fine_tune_dataset, batch_size=8, sampler=fine_tune_sampler, collate_fn=stack_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = CrossEntropyLoss()\n",
    "test_model = ResNet18(test_loss, input_size=patch_size, n_classes=10)\n",
    "\n",
    "test_model.network.conv1 = model.backbone.encoder.conv1\n",
    "test_model.network.layer1 = model.backbone.encoder.layer1\n",
    "test_model.network.layer2 = model.backbone.encoder.layer2\n",
    "test_model.network.layer3 = model.backbone.encoder.layer3\n",
    "test_model.network.layer4 = model.backbone.encoder.layer4\n",
    "\n",
    "test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = RandomSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, sampler=test_sampler, collate_fn=stack_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_optimiser = Adam(test_model.parameters(), lr=1.0e-3)\n",
    "test_model.set_optimiser(test_optimiser)\n",
    "\n",
    "fine_tune_losses = []\n",
    "for batch in fine_tune_dataloader:\n",
    "    images = batch[\"image\"].to(device)\n",
    "    print(images.size())\n",
    "    labels = batch[\"label\"].to(device)\n",
    "\n",
    "    loss, z = test_model.step(images, labels, train=True)\n",
    "    \n",
    "    fine_tune_losses.append(loss.item())\n",
    "\n",
    "print(np.mean(fine_tune_losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
